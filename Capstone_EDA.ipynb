{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unlocking Climate Solutions\n",
    "Collaboration opportunities between cities and businesses for socially equitable climate risk mitigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title image](figures/cdp-logo_16_9_capstone.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll explore the world's largest survey on environmental actions in search for collaboration potential between cities and corporates. Using different text analysis methods, we aim to discover climate mitigation concepts that do not perpetuate social inequities. As you read this notebook, you will learn how cities and businesses assess the risks and opportunities posed by climate change. We show how committed the participants in the survey are already working on climate protection, which topics are particularly suitable for collaboration and describe the relationship between climate risks and social equity. Furthermore, we will take a look at the current status and the objectives of the survey participants with regard to their emission values.\n",
    "\n",
    "We have summarised all our findings in a scoring, the results of which can be further explored on our [interactive dashboard](https://score2-project.herokuapp.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Origin of the dataset\n",
    "CDP is an international non-profit organization that supports companies and cities disclose their environmental impact.\n",
    "\n",
    "Once a year, the CDP voluntarily collects data and information on behalf investors on CO2 emissions, climate risks and reduction targets and strategies of companies using standardized questionnaires. The CDP now manages the world’s largest database of it’s kind.\n",
    "\n",
    "CDP works with over 6000 corporations, as well as over 550 cities and 100 states and regions to help them ensure that an effective carbon emissions reductions strategy is made integral to their operations.\n",
    "\n",
    "Kaggle is an online community for data scientists and machine learning practitioners. Kaggle allows users to find and publish datasets, explore and build models in a web-based data-science environment, work with other data scientists and machine learning engineers, and enter competitions to solve data science challenges.\n",
    "\n",
    "In order to develop a methodology for calculating key performance indicators that relate to the environmental and social issues that relate to the environmental and social issues that are discussed in the survey data, the CDP launched a competition on Kaggle. These KPI’s should aim to support finding answers to the following questions.\n",
    "\n",
    "- How do you help cities to a rapidly changing climate admits a global pandemic, but do It in a way that is social equitable?\n",
    "- What are the projects that can be invested in that will help pull cities out of a recession, mitigate climate issues, but not perpetuate racial/social inequities?\n",
    "- What are the practical and actionable points where city corporate ambition join, i.e. where do cities have problems that corporations affected by those problems could solve, and vice versa?\n",
    "- How can we measure the intersection between environmental risks and social equity, as a contributor to resiliency?\n",
    "\n",
    "The dataset provided by CDP contains data for the years 2018, 2019 and 2020. It contains data for the city disclosure (cid) and corporation disclosure (cod) with meta data of their respective cities or corporations. Additionally there are data (cor and cir) containing the answers for cities and corporations for the questionnaires in their respective years. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Feature Glossary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Cities Disclosing (cid)\n",
    "- **year_reported_to_cdp:** Cities Disclosure cycle survey year  \n",
    "- **account_number:** The unique identifier given to every city organisation that receives a request to complete a CDP questionnaire  \n",
    "- **organization:** Name of the City organisation disclosing  \n",
    "- **city:** Name of the City the city organisation is disclosing on behalf of  \n",
    "- **country:** Country of city  \n",
    "- **cdp_region:** CDP operation region City is located within  \n",
    "- **reporting_authority:** \"CDP collects information on behalf of a number of additional initiatives. Other than CDP Cities, organisations can indicate the additional initiatve they are have answered questions for \",\"C40,CDP Cities,ICLEI - Local Governments for Sustainability\",\"Includes Global Covenant of Mayors for Climate and Energy, ICLEI Green Climate Cities, ICLEI Ecomobility / Ecologistics, C40 Cities Climate Leadership Group\"  \n",
    "- **access:** Cities can submit CDP response in public status or in non public status. Non public responses can only be shared within CDP and between signatory partners. Public responses can be shared beyond CDP City organisations,public  \n",
    "- **first_time_discloser:** Is the City disclosing for the first time to CDP  \n",
    "- **population:** Citiy population estimate  \n",
    "- **population_year:** City population estimate year  \n",
    "- **city_location:** \"Citty location cordinates by longitude, latitide\"  \n",
    "- **last_update:** Resonse record last update  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Cities Responses (cir)\n",
    "- **questionnaire:** Questionnaire and questionnaire year the company's response relates to\n",
    "- **year_reported_to_cdp:** Cities Disclosure cycle survey year  \n",
    "- **account_number:** The unique identifier given to every city organisation that receives a request to complete a CDP questionnaire  \n",
    "- **organization:** Name of the City organisation disclosing  \n",
    "- **country:** Country of city    \n",
    "- **cdp_region:** CDP operation region City is located within  \n",
    "- **parent_section:** Module ('Parent Section') of the CDP questionnaire the question belongs to (e.g. Emissions Reduction)  \n",
    "- **section:** Section of the CDP questionnaire the question belongs to (e.g.Mitigation Actions)  \n",
    "- **question_number:** Question number of response (e.g. 5.4) \n",
    "- **question_name:** Describes the anticipated outcomes of the most impactful mitigation actions your city is currently undertaking; the total cost of the action and how much is being funded by the local government \n",
    "- **column_number:** Column number of matrix set (Table) or matrix dynamic (Add Rows Table) column in question  reponse table  \n",
    "- **column_name:** Column name of matrix set (Table) or matrix dynamic (Add Rows Table) column in question  reponse table,Co-benefit area \n",
    "- **row_number:** \"Row number of matrix set (Table) or matrix dynamic (Add Rows Table) row in question  reponse table. If originally submitted in a table format, this will indicate the number of rows of response data has been entered in response to a question. \",  \n",
    "- **row_name:** Row name of matrix set (Table) or matrix dynamic (Add Rows Table) row in question  reponse table. Description of data type for RowNumber where applicable, Population that is food insecure)  \n",
    "- **response_answer:** Question response submitted by company,Greening the economy,\"Can range from string, integar and double data types. Question not applicable = This question was not presented to the company to be answered due to conditional logic in the questionnaire. NA = The company was presented with this question but did not respond\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Corporations Disclosing (cod)\n",
    "- **account_number:** The unique identifier given to every company that receives a request to complete a CDP questionnaire.\n",
    "- **organization:** Name of the company disclosing.\n",
    "- **survey_year:** Disclosure cycle survey year. (E.g. survey year 2020 ran from March 2020 - September 2020)\n",
    "- **country:** Country in which the company is incorporated or legally registered.\n",
    "- **region:** CDP operating region in which the company is incorporated or legally registered.\n",
    "- **invitation_status:** CDP invites companies to disclose to the Investor request. If they choose to disclose, they will appear as \"\"submitted\"\".\n",
    "- **public:** Companies can submit CDP response in public status or in non public status. Non public responses can only be shared within CDP. Public responses can be shared beyond CDP investor signatories.\n",
    "- **samples:** CDP uses Market Cap from major indices and other environmental factors to help determine who should be requested to respond. Company's are distributed among sample groups to group similar organisations for targetted  invitations to disclose etc.(Continuity, Companies that disclosed the previous year are automatically requested to disclose the following year.)\n",
    "- **response_received_date:** DateTime company response was first received within CDP response systems,2018-08-15T00:00:00Z\n",
    "- **minimum_tier:** Indicates if the highest questionnaire tier a company has responded to. Company's can choose or are requested to submit to a shorter 'Minimum tier' questionnaire or a more in-depth 'Full tier' questionnaire with extended questions. Certain questions are therefore only available in the Full questionnaire.\n",
    "- **selected_tier:** Indicates if the questionnaire tier a company has responded to. Company's can choose or are requested to submit to a shorter 'Minimum tier' questionnaire or a more in-depth 'Full tier' questionnaire with extended questions.  Certain questions are therefore only available in the Full questionnaire. \n",
    "- **questionnaire:** Questionnaire and questionnaire year the company's response relates to.\n",
    "- **theme:** Questionnaire Theme the company's response relates to.\n",
    "- **authority_types:** Company's can be requested to respond to the CDP questionnaire by either/both CDP investor signatories and CDP Supply Chain members as suppliers that constititute their supply chain operations.\n",
    "- **activities:** CDP Activity Classification System categorizes companies according to their different business streams, revenue and impact on the environment. All  company's potential  business activities based on revenue, within the CDP Activity Classification System (e.g. Aluminium refining, Aluminum, Engines & motors, Fabricated metal components, Other vehicle equipment & systems). \n",
    "- **sectors:** CDP Activity Classification System categorizes companies according to their different business streams, revenue and impact on the environment. All  company's  potential business sectors based on revenue, within the CDP Activity Classification System (e.g. Metal products manufacturing, Metal smelting, refining & forming, Powered machinery). \n",
    "- **industries:** CDP Activity Classification System categorizes companies according to their different business streams, revenue and impact on the environment.  All  company's  potential business industries based on revenue, within the CDP Activity Classification System (e.g. Manufacturing, Materials).\n",
    "- **primary_activity:** CDP Activity Classification System categorizes companies according to their different business streams, revenue and impact on the environment. A company's primary business activity based on revenue; the most specific classification of three tiers in the CDP Activity Classification System.\n",
    "- **primary_sector:** CDP Activity Classification System categorizes companies according to their different business streams, revenue and impact on the environment. A company's primary business sector based on revenue; the second most specific classification of three tiers in the CDP Activity Classification System (e.g. Powered machinery)\n",
    "- **primary_industry:** CDP Activity Classification System categorizes companies according to their different business streams, revenue and impact on the environment. A company's primary industry based on revenue; the broadest classification of three tiers in the CDP Activity Classification System.\n",
    "- **primary_questionnaire_sector:** Describes the sector-specific questionnaire that was provided to the company based on their largest activity, if this version of the general questoinnaire was available.\n",
    "- **primary_ticker:** Financial  Market identifier for company.\n",
    "- **tickers:** Market identifiers (if more than one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Corporations Responses (cor)\n",
    "- **account_number:** The unique identifier given to every company that receives a request to complete a CDP questionnaire.\n",
    "- **organization:** Name of the company disclosing.\n",
    "- **survey_year:** Disclosure cycle survey year. \n",
    "- **response_received_date:** DateTime company response was first received within CDP response systems.\n",
    "- **accounting_period_to:** Accounting year end for the survey responses provided by the Company.\n",
    "- **ors_response_id:** Response Identifier for all responses belonging to that company and theme.\n",
    "- **submission_date:** DateTime company response was finalised and submitted to CDP with no further amendments.\n",
    "- **page_name:** Section of the CDP questionnaire the question belongs to.\n",
    "- **module_name:** Module ('Parent Section') of the CDP questionnaire the question belongs to e.g.Questions.\n",
    "- **question_number:** Question number of response.\n",
    "- **question_unique_reference:** Question name.\n",
    "- **colmn_number:** Column number of matrix set (Table) or matrix dynamic (Add Rows Table) column in question  reponse table.\n",
    "- **column_name:** Column name of matrix set (Table) or matrix dynamic (Add Rows Table) column in question  reponse table.\n",
    "- **table_columns_unique_reference:** Column name and number combination modified with '-' seperator from column_name, providing unique column identifer for each question response.\n",
    "- **row_number:** Row number of matrix set (Table) or matrix dynamic (Add Rows Table) row in question  reponse table. If originally submitted in a table format, this will indicate the number of rows of response data has been entered in response to a question.\n",
    "- **row_name:** Row name of matrix set (Table) or matrix dynamic (Add Rows Table) row in question  reponse table. Description of data type for RowNumber where applicable (i.e. Scope 3 emissions category).\n",
    "- **data_point_name:** Question number_Column number_Question Name - Column Name string identifier.\n",
    "- **data_point_id:** Unique identifier for Question Column Response.\n",
    "- **response_value:** Question response submitted by company.\n",
    "- **comments:** Added response clarifications from Company or CDP staff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Dataframe Description\n",
    "\n",
    "The following dataframes are going to be used within this notebook:\n",
    "\n",
    "- **cid_raw** - Cities Disclosing. Originally imported dataset. Combines ...\n",
    "- **cir_raw** - Cities Disclosing. Originally imported dataset. Combines ...\n",
    "- **cod_raw** - Cities Responses.  Originally imported dataset. Combines ... water and climate\n",
    "- **cor_raw** - Cities Responses.  Originally imported dataset. Combines ... water and climate  \n",
    "\n",
    "- **cid_ext01** - External Data with AccountNumber, City, Population\n",
    "- **cid_ext02** - External Data with Location\n",
    "\n",
    "- **cid** - Result of DataCleaning: DataFrame for working ...\n",
    "- **cir** - Result of DataCleaning: DataFrame for working ...\n",
    "- **cod** - Result of DataCleaning: DataFrame for working ...\n",
    "- **cor** - Result of DataCleaning: DataFrame for working ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Environment Set-Up\n",
    "## 3.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# specific libaries\n",
    "import glob                                     # read all csv files in the directory\n",
    "import os                                       # for using OS functions\n",
    "import warnings                                 # for suppression of depricated messages          \n",
    "import pandas_profiling                         # enhanced EDA functions\n",
    "from methods import *                           # selfmade functions and methods\n",
    "from geopy.geocoders import Nominatim\n",
    "from tqdm import tqdm\n",
    "#from sqlalchemy import create_engine           # for SQL access\n",
    "\n",
    "\n",
    "# visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import pygal\n",
    "from keplergl import KeplerGl\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# ML - PreProcessing\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Global Variables and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')               # for suppression of depricated messages\n",
    "RSEED = 42                                      # for replicability purposes\n",
    "\n",
    "# ipython magic commands\n",
    "%matplotlib inline\n",
    "\n",
    "# Data-Import/Export and Pickle-Handling\n",
    "csv_read     = True\n",
    "pkl_write    = True \n",
    "pkl_read     = False\n",
    "sql_present  = False                            # only True if MySQL-Database is available\n",
    "db_write     = False                            # only True if MySQL-Database is available\n",
    "sqlpkl_write = False                             # only True if MySQL-Database is available\n",
    "cxx_creation = True\n",
    "\n",
    "# database engine for connection\n",
    "if sql_present:\n",
    "    login = pd.read_csv('data/database-login.csv')\n",
    "    credentials = str(login.iloc[0,5])\n",
    "    engine = create_engine('mysql+pymysql://'+credentials)\n",
    "\n",
    "# show plotting params from methods.py\n",
    "rcParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing Response-Datasets for better handling in development-testing\n",
    "def reduce_to_10k(df):\n",
    "    result = resample(df,                       # Dataframe to resample\n",
    "                      replace=False,            # sample without replacement\n",
    "                      n_samples=10000,          # sample size\n",
    "                      random_state=RSEED)       # for reproducible results\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_number_cleaning(question_number_string):\n",
    "    dict_l3 = {'a':'1', 'b':'2', 'c':'3', 'd':'4', 'e':'5', \n",
    "               'f':'6', 'g':'7', 'h':'8', 'i':'9', 'j':'10', \n",
    "               'k':'11', 'l':'12', 'm':'13', 'n':'14', 'o':'15', \n",
    "               'p':'16', 'q':'17', 'r':'18', 's':'19', 't':'20', \n",
    "               'u':'21', 'v':'22', 'w':'23', 'x':'24', 'y':'25', 'z':'26'}\n",
    "    last_char = question_number_string[-1]\n",
    "    \n",
    "    if question_number_string == 'Response Language':\n",
    "        q_nr_l1, q_nr_l2, q_nr_l3 = '00','00','01'\n",
    "    elif question_number_string == 'Amendments_question':\n",
    "        q_nr_l1, q_nr_l2, q_nr_l3 = '00','00','02'\n",
    "    elif last_char in  dict_l3:\n",
    "        question_number_string = question_number_string[0:-1]\n",
    "        q_nr_l1 = question_number_string.split('.')[0].zfill(2)\n",
    "        q_nr_l2 = question_number_string.split('.')[1].zfill(2)\n",
    "        q_nr_l3 = dict_l3[last_char].zfill(2)\n",
    "    else:\n",
    "        q_nr_l1 = question_number_string.split('.')[0].zfill(2)\n",
    "        q_nr_l2 = question_number_string.split('.')[1].zfill(2)\n",
    "        q_nr_l3 = '00'\n",
    "    return q_nr_l1, q_nr_l2, q_nr_l3\n",
    "\n",
    "#question_number_cleaning('17.3u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_responses(data, question_num, column_number=[1], row_number=[1], theme='combined',year=['2018','2019','2020']):\n",
    "    '''’A query function that creates a new dataframe with responses from the given data.'''\n",
    "    # Reduktion auf ausgewählte Menge:\n",
    "    responses = data[(data.theme == theme) &\n",
    "                     (data.year.isin(year)) &\n",
    "                     # Abfrageteil bei Nutzung der 'question_number':                   \n",
    "                     (data.question_number == question_num) &\n",
    "                     # Abfrageteil bei Nutzung der 'q_nr':\n",
    "                     #(data.q_nr == question_num) &\n",
    "                     (data.column_number.isin(column_number)) &\n",
    "                     (data.row_number.isin(row_number)) \n",
    "                    ].copy()\n",
    "\n",
    "    # Ausgabe der Haupt-Frage:\n",
    "    print(f'AnswerCount = {responses.shape[0]}')\n",
    "\n",
    "    # Variablenbesetzung bei Nutzung der 'question_number':\n",
    "    quest_num = data[(data.question_number == question_num) & (data.year == year[0])].question_number.iat[0]\n",
    "    question  = data[(data.question_number == question_num) & (data.year == year[0])].question_name.iat[0]\n",
    "\n",
    "    # Variablenbesetzung bei Nutzung der 'q_nr':\n",
    "    #quest_num = data[(data.q_nr == question_num) & (data.year == year[0])].question_number.iat[0]\n",
    "    #question  = data[(data.q_nr == question_num) & (data.year == year[0])].question_name.iat[0]\n",
    "\n",
    "    print(f'QuestionNumber = {quest_num}:\\n{question}')\n",
    "\n",
    "    # Sortierung:\n",
    "    result = responses.sort_values(by=['type',\n",
    "                                       'theme',\n",
    "                                       #'year',\n",
    "                                       'account_number',\n",
    "                                       'response_pnt'])[[#'type',\n",
    "                                                         #'theme',\n",
    "                                                         #'year',\n",
    "                                                         'account_number',\n",
    "                                                         'entity',\n",
    "                                                         'response_pnt',\n",
    "                                                         'column_name',\n",
    "                                                         'row_name',\n",
    "                                                         'response_answer']]\n",
    "    return result\n",
    "\n",
    "#answer_df = get_responses(cir, '1.0a', [0,1,2,3,4], [i for i in range(2146)], theme='combined', year=['2020'])\n",
    "#answer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_theme(strng):\n",
    "    if strng[0] == 'C':\n",
    "        result = 'climate'\n",
    "    elif strng[0] == 'W':\n",
    "        result = 'water'\n",
    "    else:\n",
    "        result = 'other'\n",
    "    return result\n",
    "\n",
    "#identify_theme('W-EU0.1b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sql_present:\n",
    "    def sql_to_db(sql_statement):\n",
    "        cnx = engine.connect()\n",
    "        result = pd.read_sql(sql_statement, cnx)\n",
    "        cnx.close()\n",
    "        return result\n",
    "\n",
    "    def write_to_db(df,table_name):\n",
    "        df.to_sql(table_name, engine, chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_pickle(name='_empty_', statement=''):\n",
    "    path = \"data/Other/sqlpkl/\"+name+\".sqlpkl\"\n",
    "    if sqlpkl_write:\n",
    "        df_sql_saved = sql_to_db(statement)\n",
    "        df_sql_saved.to_pickle(path)\n",
    "        return df_sql_saved\n",
    "    else:\n",
    "        df_sql_loaded = pd.read_pickle(path)\n",
    "        return df_sql_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Mining\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start the analysis by loading the given data through our functions and by gathering external sources to account for relevant missing information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Importing from Kaggle (.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cities Disclosing (combining the years 2018, 2019 and 2020)\n",
    "path = 'data/Cities/Disclosing/'\n",
    "filename_start = '20'\n",
    "if csv_read:  cid_raw = get_data(path, filename_start)\n",
    "if db_write:  write_to_db(cid_raw,'cid_raw')\n",
    "if pkl_write: cid_raw.to_pickle(path+'cid_raw.pkl')\n",
    "if pkl_read:  cid_raw = pd.read_pickle(path+'cid_raw.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cities Responses (combining the years 2018, 2019 and 2020)\n",
    "path = 'data/Cities/Responses/'\n",
    "filename_start = '20'\n",
    "if csv_read:  cir_raw = get_data(path, filename_start)\n",
    "if db_write:  write_to_db(cir_raw,'cir_raw')\n",
    "if pkl_write: cir_raw.to_pickle(path+'cir_raw.pkl')\n",
    "if pkl_read:  cir_raw = pd.read_pickle(path+'cir_raw.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corporations Disclosing  (combining Climate_Change and Water_Security with the years 2018, 2019 and 2020)\n",
    "path = 'data/Corporations/Disclosing/'\n",
    "filename_start = '20'\n",
    "if csv_read:  cod_raw = get_data(path, filename_start)\n",
    "if db_write:  write_to_db(cod_raw,'cod_raw')\n",
    "if pkl_write: cod_raw.to_pickle(path+'cod_raw.pkl')\n",
    "if pkl_read:  cod_raw = pd.read_pickle(path+'cod_raw.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Corporations Responses  (combining Climate_Change and Water_Security with the years 2018, 2019 and 2020)\n",
    "path = 'data/Corporations/Responses/'\n",
    "filename_start = '20'\n",
    "if csv_read:  cor_raw = get_data(path, filename_start)\n",
    "if db_write:  write_to_db(cor_raw,'cor_raw')\n",
    "if pkl_write: cor_raw.to_pickle(path+'cor_raw.pkl')\n",
    "if pkl_read:  cor_raw = pd.read_pickle(path+'cor_raw.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Importing from External Sources (.xls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the best possible overview of the city disclosure data set, we import the **missing city names** as well as the **population** for the corresponding organizations. This will allows us to get a slightly better understanding of the underlying data and helps later on to conduct more accurate analysis. \n",
    "\n",
    "In order to append the missing city names, as well as the missing popualtion data we used public available sources. Additionally we checked all cities with a population of 3000 or less and a population of 100000 or more and corrected the data where necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing additional population data and city names, that were missing\n",
    "cid_ext01 = pd.read_excel('data/Cities/cities_final.xls')\n",
    "\n",
    "#merging imported data\n",
    "cid_pop = pd.merge(left=cid_raw,\n",
    "                   right=cid_ext01[['City', 'Population']],\n",
    "                   left_on=cid_raw['account_number'],\n",
    "                   right_on=cid_ext01['AccountNumber'],\n",
    "                   how='left')\n",
    "\n",
    "#drop the key_0 column which is generated during the merge step\n",
    "cid_pop.drop('key_0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all `City`and `Population`data, it is worthwhile to import the corresponding geo locations to obtain a better geographical understanding of the dataset. For that, we use the `GeoPy`library and pull latitude and longitude data from the city names. The aim of this effort is to transfer the information to the city dataset and plot the response answers on **KeplerGl** maps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the coordinates for each of the cities\n",
    "cid_ext02 = pd.read_excel('data/Cities/city_coordinates_data.xls')\n",
    "\n",
    "# drop duplicates rows based on account_number\n",
    "cid_ext02 = cid_ext02.drop_duplicates(subset=\"account_number\", keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#merge location data to cleaned city disclosure dataframe\n",
    "cid_loc = pd.merge(left=cid_raw,\n",
    "                   right=cid_ext02[['account_number','lat', 'lon']],\n",
    "                   on=\"account_number\",\n",
    "                   how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Cleaning\n",
    "The original goal of this step was to create a basis on which answers to specific questions could be directly accessed and evaluated.\n",
    "\n",
    "During the intensive examination of the data provided by CDP (especially the extensive response data sets), we came across various issues that made structurally clean or fully automated access difficult or impossible:\n",
    "\n",
    "- Question numbers and contents differ from year to year\n",
    "- Content of the question cannot be systematically determined\n",
    "- Reply sequence partly individually selectable\n",
    "- Numerical, categorical and free text mixed in one column\n",
    "- Many false statements, transmission errors (always only detectable in relation to the individual question)\n",
    "- 90 different languages\n",
    "\n",
    "After various attempts to fully address the problems with the help of functions, we decided to leave the data as it is and to carry out the selective data cleaning always in the context of dealing with a specific question.\n",
    "So here we have (apart from the obvious deletion of lines without a meaningful answer) only made a structural unification in order to create a basis for functions that allow an approach to a single question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Cities Disclosing (cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_raw.info()\n",
    "print(cid_raw.shape)\n",
    "print(cid_pop.shape)\n",
    "print(cid_loc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step, we create a simplified city disclosure dataframe by focusing on the columns that contain the most relevant information for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new DataFrame for working (incl. creating some new colums/features):\n",
    "if cxx_creation:\n",
    "    cid = pd.DataFrame()\n",
    "    cid['type']                     = ['cid' for i in cid_raw.index]\n",
    "    cid['theme']                    = 'combined'\n",
    "    #cid['year']                    = cid_raw['year_reported_to_cdp']\n",
    "    cid['year']                     = [str(i) for i in cid_raw.year_reported_to_cdp]\n",
    "    cid['account_number']           = cid_raw['account_number']\n",
    "    cid['public']                   = cid_raw['access']\n",
    "    cid['entity']                   = cid_pop['City']\n",
    "    cid['country']                  = cid_raw['country']\n",
    "    cid['region']                   = cid_raw['cdp_region']\n",
    "    cid['population']               = cid_pop['Population']\n",
    "    cid['city']                     = cid_pop['City']\n",
    "    cid['lat']                      = cid_loc['lat']\n",
    "    cid['lon']                      = cid_loc['lon']\n",
    "\n",
    "    # Due to redundant or missing information the following columns are no longer needed:\n",
    "    #cid['organization']            = cid_raw['organization']\n",
    "    #cid['reporting_authority']     = cid_raw['reporting_authority']\n",
    "    #cid['first_time_discloser']    = cid_raw['first_time_discloser']\n",
    "    #cid['population_year']         = cid_raw['population_year']\n",
    "    #cid['last_update']             = cid_raw['last_update']\n",
    "    #cid['altitude']                = cid_raw['altitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Saving and loading of the full dataset:\n",
    "if db_write:  write_to_db(cid,'cid')\n",
    "if pkl_write: cid.to_pickle(\"data/Cities/Disclosing/cid.pkl\")\n",
    "if pkl_read:  cid = pd.read_pickle(\"data/Cities/Disclosing/cid.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating one (or more) copis of cid for further enhancement:\n",
    "cid_enh =cid.copy()   # This one is used by Olaf\n",
    "cid_enh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Cities Responses (cir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, we will use the geographical information that we retrieved to complete the city disclosure data set and transfer this data to the cities responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cir_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer city, latitude, longitude and population data to city response dataframe\n",
    "if cxx_creation:\n",
    "    loc_info = cid[[\"account_number\", \"city\", \"lat\", \"lon\", \"population\"]]\n",
    "\n",
    "# drop duplicates rows based on account_number\n",
    "if cxx_creation:\n",
    "    loc_info=loc_info.drop_duplicates(subset=\"account_number\", keep=\"first\")\n",
    "\n",
    "# Add city, lat, lon and population to raw dataset.\n",
    "if cxx_creation:\n",
    "    cir_loc = pd.merge(left=cir_raw,\n",
    "                       right=loc_info, \n",
    "                       on=\"account_number\",\n",
    "                       how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we again simplify the dataframe for the cities responses by omitting all columns that we perceive as less relevant for the further analysis. In addition, we reduce complexity of the question names by splitting the **question name** into separate columns. This allows for easier access to specific questions in the analysis later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new DataFrame for working (incl. creating some new colums/features):\n",
    "if cxx_creation:\n",
    "    cir = pd.DataFrame()\n",
    "    cir['type']                   = ['cir' for i in cir_raw.index]\n",
    "    cir['theme']                  = 'combined'\n",
    "    #cir['year']                  = cir_raw.apply(lambda x : int(x['questionnaire'][-4:]), axis=1)\n",
    "    cir['year']                   = cir_raw.apply(lambda x : str(x['questionnaire'][-4:]), axis=1)\n",
    "    cir['account_number']         = cir_raw['account_number']\n",
    "    cir['entity']                 = cir_loc['city']\n",
    "    cir['city']                   = cir_loc['city']\n",
    "    cir['population']             = cir_loc['population'] \n",
    "    cir['country']                = cir_raw['country']\n",
    "    cir['region']                 = cir_raw['cdp_region']\n",
    "    cir['section']                = cir_raw['section']\n",
    "    cir['q_nr_l1']                = cir_raw.apply(lambda x : question_number_cleaning(x['question_number'])[0], axis=1)\n",
    "    cir['q_nr_l2']                = cir_raw.apply(lambda x : question_number_cleaning(x['question_number'])[1], axis=1)\n",
    "    cir['q_nr_l3']                = cir_raw.apply(lambda x : question_number_cleaning(x['question_number'])[2], axis=1)\n",
    "    cir['q_nr']                   = cir['q_nr_l1']+cir['q_nr_l2']+cir['q_nr_l3']\n",
    "    cir['question_number']        = cir_raw['question_number']\n",
    "    cir['question_name']          = cir_raw['question_name']\n",
    "    cir['column_number']          = cir_raw['column_number']\n",
    "    cir['column_name']            = cir_raw['column_name']\n",
    "    cir['row_number']             = cir_raw['row_number']\n",
    "    cir['row_name']               = cir_raw['row_name']\n",
    "    cir['response_col']           = cir.apply(lambda x : str(x['year']) +'-'+ x['q_nr'] +'-C'+ str(x['column_number']).zfill(2), axis=1)\n",
    "    cir['response_pnt']           = cir.apply(lambda x : str(x['year']) +'-'+ x['q_nr'] +'-C'+ str(x['column_number']).zfill(2) +'-R'+ str(x['row_number']).zfill(2), axis=1)\n",
    "    cir['response_answer']        = cir_raw['response_answer']\n",
    "    cir['lat']                    = cir_loc['lat']\n",
    "    cir['lon']                    = cir_loc['lon']\n",
    "\n",
    "    # Due to redundant or missing information the following columns are no longer needed:\n",
    "    #cir['questionnaire']         = cir_raw['questionnaire']\n",
    "    #cir['year_reported_to_cdp']  = cir_raw['year_reported_to_cdp']\n",
    "    #cir['cdp_region']            = cir_raw['cdp_region']\n",
    "    #cir['parent_section']        = cir_raw['parent_section']\n",
    "    #cir['comments']              = cir_raw['comments']\n",
    "    #cir['file_name']             = cir_raw['file_name']\n",
    "    #cir['last_update']           = cir_raw['last_update']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cxx_creation:\n",
    "    cir.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das heisst: Es gibt nur 1.141.308 Non-Null Antworten von 1.542.496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting cir[response_answer'] = NaN:\n",
    "if cxx_creation:\n",
    "    print(f'Number of rows before deleting: {cir.shape[0]}')\n",
    "    cir.dropna(axis=0, subset=['response_answer'], inplace=True)\n",
    "    print(f'Number of rows after deleting:  {cir.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welche verschiedenen Antworten gibt es? Was sind die Favoriten?\n",
    "if cxx_creation:\n",
    "    cir.response_answer.value_counts().sort_values(ascending=False, inplace=False, na_position='first').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Question not applicable' represents about 33% of the answers. \n",
    "# Deleting cir[response_answer'] = 'Question not applicable':\n",
    "if cxx_creation:\n",
    "    print(f'Number of rows before deleting: {cir.shape[0]}')\n",
    "    cir = cir.loc[cir['response_answer'] != 'Question not applicable']\n",
    "    print(f'Number of rows after deleting:   {cir.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and loading of the full dataset:\n",
    "if db_write:  write_to_db(cir,'cir')\n",
    "if pkl_write: cir.to_pickle(\"data/Cities/Responses/cir.pkl\")\n",
    "if pkl_read:  cir = pd.read_pickle(\"data/Cities/Responses/cir.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cir.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Corporations Disclosing (cod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new DataFrame for working (incl. creating some new colums/features):\n",
    "if cxx_creation:\n",
    "    cod = pd.DataFrame()\n",
    "    cod['type']                         = ['cod' for i in cod_raw.index]\n",
    "    cod['theme']                        = cod_raw.apply(lambda x : x['questionnaire'].split(' ')[0].lower(), axis=1)\n",
    "    #cod['year']                        = cod_raw.apply(lambda x : int(x['questionnaire'].split(' ')[-1]), axis=1)\n",
    "    cod['year']                         = cod_raw.apply(lambda x : str(x['questionnaire'].split(' ')[-1]), axis=1)\n",
    "    cod['account_number']               = cod_raw['account_number']\n",
    "    cod['public']                       = cod_raw['public']\n",
    "    cod['entity']                       = cod_raw['organization']\n",
    "    cod['country']                      = cod_raw['country']\n",
    "    cod['addressed_by']                 = cod_raw['samples']\n",
    "    cod['minimum_tier']                 = cod_raw['minimum_tier']\n",
    "    cod['selected_tier']                = cod_raw['selected_tier']\n",
    "    cod['authority_types']              = cod_raw['authority_types']              # String sollte noch bereinigt werden (' Investor, Supply Chain')\n",
    "    cod['activities']                   = cod_raw['activities']                   # String mit ausgewählten Branchen/Bereichen. Ansehen!\n",
    "    cod['sectors']                      = cod_raw['sectors']                      # String mit ausgewählten Branchen/Bereichen. Ansehen!\n",
    "    cod['industries']                   = cod_raw['industries']                   # String mit ausgewählten Branchen/Bereichen. Ansehen!\n",
    "    cod['primary_activity']             = cod_raw['primary_activity']             # String mit ausgewählten Branchen/Bereichen. Ansehen!\n",
    "    cod['primary_sector']               = cod_raw['primary_sector']               # String mit ausgewählten Branchen/Bereichen. Ansehen!\n",
    "    cod['primary_industry']             = cod_raw['primary_industry']             # String mit ausgewählten Branchen/Bereichen. Ansehen!\n",
    "    cod['primary_questionnaire_sector'] = cod_raw['primary_questionnaire_sector'] # String mit ausgewählten Branchen/Bereichen. Ansehen!\n",
    "    #cod['location']                    = cod_ext03[]                             # muss noch geändert werden (externe Daten)\n",
    "\n",
    "    # Due to redundant or missing information the following columns are no longer needed:\n",
    "    #cod['survey_year']                 = cod_raw['survey_year']\n",
    "    #cod['region']                      = cod_raw['region']\n",
    "    #cod['invitation_status']           = cod_raw['invitation_status']\n",
    "    #cod['response_received_date']      = cod_raw['response_received_date']\n",
    "    #cod['questionnaire']               = cod_raw['questionnaire']\n",
    "    #cod['theme']                       = cod_raw['theme']\n",
    "    #cod['primary_ticker']              = cod_raw['primary_ticker']\n",
    "    #cod['tickers']                     = cod_raw['tickers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cxx_creation:\n",
    "    cod.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and loading of the full dataset:\n",
    "if db_write:  write_to_db(cod,'cod')\n",
    "if pkl_write: cod.to_pickle(\"data/Corporations/Disclosing/cod.pkl\")\n",
    "if pkl_read:  cod = pd.read_pickle(\"data/Corporations/Disclosing/cod.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating one (or more) copis of cid for further enhancement:\n",
    "cod_enh =cod.copy()   # This one is used by Olaf\n",
    "cod_enh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Corporations Responses (cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new DataFrame for working (incl. creating some new colums/features):\n",
    "if cxx_creation:\n",
    "    cor = pd.DataFrame()\n",
    "    cor['type']                     = ['cor' for i in cor_raw.index]\n",
    "    cor['theme']                    = cor_raw.apply(lambda x : identify_theme(x['question_number']), axis=1)\n",
    "    #cor['theme']                   = [identify_theme(i) for i in cor_raw.question_number]\n",
    "    #cor['year']                    = cor_raw['survey_year']\n",
    "    cor['year']                     = [str(i) for i in cor_raw.survey_year]\n",
    "    cor['account_number']           = cor_raw['account_number']\n",
    "    #cor['account_number']          = [i for i in cor_raw.account_number]\n",
    "    cor['entity']                   = cor_raw['organization']\n",
    "    cor['section']                  = cor_raw['module_name']\n",
    "    #cor['q_nr_l1']                 = cor_raw.apply(lambda x : question_number_cleaning(x['question_number'])[0], axis=1)\n",
    "    #cor['q_nr_l2']                 = cor_raw.apply(lambda x : question_number_cleaning(x['question_number'])[1], axis=1)\n",
    "    #cor['q_nr_l3']                 = cor_raw.apply(lambda x : question_number_cleaning(x['question_number'])[2], axis=1)\n",
    "    #cor['q_nr']                    = cor['q_nr_l1']+cor['q_nr_l2']+cor['q_nr_l3']\n",
    "    cor['question_number']          = cor_raw['question_number']\n",
    "    cor['question_name']            = cor_raw['question_unique_reference']\n",
    "    cor['column_number']            = cor_raw['column_number']\n",
    "    cor['column_name']              = cor_raw['table_columns_unique_reference']\n",
    "    cor['row_number']               = cor_raw['row_number']\n",
    "    cor['row_name']                 = cor_raw['row_name']\n",
    "    cor['response_answer']          = cor_raw['response_value']\n",
    "\n",
    "    # Due to redundant or missing information the following columns are no longer needed:\n",
    "    #cor['response_received_date']  = cor_raw['response_received_date']\n",
    "    #cor['accounting_period_to']    = cor_raw['accounting_period_to']\n",
    "    #cor['ors_response_id']         = cor_raw['ors_response_id']\n",
    "    #cor['submission_date']         = cor_raw['submission_date']\n",
    "    #cor['page_name']               = cor_raw['page_name']\n",
    "    #cor['column_name']             = cor_raw['column_name']\n",
    "    #cor['data_point_name']         = cor_raw['data_point_name']\n",
    "    #cor['data_point_id']           = cor_raw['data_point_id']\n",
    "    #cor['comments']                = cor_raw['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting cor[response_answer'] = NaN:\n",
    "if cxx_creation:\n",
    "    print(f'Number of rows before deleting: {cor.shape[0]}')\n",
    "    cor.dropna(axis=0, subset=['response_answer'], inplace=True)\n",
    "    print(f'Number of rows after deleting:  {cor.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cxx_creation:\n",
    "    cor.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing cor[response_answer'] = NaN with 0:\n",
    "if cxx_creation:\n",
    "    cor['column_number'].fillna(0, inplace=True)\n",
    "\n",
    "    # Changing the dtype to int64:\n",
    "    cor['column_number'] = cor['column_number'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welche verschiedenen Antworten gibt es? Gibt es hier auch so viele 'Question not applicable'?\n",
    "if cxx_creation:\n",
    "    cor.response_answer.value_counts().sort_values(ascending=False, inplace=False, na_position='first').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and loading of the full dataset:\n",
    "if db_write:  write_to_db(cor,'cor')\n",
    "if pkl_write: cor.to_pickle(\"data/Corporations/Responses/cor.pkl\")\n",
    "if pkl_read:  cor = pd.read_pickle(\"data/Corporations/Responses/cor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Data Exploration and Score Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With respect to the tasks and conditions of the [CDP Kaggle Competition](https://www.kaggle.com/c/cdp-unlocking-climate-solutions), we  defined our main goals for EDA and feature engineering as follows:\n",
    "\n",
    "1. help cities and corporates to optimize and communicate there mitigation and climate protection strategies\n",
    "2. show intersection between the interests of the public sekctor and private companies to strengthen collaborations and to encourage to start new ones.\n",
    "3. identify and visualize best practices that strike the best possible blance climate protection and aspects of social justice\n",
    "4. generate new features and explain the insights gained from them\n",
    "5. create relevant KPI\n",
    "6. interpretation of unstructured free text responses\n",
    "7. usage of cluster algorithms to get additional insights\n",
    "\n",
    "As part of our EDA we dig deep into the data sets and examine them for findings. In doing so, we particularly address goals 1, 2 and 3. Based on our qualitative analysis, we then develop a scoring system that includes the following dimensions:\n",
    "<br/>\n",
    "![score2](figures/score2_logo.png)\n",
    "<br/>\n",
    "After an introductory presentation of the basic survey data, the structure of the following section is aligned with the six elements of our SCORE2 model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Basic Survey Data..\n",
    "Having our dataframes prepared, we'll analyze some basic facts about the city and corporations disclosure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 City Disclosures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We start our visual data exploration by examining where the disclosing cities are located and visualize their size by population. Looking at the size distribution of cities is important as it will help us to put their **CO2 emissions** into perspective later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize disclosure data using lat and lon data \n",
    "fig = px.scatter_geo(cid, \n",
    "                     lat=\"lat\",\n",
    "                     lon=\"lon\",\n",
    "                     color=\"country\",\n",
    "                     hover_name=\"country\",\n",
    "                     size=\"population\",\n",
    "                     animation_frame=\"year\", # consider replacing thsi with organization count per country\n",
    "                     projection=\"robinson\",\n",
    "                     size_max=100)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot survey respondents per country\n",
    "plt.figure(figsize=(12,6))\n",
    "ax = sns.countplot(x=\"region\",palette=\"mako\", data=cid, order=cid[\"region\"].value_counts().index)\n",
    "plt.xticks(rotation=70)\n",
    "plt.title(\"Survey Participation Distribution per Region\",{'fontsize': 12});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most contribution to the surveys comes from Latin America, North America and Europe. Other areas are underrepresented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interactive geographical plots with Keplergl**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KeplerGl** allows to interactively explore location data, which we use to analyze the regional distribution of participating cities. From the visualization, we can derive that a major share of participating cities originate from **North and **South America**. The Asian region in contrast is less represented. This is an important observation since the participating corporates are based in North America. Therefore, also having a large share of city respondents from this area facilitates comparisons between cities and corporates later on. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initiate new KeplerGl map\n",
    "cidmap = KeplerGl(height=600, width=800)\n",
    "\n",
    "# add disclosure data\n",
    "cidmap.add_data(data=cid, name='disclosure_map')\n",
    "cidmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 City Responses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, an interactive plot of the response distribution per attribute allows to obtain a better understanding of the data source. To avoid longer run-times and improve the handling of the **KeplerGl** map, we visualize only subsets of the full city response dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract subsample from city response dataframe \n",
    "\n",
    "#initiate new map\n",
    "cirmap = KeplerGl(height=600, width=800)\n",
    "\n",
    "##load selected city response data\n",
    "cirmap.add_data(data=cir, name='responses')\n",
    "cirmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 Corporations Disclosure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize corporate responses per survey theme and year\n",
    "cod_raw[\"questionnaire\"].value_counts().plot(kind='bar')  # Tobi: cod hat jetzt cod[\"year\"] + cod[\"theme\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contribution to the surveys raised from 2018 to 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the most frequent sectors participating in the survey\n",
    "prob = cod[\"sectors\"].value_counts()\n",
    "threshold = 100\n",
    "mask = prob > threshold\n",
    "tail_prob = prob.loc[~mask].sum()\n",
    "prob = prob.loc[mask]\n",
    "prob['other'] = tail_prob\n",
    "prob.plot(kind='bar')\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most contribution from the corporations are from the following sectors:\n",
    "- Electrical & electronic equipment\n",
    "- Food & beverage processing\n",
    "- Financial services\n",
    "- Chemicals\n",
    "- Specialized professional services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Share of Top 5% sectors from all responses\n",
    "\n",
    "#check quantile distribution of sectors\n",
    "prob = cod[\"sectors\"].value_counts()\n",
    "prob /= prob.sum()\n",
    "\n",
    "#split data into quantiles\n",
    "category_classes = pd.qcut(prob, q=[0, .25, 0.95, 1.], \n",
    "                           labels=['bottom 25%', 'mid 70%', 'top 5%'])\n",
    "prob_groups = prob.groupby(category_classes).sum()\n",
    "prob_groups.plot(kind='bar')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meaning of the contribution of the top 5% sectors is about 40% of all answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most frequent industries\n",
    "prob = cod[\"industries\"].value_counts()\n",
    "threshold = 140\n",
    "mask = prob > threshold\n",
    "tail_prob = prob.loc[~mask].sum()\n",
    "prob = prob.loc[mask]\n",
    "prob['other'] = tail_prob\n",
    "prob.plot(kind='bar')\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most contribution from the corporations comes from the following industries:\n",
    "- Manufactoring\n",
    "- Services\n",
    "- Food, veverage & agriculture\n",
    "- Materials\n",
    "- Retail\n",
    "- Biotech, health care & pharma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Share of top 5% industries\n",
    "prob = cod[\"industries\"].value_counts()\n",
    "prob /= prob.sum()\n",
    "\n",
    "#split data into quantiles\n",
    "category_classes = pd.qcut(prob, q=[0, .25, 0.95, 1.], \n",
    "                           labels=['bottom 25%', 'mid 70%', 'top 5%'])\n",
    "prob_groups = prob.groupby(category_classes).sum()\n",
    "prob_groups.plot(kind='bar')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meaning of the contribution of the top 5% industries is about 60% of all answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Social Equity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploration Content**: <br/>\n",
    "On the basis of the available survey results, we investigate in this section the influence of climate-related hazards on social aspects.\n",
    "\n",
    "\n",
    "**Motivation Purpose**:<br/>\n",
    "In order to find out in which areas of climate protection social justice can be particularly positively influenced, we first classify the existing climate risks in terms of their negative impact on them. If a climate threat affects particularly socially disadvantaged groups, countermeasures in this area appear to be particularly socially equitable in conclusion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe with relevant questions\n",
    "df = get_response_pivot(data=cir, questionnumber=\"2.1\", columnnumber=\"all\", pivot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Social Impact of Climate Change Hazards**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows and get responses from dataframe\n",
    "data = df.query('column_number == 5')\n",
    "answers = data.response_answer     # get responses from data frame\n",
    "\n",
    "# provide corrosponding question context\n",
    "print_question(data, \"2.1\",[5]) \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "val, perc = get_pct_freq(answers)\n",
    "top = perc.nlargest(11)\n",
    "                      \n",
    "# Configure main plot\n",
    "ax = plot_freq_of_cv(data=top, xlabel=\"% Responses\", ylabel=\"Impact_Type\",\n",
    "                        title=\"Social impact of hazards\", orient=\"h\")\n",
    "\n",
    ";\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of great importance is the consideration of the social influence of climate hazards. The graph shows the 11 most frequently mentioned answers. All other answers account for a share of less than 0.1% each. We can see that particularly vulnerable population groups are already at risk from climate change. We know that this group is already considered to be disproportionately disadvantaged in many other dimensions.\n",
    "\n",
    "Population displacement is an impact that effects the socially disadvanteged part of a populations above average. Experience also shows that a potential lack of resources is first at the expense of disadvantaged groups. \n",
    "\n",
    "The loss of traditional jobs has a very concrete impact on social justice. So far, this impact has been described as low, but in connection with the Covid pandemic it can be assumed that especially members of the lower and middle classes are threatened by job loss. Climate-related effects could exacerbate this development in a threatening way.\n",
    "\n",
    "Therefor we will focus on the following points:\n",
    "- Increased risk to already vulnerable population\n",
    "- Increased demand for healthcare service\n",
    "- Increased resoure_demand\n",
    "- Population Displacement\n",
    "- Loss of traditional jobs\n",
    "- Increased conflict / crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows and get responses from dataframe\n",
    "top_index = [\n",
    "    'Increased risk to already vulnerable populations', \n",
    "    'Increased demand for healthcare services', \n",
    "    'Increased resource demand',\n",
    "    'Population displacement', \n",
    "    'Loss of traditional jobs'\n",
    "    ]\n",
    "data = df.query('column_number == 1 | (column_number == 5 & response_answer == @top_index)')\n",
    "\n",
    "# create dataframe with responser to columns 1 and 5 next to each others\n",
    "comparison = compare_columns(data=data, questionnumber=\"2.1\", select_col=1, compare_col=5)\n",
    "comparison.rename(columns={\"column_1\":\"hazard_cat\", \"column_5\":\"social_impact\"}, inplace=True)\n",
    "\n",
    "# group results by impact\n",
    "gob = comparison.groupby([\"hazard_cat\",\"social_impact\"]).count()\n",
    "gob = gob.iloc[:,0]\n",
    "gob_perc = gob.groupby(level=0).apply(lambda x:100 * x / float(x.sum()))\n",
    "gob_perc = round(gob_perc, 1)\n",
    "gob_perc = gob_perc.reset_index()\n",
    "gob_perc\n",
    "\n",
    "\n",
    "# Configure main plot\n",
    "plt.figure(figsize=(19,6))\n",
    "ax = sns.barplot(data=gob_perc, x=\"hazard_cat\", y=\"select_key\",hue = \"social_impact\", orient=\"v\", palette=\"hls\", hue_order=top_index) #xlabel=\"Frequency\", ylabel=\"Climate Hazard\",\n",
    "                      #  title=\"Cities threatining Climate Hazards\", orient=\"h\", ax=ax_b1)\n",
    "ax.set_xlabel(\"Hazard category\",fontdict={\"fontsize\":rcParams[\"axes.labelsize\"]})\n",
    "ax.set_ylabel(\"% responses\", fontdict={\"fontsize\":rcParams[\"axes.labelsize\"]})\n",
    "ax.set_title(\"Social impact per category\", fontdict={\"fontsize\":rcParams[\"axes.titlesize\"], \"fontweight\":rcParams[\"axes.titleweight\"]})\n",
    "\n",
    "ax.legend(loc='center left', bbox_to_anchor=(0, -0.5), ncol=5)\n",
    "add_patches(ax)\n",
    "rotate_labels(ax, \"x\", 45);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The social impacts of climate change threats are particularly evident in the health sector. This becomes particularly clear when considering the extreme weather conditions. Here, the negative effect is mostly related directly or indirectly to the health sector. \n",
    "We know that physical health and health care globally is highly dependent on personal prosperity. Measures to avoid health risks are therefore particularly preferable from a social point of view compared to other aspects.\n",
    "\n",
    "The problem of water scarcity is also problematic. This impact affects third-world countries to a massive extent, which already have to cope with particular difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 Scoring "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will be two scores that will give a value to the fact, if a city deals with the fact if there are climate hazards with a social impact and if there are hazards, which vulnerable populations are affected by these hazards.\n",
    "\n",
    "**s_score_1** Score for dealing with climate hazards with social impact.\n",
    "\n",
    "**s_score_2** Score for dealing with vulnerable populations that are affected by these hazards.\n",
    "\n",
    "Each answer provided by the cities will be valued as more acknowledgement of these facts and will count as an additional point. There is a maximum of five points and 0 points for missing answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating s_scores\n",
    "\n",
    "#Creating scoring function for s_score_1 and s_score_2\n",
    "def create_score(x):\n",
    "        if x == 1:\n",
    "            return 1\n",
    "        elif x == 2:\n",
    "            return 2\n",
    "        elif x == 3:\n",
    "            return 3\n",
    "        elif x == 4:\n",
    "            return 4\n",
    "        elif x >= 5:\n",
    "            return 5\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "#Creating subset of cir dataframe and collecting relevant answers for s_score_1\n",
    "reduced = cir[((cir['question_number'] == '4.0a') & (cir['year'] == '2018')) | ((cir['question_number'] == '2.1') & ((cir['column_number'] == 5) | (cir['column_number'] == 10)) & ((cir['year'] == '2019') | (cir['year'] == '2020')))]\n",
    "reduced[\"select_key\"] =reduced[\"year\"].astype(str)+\"_\"+reduced[\"account_number\"].astype(str)\n",
    "reduced_SI = reduced[((reduced['column_number'] == 5) & ((reduced['year'] == '2019') | (reduced['year'] == '2020'))) | ((cir['question_number'] == '4.0a') & (cir['year'] == '2018'))]\n",
    "\n",
    "#Counting answers\n",
    "reduced_SI = reduced_SI['select_key'].value_counts().to_frame()\n",
    "reduced_SI['sum'] = reduced_SI['select_key']\n",
    "reduced_SI['select_key'] = reduced_SI.index\n",
    "reduced_SI.reset_index(inplace =True)\n",
    "\n",
    "#Calculating s_score_1\n",
    "reduced_SI['s_score_1'] = reduced_SI[\"sum\"].apply(create_score)\n",
    "\n",
    "\n",
    "#Creating subset of cir dataframe and collecting relevant answers for s_score_2\n",
    "reduced_SII = reduced.query(\"column_number == 10\")\n",
    "reduced_SII = reduced_SII['select_key'].value_counts().to_frame()\n",
    "\n",
    "#Counting answers\n",
    "reduced_SII['sum'] = reduced_SII['select_key']\n",
    "reduced_SII['select_key'] = reduced_SII.index\n",
    "reduced_SII.reset_index(inplace =True)\n",
    "\n",
    "#Calculating s_score_2\n",
    "reduced_SII['s_score_2'] = reduced_SII[\"sum\"].apply(create_score) \n",
    "\n",
    "\n",
    "#Merging s_score_1 and s_score_2 into one dataframe s_score\n",
    "cid_red = cid.copy()\n",
    "cid_red[\"select_key\"] =cid_red[\"year\"].astype(str)+\"_\"+cid_red[\"account_number\"].astype(str)\n",
    "cid_red = cid_red[['select_key']]\n",
    "s_score   =     pd.merge(left = cid_red,\n",
    "                     right = reduced_SI[['s_score_1']],\n",
    "                     left_on = cid_red['select_key'],\n",
    "                     right_on = reduced_SI['select_key'], \n",
    "                     how = 'left')\n",
    "s_score = s_score[['select_key', 's_score_1']]\n",
    "s_score   =     pd.merge(left = s_score,\n",
    "                     right = reduced_SII[['s_score_2']],\n",
    "                     left_on = s_score['select_key'],\n",
    "                     right_on = reduced_SII['select_key'], \n",
    "                     how = 'left')\n",
    "s_score = s_score[['select_key', 's_score_1', 's_score_2']]\n",
    "s_score.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the survey does not provide information that would allow a comprehensive picture of the link between climate protection and social equity. Only the cities provide a small amount of information about their assessment of the threat situation with regard to social issues. From the available information, however, we can deduce that, from a risk perspective, measures that improve the health and resource supply of the population and can be reconciled with job retention are to be assessed as particularly fair.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Collaboration \n",
    "<font color=orange size=5> **Tobi / überarbeiten, auf Standard anpassen.** </font>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploration Content**: <br/>\n",
    "In this section, \n",
    "\n",
    "\n",
    "**Motivation Purpose**:<br/>\n",
    "In order to, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange size=3> **Noch für diesen Abschnitt beschreiben** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the question inevitably arises as to how leading cities and companies differ in their environmental and social policies from less successful representatives. \n",
    "\n",
    "One approach is to differentiate from those cities that make a public commitment to reduce CO2 emissions and improve social justice, participate in competitions such as the WWF's One Planet City Challenge, or are part of communities such as the Building Efficiency Accelerator. However, since such data is difficult to evaluate and not available for the corporate counterparts, this work stream is beyond the scope of this notebook. \n",
    "\n",
    "Similarly, another interesting perspective is to analyze management incentivization schemes for businesses and assess whether board level compensation for climate-related targets impacts the way companies behave. As with public commitment, we lack the required data to make a thorough analysis. \n",
    "\n",
    "Instead, we will focus our attention on the following pillars: \n",
    "\n",
    "* **Social Impact**:  \n",
    "\n",
    "* **Collaboration**: Examine whether cities and corporates are actively working together on climate issues and in which areas collaboration tends to take place \n",
    "\n",
    "* **Opportunities**: Assessment of perceived opportunities arises from the climate crisis    \n",
    "\n",
    "* **Risk**: Analysis of the perceived risks that threaten cities and corporates\n",
    "\n",
    "* **Engagement**: How willing are cities and corporates to work on climate and social issues  \n",
    "\n",
    "* **Emissions**: Here, we analze cities and corporates current CO2 emission levels, their target emissions as well as the time frame of their goals  \n",
    "\n",
    "Upon scrutinizing different perspectives and questions from the questionnaires, we set up a scoring model to measure the performance of cities and business in addressing the climate crisis with respect to social equity. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Are cities collaborating with businesses on climate change?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We follow the intuition that an effecive and holistic climate strategy requires cities and businesses to work together rather than alone. Firstly, this is because both cities and business pursue common interests and needs in their climate resilience planning. Simply put they thrive on a strong community and suffer under the negative of climate change on infrastructure, energy, food and water supplies and public health. Collaboration between cities and businesses is paramount as both bring complementary strength. Businesses operate much of the essential infrastructure, power, food and water supplies, and accumulate critical technical expertise upon which cities rely. Businesses are also influential political constituencies in cities, and having their support for the city’s climate resilience planning efforts can boost the overall political support for the process.\n",
    "\n",
    "~ adapted from C2ES Guide to Public-Private Collaboration on City Climate Resilience Planning\n",
    "\n",
    "We will beginn the collaboration assessment by investigating the question whether cities are already collaborating with businesses on climate action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe, fetching only the information from the question whether a city is collaborating with businesses on climate action\n",
    "# this information occurs in different question numbers for the different years\n",
    "df6_2 = cir.query(\"(question_number == '6.2' and year == '2020') or (question_number == '6.1' and year == '2019') or (question_number == '5.1' and year == '2018')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows and get responses from dataframe\n",
    "data = df6_2\n",
    "answers = data.response_answer          \n",
    " \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "val, perc = get_pct_freq(answers)\n",
    "val = val.nlargest(5)                     # get top 10 values\n",
    "\n",
    "# Create plotting grid\n",
    "fig, ax_b1, ax_s1, ax_s2, ax_s3 = create_3x3grid(size=(15,10), orient=\"vertical\")\n",
    "\n",
    "# plot results\n",
    "ax_b1 = plot_freq_of_cv(\n",
    "                data=val, \n",
    "                xlabel=\"Frequency\", \n",
    "                ylabel=\"Response\", \n",
    "                title=\"Does your city collaborate with business on climate change?\",\n",
    "                orient=\"h\",\n",
    "                ax=ax_b1\n",
    "        );\n",
    "ax_s1 = plot_small_no_responses(data, ax=ax_s1)\n",
    "ax_s2 = plot_small_responses_yoy(data, ax=ax_s2, plt_type=\"perc\");\n",
    "#ax_s3 = plot_small_responses_per_ptcp(data, ax=ax_s3)\n",
    "plt.tight_layout();\n",
    "cut_labels(fig=ax_b1, \n",
    "           axis=\"y\",\n",
    "           max_length=25)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph we can derive that the overwhelming majority of cities are already or are at least in the progress of engaging with companies on climate topics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename response answer column in question-specific dataframe and map information to disclosure dataframe\n",
    "cid_new = rename_and_merge(original_df=cid,\n",
    "                 feature_df=df6_2,\n",
    "                 feature=\"has_business_collaboration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Areas of collaboration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe, fetching only the information from the question on what topics cities are collaborating with businesses\n",
    "# this information occurs in different question numbers for the different years\n",
    "df6_2a = cir.query(\"(question_number == '6.2a' and year == '2020' and column_number == 1) or (question_number == '6.1a' and year == '2019' and column_number == 1) or (question_number == '5.1a' and year == '2018' and column_number == 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is a long range of individual `Other` answers which will be grouped into a single other category\n",
    "threshold_percent = 1\n",
    "series = pd.value_counts(df6_2a['response_answer'])\n",
    "mask = (series / series.sum() * 100).lt(threshold_percent)\n",
    "df6_2a = df6_2a.assign(response_answer = np.where(df6_2a['response_answer'].isin(series[mask].index),'Other', df6_2a['response_answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge slightly diverging response options from 2018 to 2020 into one reponse\n",
    "df6_2a[\"response_answer\"] = df6_2a['response_answer'].replace('Transport (Mobility)','Transport').replace('Buildings','Building and Infrastructure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows and get responses from dataframe\n",
    "data = df6_2a\n",
    "answers = data.response_answer          \n",
    " \n",
    "# provide corrosponding question context\n",
    "print_question(data, \"6.2a\", columnnumber='1')   \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "val, perc = get_pct_freq(answers)\n",
    "val = val.nlargest(10)                     # get top 10 values\n",
    "\n",
    "# Create plotting grid\n",
    "fig, ax_b1, ax_s1, ax_s2, ax_s3 = create_3x3grid(size=(15,10), orient=\"vertical\")\n",
    "\n",
    "# plot results\n",
    "ax_b1 = plot_freq_of_cv(\n",
    "                data=val, \n",
    "                xlabel=\"Frequency\", \n",
    "                ylabel=\"Response\", \n",
    "                title=\"In which areas do you collaborate with businesses?\",\n",
    "                orient=\"h\",\n",
    "                ax=ax_b1\n",
    "        );\n",
    "ax_s1 = plot_small_no_responses(data, ax=ax_s1)\n",
    "ax_s2 = plot_small_responses_yoy(data, ax=ax_s2, plt_type=\"perc\");\n",
    "ax_s3 = plot_small_responses_per_ptcp(data, ax=ax_s3)\n",
    "plt.tight_layout();\n",
    "cut_labels(fig=ax_b1, \n",
    "           axis=\"y\",\n",
    "           max_length=25)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Energy turns out to be most prevalent collaboration area followed by Transport and Waste. An interesting side note is that for spatial planning, hence the practice of urban planning and development, cities are collaborating much less with businesses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename response answer column in question-specific dataframe and map information to disclosure dataframe\n",
    "cid_new = rename_and_merge(original_df=cid_new,\n",
    "                 feature_df=df6_2a,\n",
    "                 feature=\"collaboration_area\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do corporates engage with their value on climate issues?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will continue to assess the collaboration from the business perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract information into new dataframe\n",
    "dfC12_1 = cor.query(\"question_number == 'C12.1'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we deploy a function that splits the combined responses into its individual components and explodes them into the same column\n",
    "dfC12_1 = split_response(df=dfC12_1, column=\"response_answer\", sep=\";\") \n",
    "dfC12_1[\"response_answer\"] = dfC12_1[\"response_answer\"].str.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows and get responses from dataframe\n",
    "data = dfC12_1\n",
    "answers = data.response_answer          \n",
    "\n",
    "# provide corrosponding question context\n",
    "print_question(data, \"C12.1\", columnnumber='all')     \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "# we strip the left whitespaces from the response answer column\n",
    "val, perc = get_pct_freq(answers)\n",
    "val = val.nlargest(10)                     # get top 10 values\n",
    "\n",
    "# Create plotting grid\n",
    "fig, ax_b1, ax_s1, ax_s2, ax_s3 = create_3x3grid(size=(15,10), orient=\"vertical\")\n",
    "\n",
    "# plot results\n",
    "ax_b1 = plot_freq_of_cv(\n",
    "                data=val, \n",
    "                xlabel=\"Frequency\", \n",
    "                ylabel=\"Response\", \n",
    "                title=\"Do you engage with you value chain in climate issues?\",\n",
    "                orient=\"h\",\n",
    "                ax=ax_b1\n",
    "        );\n",
    "ax_s1 = plot_small_no_responses(data, ax=ax_s1)\n",
    "ax_s2 = plot_small_responses_yoy(data, ax=ax_s2, plt_type=\"perc\");\n",
    "#ax_s3 = plot_small_responses_per_ptcp(data, ax=ax_s3)\n",
    "plt.tight_layout();\n",
    "cut_labels(fig=ax_b1, \n",
    "           axis=\"y\",\n",
    "           max_length=25)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, we observe more than 600 responses of corporaes stating that they **do not engage** with their value chain on climate topics. This poses significant room for improvement as an **integrated approach** that incorporates the full suit of stakeholders is seen as favorable in effectively tackling environmental challenges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename response answer column in question-specific dataframe and map information to disclosure dataframe\n",
    "cod_new = rename_and_merge(original_df=cod,\n",
    "                           feature_df=dfC12_1,\n",
    "                           feature=\"value_chain_engagement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How do corporates with their suppliers?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new data frame\n",
    "dfC12_1a = get_response_pivot(data=cor,\n",
    "                          questionnumber='C12.1a',\n",
    "                          columnnumber='all',\n",
    "                          pivot=False,\n",
    "                          add_info=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all of the individual \"other\" specifications into a single \"other\" group\n",
    "x = dfC12_1a.query(\"column_number == '1'\")\n",
    "dfC12_1a_grouped = x.replace(x.groupby('response_answer').sum().index[4:], 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows and get responses from dataframe\n",
    "data = dfC12_1a_grouped.query(\"column_number == '1'\")\n",
    "answers = data.response_answer          \n",
    "\n",
    "# provide corrosponding question context\n",
    "print_question(data, \"C12.1a\", columnnumber='1')   \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "val, perc = get_pct_freq(answers)\n",
    "val = val.nlargest(10)                     # get top 10 values\n",
    "\n",
    "# Create plotting grid\n",
    "fig, ax_b1, ax_s1, ax_s2, ax_s3 = create_3x3grid(size=(15,10), orient=\"vertical\")\n",
    "\n",
    "# plot results\n",
    "ax_b1 = plot_freq_of_cv(\n",
    "                data=val, \n",
    "                xlabel=\"Frequency\", \n",
    "                ylabel=\"Response\", \n",
    "                title=\"How do you engage with your supply chain on climate issues?\",\n",
    "                orient=\"h\",\n",
    "                ax=ax_b1\n",
    "        );\n",
    "ax_s1 = plot_small_no_responses(data, ax=ax_s1)\n",
    "ax_s2 = plot_small_responses_yoy(data, ax=ax_s2, plt_type=\"perc\");\n",
    "ax_s3 = plot_small_responses_per_ptcp(data, ax=ax_s3)\n",
    "plt.tight_layout();\n",
    "cut_labels(fig=ax_b1, \n",
    "           axis=\"y\",\n",
    "           max_length=25)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are derived from analyzing the supply chain engagement of corporates are noteworthy. Seemingly companies focus their collaboration with the supply chain on climate topics on collecting information and compliance rather than trying to truly change either the individual suppliers behavor or the market as a whole. Co-creating **innovative climate-friendly** or carbon neutral solutions with their suppliers is arguably a far greater step towards truely changing the company'footprint along the supply chain. However, as of now it appears that only few companies are already pursuing this path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to disclosure dataframe\n",
    "cod_new = rename_and_merge(original_df=cod_new,\n",
    "                 feature_df=dfC12_1a_grouped,\n",
    "                 feature=\"supply_chain_engagement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How do corporate engage with their customers?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the relevant dataframe\n",
    "dfC12_1b = get_response_pivot(data=cor,\n",
    "                          questionnumber='C12.1b',\n",
    "                          columnnumber='all',\n",
    "                          pivot=False,\n",
    "                          add_info=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we again replace all of the individual \"other\" specifications into a single \"other\" group\n",
    "x = dfC12_1b.query(\"column_number == '1'\")\n",
    "dfC12_1b_grouped = x.replace(x.groupby('response_answer').sum().index[4:], 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows and get responses from dataframe\n",
    "data = dfC12_1b_grouped.query(\"column_number == '1'\")\n",
    "answers = data.response_answer          \n",
    "\n",
    "# provide corrosponding question context\n",
    "print_question(data, \"C12.1b\", columnnumber='1')   \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "val, perc = get_pct_freq(answers)\n",
    "val = val.nlargest(10)                     # get top 10 values\n",
    "\n",
    "# Create plotting grid\n",
    "fig, ax_b1, ax_s1, ax_s2, ax_s3 = create_3x3grid(size=(15,10), orient=\"vertical\")\n",
    "\n",
    "# plot results\n",
    "ax_b1 = plot_freq_of_cv(\n",
    "                data=val, \n",
    "                xlabel=\"Frequency\", \n",
    "                ylabel=\"Response\", \n",
    "                title=\"What is your engagement type with your customers?\",\n",
    "                orient=\"h\",\n",
    "                ax=ax_b1\n",
    "        );\n",
    "ax_s1 = plot_small_no_responses(data, ax=ax_s1)\n",
    "ax_s2 = plot_small_responses_yoy(data, ax=ax_s2, plt_type=\"perc\");\n",
    "ax_s3 = plot_small_responses_per_ptcp(data, ax=ax_s3)\n",
    "plt.tight_layout();\n",
    "cut_labels(fig=ax_b1, \n",
    "           axis=\"y\",\n",
    "           max_length=25)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the engagement with the suppliers, to date many companies educate their customers about the sustainability efforts of the company. While this is an important first step, collaborating with the customers on innovative climate-friendly solutions is perceived by us as favorable. In this regard, we see again room for improvement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to disclosure dataframe\n",
    "cod_new = rename_and_merge(original_df=cod_new,\n",
    "                 feature_df=dfC12_1b_grouped,\n",
    "                 feature=\"customer_engagement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corporate Engagement with Policy Makers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will examine whether corporates not only engage with suppliers and customers but also with policy makers. This information is vital in determining ways of collaboration between corporates and cities. However, this part is particularly sensible. Corporate influence on policy makers is not always associated with a pro-climate stance. In contrast, corporates spend millions each year to impede the implementation of stricter regulation. \n",
    "\n",
    "Fortunately, the survey contains the question on what position companies take in their engagement with policy makers. Though not a perfect indicator, this information give a guideline in which direction the collaboration between corporates and policy makers is heading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC12_3 = cor.query(\"question_number == 'C12.3'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function to split connected responses and clean whitespaces\n",
    "dfC12_3 = split_response(df=dfC12_3, column=\"response_answer\", sep=\";\")\n",
    "\n",
    "dfC12_3[\"response_answer\"] = dfC12_3[\"response_answer\"].str.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows and get responses from dataframe\n",
    "data = cor.query(\"question_number == 'C12.3'\")\n",
    "answers = data.response_answer          \n",
    "\n",
    "# provide corrosponding question context\n",
    "print_question(data, \"C12.3\", columnnumber='all')   \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "val, perc = get_pct_freq(answers)\n",
    "val = val.nlargest(10)                     # get top 10 values\n",
    "\n",
    "# Create plotting grid\n",
    "fig, ax_b1, ax_s1, ax_s2, ax_s3 = create_3x3grid(size=(15,10), orient=\"vertical\")\n",
    "\n",
    "# plot results\n",
    "ax_b1 = plot_freq_of_cv(\n",
    "        \n",
    "                data=val, \n",
    "                xlabel=\"Frequency\", \n",
    "                ylabel=\"Response\", \n",
    "                title=\"Do you engage with policy makers?\",\n",
    "                orient=\"h\",\n",
    "                ax=ax_b1\n",
    "        );\n",
    "ax_s1 = plot_small_no_responses(data, ax=ax_s1)\n",
    "ax_s2 = plot_small_responses_yoy(data, ax=ax_s2, plt_type=\"perc\");\n",
    "#ax_s3 = plot_small_responses_per_ptcp(data, ax=ax_s3)\n",
    "plt.tight_layout();\n",
    "cut_labels(fig=ax_b1, \n",
    "           axis=\"y\",\n",
    "           max_length=25)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that most respondents use a form of engagement with policy makers. The most frequent form thereby appears to be via **Trade associations** followed by **Direct engagement with policy makers**. We will focus on the direct engagement as there is additional information available about whether corporates advocate a supportive or opposing view with policy makers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to disclosure dataframe\n",
    "cod_new = rename_and_merge(original_df=cod_new,\n",
    "                 feature_df=dfC12_3,\n",
    "                 feature=\"policy_engagement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On what topics do corporates engage with policy makers?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC12_3a = cor.query(\"question_number == 'C12.3a' and column_number == '1'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the response answer column has more than 200 different entries, most of which occur only once.\n",
    "#  We will group all entries which account for less than 2% of all responses into the category `Other`\n",
    "threshold_count = 2\n",
    "series = pd.value_counts(dfC12_3a['response_answer'])\n",
    "mask = (series / series.sum() * 100).lt(threshold_count)\n",
    "dfC12_3a = dfC12_3a.assign(response_answer = np.where(dfC12_3a['response_answer'].isin(series[mask].index),'Other', dfC12_3a['response_answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dfC12_3a\n",
    "answers = data.response_answer          \n",
    "\n",
    "# provide corrosponding question context\n",
    "print_question(data, \"C12.3a\", columnnumber='1')   \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "val, perc = get_pct_freq(answers)\n",
    "val = val.nlargest(10)                     # get top 10 values\n",
    "\n",
    "# Create plotting grid\n",
    "fig, ax_b1, ax_s1, ax_s2, ax_s3 = create_3x3grid(size=(12,8), orient=\"vertical\")\n",
    "\n",
    "# plot results\n",
    "ax_b1 = plot_freq_of_cv(\n",
    "                data=val, \n",
    "                xlabel=\"Frequency\", \n",
    "                ylabel=\"Response\", \n",
    "                title=\"How do you engage with policy makers?\",\n",
    "                orient=\"h\",\n",
    "                ax=ax_b1\n",
    "        );\n",
    "ax_s1 = plot_small_no_responses(data, ax=ax_s1)\n",
    "ax_s2 = plot_small_responses_yoy(data, ax=ax_s2, plt_type=\"perc\");\n",
    "ax_s3 = plot_small_responses_per_ptcp(data, ax=ax_s3)\n",
    "plt.tight_layout();\n",
    "cut_labels(fig=ax_b1, \n",
    "           axis=\"y\",\n",
    "           max_length=25)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In line with the response of the cities, collaboration on **Energy efficiency** is also stated by corporates as the most frequent response. Interestingly, this is followed by a variety of regulatory response options revolving around **Carbon taxes**, **mandatory reporting** and other forms of regulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to disclosure dataframe \n",
    "cod_new = rename_and_merge(original_df=cod_new,\n",
    "                           feature_df=dfC12_3,\n",
    "                           feature=\"policy_engagement_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corporates Alignment with Policy Makers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC12_3a_2 = cor.query(\"question_number == 'C12.3a' and column_number == '2'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dfC12_3a_2\n",
    "answers = data.response_answer          \n",
    "\n",
    "# provide corrosponding question context\n",
    "print_question(data, \"C12.3a\", columnnumber='2')   \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "val, perc = get_pct_freq(answers)\n",
    "val = val.nlargest(10)                     # get top 10 values\n",
    "\n",
    "# Create plotting grid\n",
    "fig, ax_b1, ax_s1, ax_s2, ax_s3 = create_3x3grid(size=(12,8), orient=\"vertical\")\n",
    "\n",
    "# plot results\n",
    "ax_b1 = plot_freq_of_cv(\n",
    "                data=val, \n",
    "                xlabel=\"Frequency\", \n",
    "                ylabel=\"Response\", \n",
    "                title=\"What is your position when collaborating with policy makers?\",\n",
    "                orient=\"h\",\n",
    "                ax=ax_b1\n",
    "        );\n",
    "ax_s1 = plot_small_no_responses(data, ax=ax_s1)\n",
    "ax_s2 = plot_small_responses_yoy(data, ax=ax_s2, plt_type=\"perc\");\n",
    "ax_s3 = plot_small_responses_per_ptcp(data, ax=ax_s3)\n",
    "plt.tight_layout();\n",
    "cut_labels(fig=ax_b1, \n",
    "           axis=\"y\",\n",
    "           max_length=25)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most respondents state that their position fully **supports** the view of policy makers. Under the assumption that the policy makers supports a climate-friendly perspective, this is to be seen as favorable. Only very few companies openly report that their perspective differs from the oppinion of the policy makers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to disclosure dataframe\n",
    "cod_new = rename_and_merge(original_df=cod_new,\n",
    "                           feature_df=dfC12_3a_2,\n",
    "                           feature=\"policy_engagement_position\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 Scoring (Cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we will assign values for each of the added features in an attempt to create a scoring system for the collaborative efforts of cities. \n",
    "\n",
    "More specifically, we will be looking at the columns `has_business_collaboration` and `collaboration_area`. \n",
    "\n",
    "Starting with `has_business_collaboration`, we will conduct a scoring from 1 to 5 with 1 being the lowest score which is attributed if there is no response given and 5 meaning that there is a business collaboration already in place. The scoring methodology is as follows:\n",
    "\n",
    "* 0: no response\n",
    "* 1: No / Not intending to undertake / Do not know\n",
    "* 2: Intending to undertake in future\n",
    "* 3: Intending to undertake in the next 2 years\n",
    "* 4: In progress\n",
    "* 5: Yes\n",
    "\n",
    "As for `collaboration_area` there is not enough information provided to make a clear and reliable distinction between the separate topics. However, following the idea of a holistic approach to address a climate change, we perceive that it is favorable if cities cooperate with businesses on multiple areas. Accordingly, we assign the following scores: \n",
    "\n",
    "* 0: no response\n",
    "* 1: one collaboration area\n",
    "* 2: two collaboration areas\n",
    "* 3: three collaboration areas\n",
    "* 4: four to five collaboration areas \n",
    "* 5: more that five collaboration areas\n",
    "\n",
    "Finally, we will aggregate the results in a final `city_collaboration_score` that will guide us in how well a particular city performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c_score_1 : City-Business Collaboration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign scores for each response option\n",
    "scores = {'nan': 0,\n",
    "          'No' :1, \n",
    "          'Not intending to undertake' :1,\n",
    "          'Do not know' :1,\n",
    "          'Intending to undertake in future':2,\n",
    "          'Intending to undertake in the next 2 years' :3,\n",
    "          'In progress':4,\n",
    "          'Yes':5}\n",
    "\n",
    "# create new business collaboration measure by mapping the scores to the respective response\n",
    "cid_new[\"has_business_collaboration_score\"] = cid_new[\"has_business_collaboration\"].map(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c_score_2 : City_Business Collaboration Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a select key on which the information is mapped on\n",
    "cid_new[\"select_key\"] =cid_new[\"year\"].astype(str)+\"_\"+cid_new[\"account_number\"].astype(str)\n",
    "\n",
    "# compute the sum of entries of all individual collaboration areas and add each of them as new columns\n",
    "cid_new = cid_new.join(pd.crosstab(cid_new[\"select_key\"], cid_new[\"collaboration_area\"]), on=\"select_key\")\n",
    "\n",
    "# this computes the sum of all individual columns\n",
    "cid_new[\"sum_area\"] = cid_new.iloc[:,19:].sum(axis=1)\n",
    "\n",
    "# assign the respective score for each number of counts\n",
    "def create_score(x):\n",
    "        if x == 1:\n",
    "            return 1\n",
    "        elif x == 2:\n",
    "            return 2\n",
    "        elif x == 3:\n",
    "            return 3\n",
    "        elif x == 4 or x == 5:\n",
    "            return 4\n",
    "        elif x > 5:\n",
    "            return 5\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "cid_new[\"collaboration_area_score\"] = cid_new[\"sum_area\"].apply(create_score)\n",
    "\n",
    "#drop all helper columns from the dataframe\n",
    "cid_new.drop(['Other', 'Energy', 'Water', 'Waste', 'Transport',\n",
    "       'Industry', 'Agriculture and Forestry',\n",
    "       'Building and Infrastructure', 'Spatial Planning',\n",
    "       'Social Services', 'Business and Financial Services', 'sum_area'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Collaboration Scoring Table for Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_scores = cid_new[[\"account_number\", \"year\", \"has_business_collaboration_score\", \"collaboration_area_score\"]]\n",
    "# remove all duplicate entries that originate from the multi-row responses\n",
    "cid_scores.drop_duplicates(inplace=True)\n",
    "cid_scores.rename(columns={'has_business_collaboration_score': 'c_score_1', 'collaboration_area_score': 'c_score_2'}, inplace=True)\n",
    "cid_scores = cid_new[[\"account_number\", \"year\", \"has_business_collaboration_score\", \"collaboration_area_score\"]]\n",
    "# remove all duplicate entries that originate from the multi-row responses\n",
    "cid_scores.drop_duplicates(inplace=True)\n",
    "cid_scores.rename(columns={'has_business_collaboration_score': 'c_score_1', 'collaboration_area_score': 'c_score_2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pkl_write: cid_scores.to_pickle(\"data/cid_scores.pkl\", protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 Scoring (Corporates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will assign values for each of the added features in an attempt to create a scoring model for the collaborative efforts of corporates. \n",
    "\n",
    "More specifically, we will be looking at the columns `value_chain_engagement`, `customer_engagement`, `supply_chain_engagement`, and `policy_engagement`. \n",
    "\n",
    "Starting with `value_chain_engagement`, we will conduct a scoring from 1 to 5 with 1 being the lowest score which is attributed if there is no response given and 5 meaning that the company engages with both suppliers and customers. The scoring methodology is slightly more complicated compared to the previous models and is computed as follows:\n",
    "\n",
    "* 0: No response\n",
    "* 1: No, we do not engage\n",
    "* 2: Yes, our investee companies or Yes, other partners in our value chain while both Yes, our customers and Yes, our suppliers are not included\n",
    "* 3: Either Yes, our Suppliers or Yes, our Customers\n",
    "* 4: Both Yes, our Suppliers and Yes, our Customers\n",
    "* 5: All of Yes, our Supplier, Yes, our Customers and Yes, other partners in our value chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c_score_3 : Corporate Value Chain Engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe with value chain engagement responses\n",
    "df_value = cor.query(\"question_number == 'C12.1'\")[[\"account_number\", \"year\", \"entity\", \"response_answer\"]]\n",
    "\n",
    "# split response answer entries into individual response\n",
    "df_value = split_response(df=df_value, column=\"response_answer\", sep=\";\") \n",
    "df_value[\"response_answer\"] = df_value[\"response_answer\"].str.lstrip()\n",
    "\n",
    "# create select key for mapping the response\n",
    "df_value[\"select_key\"] =df_value[\"year\"].astype(str)+\"_\"+df_value[\"account_number\"].astype(str)\n",
    "cod_new[\"select_key\"] =cod_new[\"year\"].astype(str)+\"_\"+cod_new[\"account_number\"].astype(str)\n",
    "\n",
    "# compute the sum of entries of all individual collaboration areas and add each of them as new columns\n",
    "df_value = df_value.join(pd.crosstab(df_value[\"select_key\"], df_value[\"response_answer\"]), on=\"select_key\")\n",
    "\n",
    "# define a function to convert our response methodology to scores \n",
    "def conditions(s):\n",
    "    if s[\"No, we do not engage\"] >=1: \n",
    "        return 1\n",
    "    elif ((s[\"Yes, our investee companies\"] >=1) or (s[\"Yes, other partners in the value chain\"]>=1)) and ((s[\"Yes, our customers\"] == 0) and (s[\"Yes, our suppliers\"] == 0)): \n",
    "        return 2\n",
    "    elif ((s[\"Yes, our customers\"] >= 1) or (s[\"Yes, our suppliers\"] >= 1)) and ((s[\"Yes, our investee companies\"] == 0) and (s[\"Yes, other partners in the value chain\"]==0)): \n",
    "        return 3\n",
    "    elif ((s[\"Yes, our customers\"] >= 1) and (s[\"Yes, our suppliers\"] >= 1)) and ((s[\"Yes, our investee companies\"] == 0) and (s[\"Yes, other partners in the value chain\"]==0)): \n",
    "        return 4\n",
    "    elif ((s[\"Yes, our customers\"] >= 1) and (s[\"Yes, our suppliers\"] >= 1)) and ((s[\"Yes, our investee companies\"] >= 1) or (s[\"Yes, other partners in the value chain\"]>=1)): \n",
    "        return 5\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "# apply the function to create value chain scores\n",
    "df_value['value_chain_score'] = df_value.apply(conditions, axis=1)\n",
    "\n",
    "# create new dataframe with corporate collaboration scores including the new value chain score\n",
    "cod_scores = df_value[[\"account_number\", \"year\", \"value_chain_score\"]]\n",
    "\n",
    "# remove duplicate entries for each year\n",
    "cod_scores.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c_score_4: Corporate Supply Chain Engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supply = cor.query(\"question_number == 'C12.1a' and column_number == 1\")[[\"account_number\", \"year\", \"entity\", \"response_answer\"]]\n",
    "\n",
    "# Combine all the `other. please specify` responses into one `Other` category\n",
    "df_supply = df_supply.replace(df_supply.groupby('response_answer').sum().index[4:], 'Other')\n",
    "\n",
    "# define scoring system\n",
    "scores = {'NaN': 0,\n",
    "          'Compliance & onboarding' :1, \n",
    "          'Information collection (understanding supplier behavior)' :2,\n",
    "          'Engagement & incentivization (changing supplier behavior)':4,\n",
    "          'Innovation & collaboration (changing markets)' :5,\n",
    "          'Other':3}\n",
    "\n",
    "# maps scores to the respective response answer\n",
    "df_supply[\"supply_score\"] = df_supply[\"response_answer\"].map(scores)\n",
    "\n",
    "# choose max score for each entitiy in each year\n",
    "df_supply['supply_chain_score'] = df_supply.groupby(['account_number', 'year'])['supply_score'].transform(np.max)\n",
    "\n",
    "# create merge keys\n",
    "df_supply[\"select_key\"] = df_supply[\"year\"].astype(str) + \"_\" + df_supply[\"account_number\"].astype(str)\n",
    "cod_scores[\"select_key\"] = cod_scores[\"year\"].astype(str) + \"_\" + cod_scores[\"account_number\"].astype(str)\n",
    "\n",
    "# merge new supply chain score to disclosure dataframe\n",
    "cod_scores = pd.merge(left=cod_scores,\n",
    "                   right= df_supply[\"supply_chain_score\"],\n",
    "                   left_on=cod_scores[\"select_key\"],\n",
    "                   right_on=df_supply[\"select_key\"],\n",
    "                   how=\"left\")\n",
    "cod_scores.drop_duplicates(inplace=True)\n",
    "\n",
    "# drop the unneccessary columns\n",
    "cod_scores.drop(\"key_0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c_score_5: Corporate Customer Engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer = cor.query(\"question_number == 'C12.1b' and column_number == 1\")[[\"account_number\", \"year\", \"entity\", \"response_answer\"]]\n",
    "\n",
    "# replace all of the individual \"other\" specifications into a single \"other\" group\n",
    "df_customer = df_customer.replace(df_customer.groupby('response_answer').sum().index[5:], 'Other')\n",
    "\n",
    "# we merge the two Education/information sharing response options into one response\n",
    "df_customer[\"response_answer\"] = df_customer['response_answer'].str.replace('Education/information sharing : Engagement','Education/information sharing')\n",
    "\n",
    "# we assign values for each response option\n",
    "scores = {'nan': 0, \n",
    "          'Information collection (understanding customer behavior)' :1,\n",
    "          'Education/information sharing' : 2,\n",
    "          'Engagement & incentivization (changing customer behavior)':4,\n",
    "          'Collaboration & innovation' :5,\n",
    "          'Other':3}\n",
    "\n",
    "# maps scores to the respective response answer\n",
    "df_customer[\"customer_score\"] = df_customer[\"response_answer\"].map(scores)\n",
    "\n",
    "# choose max score for each entitiy in each year\n",
    "df_customer['customer_score'] = df_customer.groupby(['account_number', 'year'])['customer_score'].transform(np.max)\n",
    "\n",
    "# create select key for merging to disclosure dataframe\n",
    "df_customer[\"select_key\"] = df_customer[\"year\"].astype(str)+\"_\"+df_customer[\"account_number\"].astype(str)\n",
    "\n",
    "# create select key for merging to collaboration scoring dataframe\n",
    "df_customer[\"select_key\"] = df_customer[\"year\"].astype(str)+\"_\"+df_customer[\"account_number\"].astype(str)\n",
    "\n",
    "# merge new supply chain score to disclosure dataframe\n",
    "cod_scores = pd.merge(left=cod_scores,\n",
    "                   right= df_customer[\"customer_score\"],\n",
    "                   left_on=cod_scores[\"select_key\"],\n",
    "                   right_on=df_customer[\"select_key\"],\n",
    "                   how=\"left\")\n",
    "cod_scores.drop_duplicates(inplace=True)\n",
    "\n",
    "# drop the unneccessary columns\n",
    "cod_scores.drop(\"key_0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c_score_6: Corporate Policy Engagement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the scoring is a little more compicated and even more subjective compared to the other value chain engagement scores. \n",
    "Again, we follow our perspective that climate resilience is enhanced when businesses and policy makers work together rather than alone. However, as denoted by the think tank InfluenceMap, only few of the influential corporations are positively engaging on climate policy globally, with most holding either a neutral or negative perspective. This makes a coherent scoring more difficult. One the one hand side, we intend to promote purposeful engagement of corporates with policy makers. On the other hand-side, we only perceive those policy engagements as positive where businesses support the view of local policy makers. Unfortunately, the data provided offers this information for the response option *Direct engagment with policy makers*.\n",
    "\n",
    "To account for this view, we focus on the direct engagement with policy makers and combine the response with the corporate position with policy decisions. Ultimately, we apply the following scoring methodology:\n",
    "\n",
    "* 1: No\n",
    "* 2: Trade associations / Funding research organizations / Direct engagement with policy makers & either no corporate position provided or position is opposing/neutral/undecided \n",
    "* 3: Direct engagement with policy makers & support with major exceptions\n",
    "* 4: Direct engagmenet with policy makers & support with minor exceptions\n",
    "* 5: Direct engagement with policy makers & supportive corporate position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract question from response dataset into separate dataframe\n",
    "df_policy = cor.query(\"question_number == 'C12.3'\")[[\"account_number\", \"year\", \"entity\", \"response_answer\"]]\n",
    "\n",
    "# split chained response answers\n",
    "df_policy = split_response(df=df_policy, column=\"response_answer\".lstrip(), sep=\";\")\n",
    "\n",
    "# remove whitespaces infront of response options\n",
    "df_policy[\"response_answer\"] = df_policy[\"response_answer\"].str.lstrip()\n",
    "\n",
    "# create select key to match information\n",
    "df_policy[\"select_key\"] =df_policy[\"year\"].astype(str)+\"_\"+df_policy[\"account_number\"].astype(str)\n",
    "\n",
    "# create new dataframe for the corporate position\n",
    "df_position = cor.query(\"question_number == 'C12.3a' and column_number == 2\")[[\"account_number\", \"year\", \"response_answer\"]]\n",
    "\n",
    "# create merge key\n",
    "df_position[\"select_key\"] =df_position[\"year\"].astype(str)+\"_\"+df_position[\"account_number\"].astype(str)\n",
    "\n",
    "# convert response options to columns\n",
    "df_position = df_position.join(pd.crosstab(df_position[\"select_key\"], df_position[\"response_answer\"]), on=df_position[\"select_key\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "In the next step, we create a helper column that defines the majority position that a companies takes on policy views. This is necessary given that it is a multi-response column, thus, a single company can have multiple position in a year. This is because each position is assigned to a policy topic (e.g. Energy). For simplification purposes, we take the majority position that a corporate holds in a year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a helper column with majority position\n",
    "df_position[\"majority_position\"] = df_position[[\"Neutral\", \"Oppose\", \"Support\", \"Support with major exceptions\", \"Support with minor exceptions\", \"Undecided\"]].idxmax(1)\n",
    "\n",
    "# merge majority position to policy dataframe\n",
    "df_policy = pd.merge(left=df_policy,\n",
    "                   right= df_position[\"majority_position\"],\n",
    "                   left_on=df_policy[\"select_key\"],\n",
    "                   right_on=df_position[\"select_key\"],\n",
    "                   how=\"left\")\n",
    "df_policy.drop_duplicates(inplace=True)\n",
    "\n",
    "# define the conditions based on which scores are assigned\n",
    "conditions = [df_policy[\"response_answer\"].eq(\"Direct engagement with policy makers\") & df_policy[\"majority_position\"].eq(\"Support\"), \n",
    "              df_policy[\"response_answer\"].eq(\"Direct engagement with policy makers\") & df_policy[\"majority_position\"].eq(\"Oppose\"),\n",
    "              df_policy[\"response_answer\"].eq(\"Direct engagement with policy makers\") & df_policy[\"majority_position\"].eq(\"Undecided\"),\n",
    "              df_policy[\"response_answer\"].eq(\"Direct engagement with policy makers\") & df_policy[\"majority_position\"].eq(\"Neutral\"),\n",
    "              df_policy[\"response_answer\"].eq(\"Direct engagement with policy makers\") & df_policy[\"majority_position\"].eq(\"NaN\"),\n",
    "              df_policy[\"response_answer\"].eq(\"Direct engagement with policy makers\") & df_policy[\"majority_position\"].eq(\"Support with minor exceptions\"),\n",
    "              df_policy[\"response_answer\"].eq(\"Direct engagement with policy makers\") & df_policy[\"majority_position\"].eq(\"Support with major exceptions\"),\n",
    "              df_policy[\"response_answer\"].eq(\"Funding research organizations\") | df_policy[\"response_answer\"].eq(\"Trade associations\"),\n",
    "              df_policy[\"response_answer\"].eq(\"Other\"),\n",
    "              df_policy[\"response_answer\"].eq(\"No\")]\n",
    "\n",
    "choices = [5, 2, 2, 2, 2, 4, 3, 2, 2, 1]\n",
    "\n",
    "df_policy[\"policy_score\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "# choose max score for each entitiy in each year\n",
    "df_policy['policy_score'] = df_policy.groupby(['account_number', 'year'])['policy_score'].transform(np.max)\n",
    "\n",
    "# merge final policy score results to collaboration scoring dataframe\n",
    "cod_scores = pd.merge(left=cod_scores,\n",
    "                   right= df_policy[\"policy_score\"],\n",
    "                   left_on=cod_scores[\"select_key\"],\n",
    "                   right_on=df_policy[\"select_key\"],\n",
    "                   how=\"left\")\n",
    "cod_scores.drop_duplicates(inplace=True)\n",
    "\n",
    "# drop the unneccessary columns\n",
    "cod_scores.drop(\"key_0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Collaboration Scoring Table for Corporates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_scores.rename(columns={'value_chain_score': 'c_score_3', 'customer_score': 'c_score_4', 'supply_chain_score': 'c_score_5', 'policy_score': 'c_score_6'}, inplace=True)\n",
    "cod_scores.drop(\"select_key\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pkl_write: cod_scores.to_pickle(\"data/cod_scores.pkl\", protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.3 Conclusion\n",
    "<font color=orange size=4> **Kurze Zusammenfassung des Capitels.** </font>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through our exploration we have found out that...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Opportunities\n",
    "<font color=orange size=5> **David / überarbeiten.** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploration Content**: <br/>\n",
    "The analysis of risks is followed by an examination of opportunities from the perspective of cities and companies. We will examine where both sides see their individual opportunities, how high they rate them and where there are overlaps between the two sides' views.\n",
    "\n",
    "**Motivation Purpose**:<br/>\n",
    "The greatest motivation for cooperation arises when all participants benefit from it. It is therefore important to look not only at security but also at opportunities on all sides. \n",
    "From a communication point of view alone, it seems promising to pay special attention to the shared possibilities and opportunities. It could be way easier to convince partners to collaborate, if both sides see a change to benefit from collaboration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  6.4.1 Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe with relevant questions\n",
    "df = get_response_pivot(data=cir, questionnumber=\"6.0\", columnnumber=\"all\", pivot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows and get responses from dataframe\n",
    "data = df.query('column_number == 1')\n",
    "answers = data.response_answer     # get responses from data frame\n",
    "\n",
    "# provide corrosponding question context\n",
    "print_question(data, \"6.0\",[1]) \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "val, perc = get_pct_freq(answers)\n",
    "top = perc.nlargest(25)\n",
    "\n",
    "# Create plotting grid\n",
    "fig, ax_b1, ax_s1, ax_s2, ax_s3 = create_3x3grid(size=(20,10), orient=\"vertical\")\n",
    "\n",
    "# Configure main plot\n",
    "ax_b1 = plot_freq_of_cv(data=top, xlabel=\"Frequency %\", ylabel=\"Opportunity type\",\n",
    "                        title=\"Cities Opportunities to address climate change\", orient=\"h\", ax=ax_b1)\n",
    "\n",
    "add_patches(ax_b1, orient=\"h\")\n",
    "# Calculate basic plots\n",
    "ax_s1 = plot_small_no_responses(data, ax=ax_s1)\n",
    "ax_s2 = plot_small_responses_yoy(data, ax=ax_s2, plt_type=\"perc\");\n",
    "ax_s3 = plot_small_responses_per_ptcp(data, ax=ax_s3)\n",
    "\n",
    "plt.tight_layout();\n",
    "plt.show();\n",
    "print(\"Number responses:\" + str(len(data)))\n",
    "print(\"Answers reflected by plot: \"+str(top.sum())+\"%\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The possibilities identified by cities for addressing climate change are manifold and can be roughly divided into \"concrete measures\" and \"general conditions\". It is noticeable that a great many possibilities concern the area of \"technology development\". Support in this area could certainly be of interest to companies and help them to develop new business models and products.\n",
    "\n",
    "As usual, the focus of public innovation efforts is on encouraging cooperation and providing funding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corporates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe with relevant questions\n",
    "df = get_response_pivot(data=cor, questionnumber=\"C2.4\", columnnumber=\"all\", pivot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows and get responses from dataframe\n",
    "data = df\n",
    "answers = data.response_answer     # get responses from data frame\n",
    "\n",
    "# provide corrosponding question context\n",
    "print_question(df, \"2.4\",[0]) \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "val, perc = get_pct_freq(answers)\n",
    "\n",
    "# Create plotting grid\n",
    "fig, ax_b1, ax_s1, ax_s2, ax_s3 = create_3x3grid(size=(15,10), orient=\"vertical\")\n",
    "\n",
    "# Configure main plot\n",
    "ax_b1 = plot_freq_of_cv(data=perc, xlabel=\"Answer\", ylabel=\"Response\",\n",
    "                        title=\"Corporates identified opportunities\", orient=\"v\", ax=ax_b1)\n",
    "\n",
    "add_patches(ax_b1, orient=\"v\")\n",
    "\n",
    "# Calculate basic plots\n",
    "ax_s1 = plot_small_no_responses(data, ax=ax_s1)\n",
    "ax_s2 = plot_small_responses_yoy(data, ax=ax_s2, plt_type=\"perc\");\n",
    "ax_s3 = plot_small_responses_per_ptcp(data, ax=ax_s3)\n",
    "\n",
    "plt.tight_layout();\n",
    "plt.show();\n",
    "print(\"Number responses:\" + str(len(data)))\n",
    "print(\"Answers reflected by plot: \"+str(top.sum())+\"%\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange size=3> **Description / Finding?** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe with relevant questions\n",
    "df = get_response_pivot(data=cor, questionnumber=\"C2.4a\", columnnumber=\"all\", pivot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows and get responses from dataframe\n",
    "data = df.query('column_number == 3')\n",
    "answers = data.response_answer     # get responses from data frame\n",
    "\n",
    "# provide corrosponding question context\n",
    "print_question(data, \"2.4a\",[3]) \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "val, perc = get_pct_freq(answers)\n",
    "top = perc.nlargest(25)\n",
    "\n",
    "# Create plotting grid\n",
    "fig, ax_b1, ax_s1, ax_s2, ax_s3 = create_3x3grid(size=(15,10), orient=\"vertical\")\n",
    "\n",
    "# Configure main plot\n",
    "ax_b1 = plot_freq_of_cv(data=top, xlabel=\"Frequency %\", ylabel=\"Opportunity type\",\n",
    "                        title=\"Corporates Opportunity types\", orient=\"h\", ax=ax_b1)\n",
    "\n",
    "add_patches(ax_b1, orient=\"h\")\n",
    "# Calculate basic plots\n",
    "ax_s1 = plot_small_no_responses(data, ax=ax_s1)\n",
    "ax_s2 = plot_small_responses_yoy(data, ax=ax_s2, plt_type=\"perc\");\n",
    "ax_s3 = plot_small_responses_per_ptcp(data, ax=ax_s3)\n",
    "\n",
    "plt.tight_layout();\n",
    "plt.show();\n",
    "print(\"Number responses:\" + str(len(data)))\n",
    "print(\"Answers reflected by plot: \"+str(top.sum())+\"%\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange size=3> **Description / Finding?** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows and get responses from dataframe\n",
    "data = df.query('column_number == 4')\n",
    "answers = data.response_answer     # get responses from data frame\n",
    "\n",
    "# provide corrosponding question context\n",
    "print_question(data, \"2.4a\",[4]) \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "val, perc = get_pct_freq(answers)\n",
    "top = perc.nlargest(25)\n",
    "\n",
    "# Create plotting grid\n",
    "fig, ax_b1, ax_s1, ax_s2, ax_s3 = create_3x3grid(size=(20,10), orient=\"vertical\")\n",
    "\n",
    "# Configure main plot\n",
    "ax_b1 = plot_freq_of_cv(data=top, xlabel=\"Frequency %\", ylabel=\"Opportunity type\",\n",
    "                        title=\"Corporates Opportunity types\", orient=\"h\", ax=ax_b1)\n",
    "\n",
    "add_patches(ax_b1, orient=\"h\")\n",
    "# Calculate basic plots\n",
    "ax_s1 = plot_small_no_responses(data, ax=ax_s1)\n",
    "ax_s2 = plot_small_responses_yoy(data, ax=ax_s2, plt_type=\"perc\");\n",
    "ax_s3 = plot_small_responses_per_ptcp(data, ax=ax_s3)\n",
    "\n",
    "plt.tight_layout();\n",
    "plt.show();\n",
    "print(\"Number responses:\" + str(len(data)))\n",
    "print(\"Answers reflected by plot: \"+str(top.sum())+\"%\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not surprising that the company considers \"Products & Service\" as well as \"Resource Efficiency\" by a large majority as the areas with the most opportunities: Both have a direct impact on value creation and represent the core of companies. Accordingly, this is also where the sphere of influence is greatest and optimisation is most promising. It is striking that these categories very clearly correspond to the concerns identified by the cities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.2 Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will be five scores for companies that will provide a value to oportunity affairs within corporations.\n",
    "\n",
    "**o_score_1** will provide a value to the fact if the corporation has identified an climate related oportunity with an impact of the business. There will be five points if so. One point, if not. And zero points, for missing answers.\n",
    "\n",
    "**o_score_2** will provide a value to the number of oportunity types, that are identified by the corporation. Each one identified, will count as a point, with a maximum of five points and zero points for missing answers.\n",
    "\n",
    "**o_score_3** will provide a value to the time horizon seen by the corporation for the oportunity.\n",
    "\n",
    "There will be: \n",
    "\n",
    "- five points for current oportunities\n",
    "- four for short-term\n",
    "- three for medium term\n",
    "- two for longterm\n",
    "- one for unknown time horizons \n",
    "- and zero for missing answers.\n",
    "\n",
    "**o_score_4** will provide a value to the liklihood that sees the corporation for the oportunity.\n",
    "\n",
    "There will be:\n",
    "\n",
    "- five points for virtually certain\n",
    "- four points for very likely\n",
    "- three points for likely\n",
    "- two points for more likely than not\n",
    "- one point for other answers\n",
    "- and zero points for missings answers.\n",
    "\n",
    "**o_score_5** will provide a value to identified drivers of oportunities by the corporation. Each one identified, will count as a point, with a maximum of five points and zero points for missing answers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating o_scores\n",
    "\n",
    "#Creating scoring function for o_score_1\n",
    "def create_score(x):\n",
    "    if x == 'No':\n",
    "        return 1\n",
    "    elif x == 'Yes':\n",
    "        return 5\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "\n",
    "#Creating subset of cor dataframe and collecting relevant answers for o_score_1\n",
    "reduced = cor[(cor['question_number'] == 'C2.4') & (cor['theme'] == 'climate')]\n",
    "reduced[\"select_key\"] =reduced[\"year\"].astype(str)+\"_\"+reduced[\"account_number\"].astype(str)\n",
    "reduced = reduced[['select_key', 'response_answer']]\n",
    "\n",
    "#Calculating o_score_1\n",
    "reduced['response_answer'] = reduced[\"response_answer\"].apply(create_score) \n",
    "reduced_O1 = reduced\n",
    "\n",
    "#Collecting answers in separate dataframe\n",
    "reduced_O1.rename(columns={'response_answer':'o_score_1'}, inplace=True)\n",
    "reduced_O1.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#Creating scoring function for o_score_2\n",
    "def create_score(x):\n",
    "        if x == 1:\n",
    "            return 1\n",
    "        elif x == 2:\n",
    "            return 2\n",
    "        elif x == 3:\n",
    "            return 3\n",
    "        elif x == 4:\n",
    "            return 4\n",
    "        elif x >= 5:\n",
    "            return 5\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "\n",
    "#Creating subset of cor dataframe and collecting relevant answers for o_score_2\n",
    "reduced = cor[(cor['question_number'] == 'C2.4a') & (cor['column_number'] == 3) & (cor['theme'] == 'climate')]\n",
    "reduced[\"select_key\"] =reduced[\"year\"].astype(str)+\"_\"+reduced[\"account_number\"].astype(str)\n",
    "reduced = reduced[['select_key', 'response_answer']]\n",
    "\n",
    "#Counting answers\n",
    "reduced = reduced['select_key'].value_counts().to_frame()\n",
    "reduced['sum'] = reduced['select_key']\n",
    "reduced['select_key'] = reduced.index\n",
    "reduced.reset_index(inplace =True)\n",
    "reduced['o_score_2'] = reduced[\"sum\"].apply(create_score) \n",
    "\n",
    "#Collecting answers in separate dataframe\n",
    "reduced_O2 = reduced \n",
    "reduced_O2.reset_index(inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "#Creating scoring function for o_score_3\n",
    "def create_score(x):\n",
    "        if x == 'Short-term':\n",
    "            return 4\n",
    "        elif x == 'Medium-term':\n",
    "            return 3\n",
    "        elif x == 'Current':\n",
    "            return 5\n",
    "        elif x == 'Long-term':\n",
    "            return 2\n",
    "        elif x == 'Unknown':\n",
    "            return 1\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "\n",
    "#Creating subset of cor dataframe and collecting relevant answers for o_score_3\n",
    "reduced = cor[(cor['question_number'] == 'C2.4a') & (cor['column_number'] == 7) & (cor['theme'] == 'climate')]\n",
    "reduced[\"select_key\"] =reduced[\"year\"].astype(str)+\"_\"+reduced[\"account_number\"].astype(str)\n",
    "reduced = reduced[['select_key', 'response_answer']]\n",
    "\n",
    "#Calculating o_score_3\n",
    "reduced['response_answer'] = reduced[\"response_answer\"].apply(create_score) \n",
    "\n",
    "#Collecting answers in separate dataframe\n",
    "reduced_O3 = reduced\n",
    "reduced_O3.rename(columns={'response_answer':'o_score_3'}, inplace=True)\n",
    "reduced_O3.reset_index(inplace=True)\n",
    "\n",
    "#Calculating mean value for points for corporations with multiple answers\n",
    "reduced_O3 = reduced_O3.groupby('select_key')['o_score_3'].agg(['sum','count'])\n",
    "reduced_O3['o_score_3'] = reduced_O3['sum'] / reduced_O3['count']\n",
    "reduced_O3['o_score_3'] = reduced_O3.o_score_3.apply(round)\n",
    "reduced_O3['select_key'] = reduced_O3.index\n",
    "\n",
    "\n",
    "\n",
    "#Creating scoring function o_score_4\n",
    "def create_score(x):\n",
    "        if x == 'About as likely as not':\n",
    "            return 3\n",
    "        elif x == 'More likely than not':\n",
    "            return 3\n",
    "        elif x == 'Likely':\n",
    "            return 4\n",
    "        elif x == 'Very likely':\n",
    "            return 4\n",
    "        elif x >= 'Virtually certain':\n",
    "            return 5\n",
    "        elif x == 'Unlikely':\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "\n",
    "#Creating subset of cor dataframe and collecting relevant answers for o_score_4\n",
    "reduced = cor[(cor['question_number'] == 'C2.4a') & (cor['column_number'] == 8) & (cor['theme'] == 'climate')]\n",
    "reduced[\"select_key\"] =reduced[\"year\"].astype(str)+\"_\"+reduced[\"account_number\"].astype(str)\n",
    "reduced = reduced[['select_key', 'response_answer']]\n",
    "\n",
    "#Calculating o_score_4\n",
    "reduced['response_answer'] = reduced[\"response_answer\"].apply(create_score) \n",
    "\n",
    "#Collecting answers in separate dataframe\n",
    "reduced_O4 = reduced\n",
    "reduced_O4.rename(columns={'response_answer':'o_score_4'}, inplace=True)\n",
    "\n",
    "#Calculating mean value for points for corporations with multiple answers\n",
    "reduced_O4 = reduced_O4.groupby('select_key')['o_score_4'].agg(['sum','count'])\n",
    "reduced_O4['o_score_4'] = reduced_O4['sum'] / reduced_O4['count']\n",
    "reduced_O4['o_score_4'] = reduced_O4.o_score_4.apply(round)\n",
    "reduced_O4['select_key'] = reduced_O4.index\n",
    "\n",
    "\n",
    "\n",
    "#Creating scoring function for o_score_5\n",
    "def create_score(x):\n",
    "        if x == 1:\n",
    "            return 1\n",
    "        elif x == 2:\n",
    "            return 2\n",
    "        elif x == 3:\n",
    "            return 3\n",
    "        elif x == 4:\n",
    "            return 4\n",
    "        elif x >= 5:\n",
    "            return 5\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "\n",
    "#Creating subset of cor dataframe and collecting relevant answers for o_score_5\n",
    "reduced = cor[(cor['question_number'] == 'C2.4a') & (cor['column_number'] == 4) & (cor['theme'] == 'climate')]\n",
    "reduced[\"select_key\"] =reduced[\"year\"].astype(str)+\"_\"+reduced[\"account_number\"].astype(str)\n",
    "reduced = reduced[['select_key', 'response_answer']]\n",
    "\n",
    "#Counting answers\n",
    "reduced = reduced['select_key'].value_counts().to_frame()\n",
    "reduced['sum'] = reduced['select_key']\n",
    "reduced['select_key'] = reduced.index\n",
    "reduced.reset_index(inplace =True)\n",
    "\n",
    "#Collecting answers in separate dataframe\n",
    "reduced['o_score_5'] = reduced[\"sum\"].apply(create_score) \n",
    "reduced_O5 = reduced\n",
    "\n",
    "\n",
    "\n",
    "#Merging o_scores to one seperate dataframe o_score_co\n",
    "cod_red = cod[cod['theme'] == 'climate']\n",
    "cod_red[\"select_key\"] =cod_red[\"year\"].astype(str)+\"_\"+cod_red[\"account_number\"].astype(str)\n",
    "cod_red = cod_red[['select_key']]\n",
    "cod_red.set_index('select_key')\n",
    "o_score_co  =     pd.merge(left = cod_red,\n",
    "                     right = reduced_O1[['o_score_1']],\n",
    "                     left_on = cod_red['select_key'],\n",
    "                     right_on = reduced_O1['select_key'], \n",
    "                     how = 'left',\n",
    "                     copy = False)\n",
    "o_score_co = o_score_co[['select_key', 'o_score_1']]\n",
    "o_score_co   =     pd.merge(left = o_score_co,\n",
    "                     right = reduced_O2[['o_score_2']],\n",
    "                     left_on = o_score_co['select_key'],\n",
    "                     right_on = reduced_O2['select_key'], \n",
    "                     how = 'left',\n",
    "                     copy = False)\n",
    "o_score_co = o_score_co[['select_key', 'o_score_1', 'o_score_2']]\n",
    "o_score_co   =     pd.merge(left = o_score_co,\n",
    "                     right = reduced_O3[['o_score_3']],\n",
    "                     left_on = o_score_co['select_key'],\n",
    "                     right_on = reduced_O3['select_key'], \n",
    "                     how = 'left',\n",
    "                     copy = False)\n",
    "o_score_co = o_score_co[['select_key', 'o_score_1', 'o_score_2', 'o_score_3']]\n",
    "o_score_co   =     pd.merge(left = o_score_co,\n",
    "                     right = reduced_O4[['o_score_4']],\n",
    "                     left_on = o_score_co['select_key'],\n",
    "                     right_on = reduced_O4['select_key'], \n",
    "                     how = 'left',\n",
    "                     copy = False)\n",
    "o_score_co = o_score_co[['select_key', 'o_score_1', 'o_score_2', 'o_score_3', 'o_score_4']]\n",
    "o_score_co   =     pd.merge(left = o_score_co,\n",
    "                     right = reduced_O5[['o_score_5']],\n",
    "                     left_on = o_score_co['select_key'],\n",
    "                     right_on = reduced_O5['select_key'], \n",
    "                     how = 'left',\n",
    "                     copy = False)\n",
    "o_score_co = o_score_co[['select_key', 'o_score_1', 'o_score_2', 'o_score_3', 'o_score_4', 'o_score_5']]\n",
    "o_score_co.drop_duplicates(subset='select_key', keep='first', inplace = True)\n",
    "o_score_co.reset_index(inplace = True)\n",
    "o_score_co.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two scores that will provide a value to fact if the cities see oportunities and the fact if they dealt with possiblities to maximize these opportunities.\n",
    "\n",
    "**o_score_1** will give a value to seen opportunities in their respective areas.\n",
    "\n",
    "**o_score_2** will give a value to the fact if the cities dealt with possiblities on how to maximize these opportunities.\n",
    "\n",
    "For both scores, each answer will count as a point, with a maximum of five points. For missing answers it will count with zero points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating o_scores\n",
    "\n",
    "#Creating scoring function for o_score_1\n",
    "def create_score(x):\n",
    "        if x == 'No':\n",
    "            return 1\n",
    "        elif x == 'In progress':\n",
    "            return 3\n",
    "        elif x == 'Likely':\n",
    "            return 3\n",
    "        elif x == 'Yes':\n",
    "            return 5\n",
    "        elif x >= 'Not intending to undertake':\n",
    "            return 1\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "\n",
    "#Creating subset of cir dataframe and collecting relevant answers for o_score_1\n",
    "reduced = cir[(cir['question_number'] == '6.0') & (cir['column_number'] == 0)]\n",
    "reduced[\"select_key\"] =reduced[\"year\"].astype(str)+\"_\"+reduced[\"account_number\"].astype(str)\n",
    "reduced = reduced[['select_key', 'response_answer']]\n",
    "\n",
    "#Counting answers\n",
    "reduced['response_answer'] = reduced[\"response_answer\"].apply(create_score) \n",
    "\n",
    "#Collecting answers in separate dataframe\n",
    "reduced_O6 = reduced\n",
    "reduced_O6.rename(columns={'response_answer':'o_score_1'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#Creating scoring function for o_score_2\n",
    "def create_score(x):\n",
    "        if x == 1:\n",
    "            return 1\n",
    "        elif x == 2:\n",
    "            return 2\n",
    "        elif x == 3:\n",
    "            return 3\n",
    "        elif x == 4:\n",
    "            return 4\n",
    "        elif x >= 5:\n",
    "            return 5\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "        \n",
    "#Creating subset of cir dataframe and collecting relevant answers for o_score_1\n",
    "reduced = cir[(cir['question_number'] == '6.0') & (cir['column_number'] == 1)]\n",
    "reduced[\"select_key\"] =reduced[\"year\"].astype(str)+\"_\"+reduced[\"account_number\"].astype(str)\n",
    "reduced = reduced[['select_key', 'response_answer']]\n",
    "\n",
    "#Counting answers\n",
    "reduced = reduced['select_key'].value_counts().to_frame()\n",
    "reduced['sum'] = reduced['select_key']\n",
    "reduced['select_key'] = reduced.index\n",
    "reduced.reset_index(inplace =True)\n",
    "\n",
    "#Collecting answers in separate dataframe\n",
    "reduced['o_score_2'] = reduced[\"sum\"].apply(create_score) \n",
    "reduced_O7 = reduced\n",
    "\n",
    "\n",
    "#Merging o_scores to one seperate dataframe o_score_co\n",
    "cid_red = cid.copy()\n",
    "cid_red[\"select_key\"] =cid_red[\"year\"].astype(str)+\"_\"+cid_red[\"account_number\"].astype(str)\n",
    "cid_red = cid_red[['select_key']]\n",
    "o_score_ci  =     pd.merge(left = cid_red,\n",
    "                     right = reduced_O6[['o_score_1']],\n",
    "                     left_on = cid_red['select_key'],\n",
    "                     right_on = reduced_O6['select_key'], \n",
    "                     how = 'left')\n",
    "o_score_ci = o_score_ci[['select_key', 'o_score_1']]\n",
    "o_score_ci   =     pd.merge(left = o_score_ci,\n",
    "                     right = reduced_O7[['o_score_2']],\n",
    "                     left_on = o_score_ci['select_key'],\n",
    "                     right_on = reduced_O7['select_key'], \n",
    "                     how = 'left')\n",
    "o_score_ci = o_score_ci[['select_key', 'o_score_1', 'o_score_2']]\n",
    "o_score_ci.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.3 Conclusion\n",
    "<font color=orange size=4> **Kurze Zusammenfassung des Capitels.** </font>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through our exploration we have found out that...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Risks \n",
    "<font color=orange size=5> **David / überarbeiten** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploration Content**: <br/>\n",
    "In this section, we will examine how cities and businesses assess their individual risks from ongoing climate change. We will focus in particular on differences and similarities between cities and businesses.\n",
    "\n",
    "**Motivation Purpose**:<br/>\n",
    "In order to encourage collaboration between cities and businesses, it is helpful to make clear to those involved their common motivation. \n",
    "In order to understand relevant drivers of activities, it is important to understand the risk assessment of stakeholders. From this, conclusions and theses on risks can finally be drawn, which are particular important in the context of social justice. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.1 Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe with relevant questions\n",
    "df = get_response_pivot(data=cir, questionnumber=\"2.1\", columnnumber=\"all\", pivot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows and get responses from dataframe\n",
    "data = df.query('column_number == 1')\n",
    "answers = data.response_answer     # get responses from data frame\n",
    "\n",
    "# provide corrosponding question context\n",
    "print_question(data, \"2.1\",[1]) \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "val, perc = get_pct_freq(answers)\n",
    "                      \n",
    "# Create plotting grid\n",
    "fig, ax_b1, ax_s1, ax_s2, ax_s3 = create_3x3grid(size=(15,10), orient=\"vertical\")\n",
    "\n",
    "# Configure main plot\n",
    "ax_b1 = plot_freq_of_cv(data=perc, xlabel=\"Frequency\", ylabel=\"Climate Hazard\",\n",
    "                        title=\"Cities threatening Climate Hazards\", orient=\"h\", ax=ax_b1)\n",
    "\n",
    "add_patches(ax_b1, orient=\"h\")\n",
    "# Calculate basic plots\n",
    "ax_s1 = plot_small_no_responses(data, ax=ax_s1)\n",
    "ax_s2 = plot_small_responses_yoy(data, ax=ax_s2, plt_type=\"perc\");\n",
    "ax_s3 = plot_small_responses_per_ptcp(data, ax=ax_s3)\n",
    "\n",
    "plt.tight_layout();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_distribition_df(answers).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2019 and 2020 the CDP received more than 6.300 responses to the question, which kind of climate hazards cities are threatened by. At first glance the responses give an ambiguous result. The feedback is spread over 36 different answers, none of which accounts for more than 10.5% of the feedback. Therefor we are going to group the responses into categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Climate Change Risks for Cities by Category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows and get responses from dataframe\n",
    "data = df.query('column_number == 1')\n",
    "answers = data.response_answer.apply(lambda x: x.split(\">\")[0])     # get responses from data frame\n",
    "\n",
    "# provide corrosponding question context\n",
    "print_question(data, \"2.1\",[1]) \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "val, perc = get_pct_freq(answers)\n",
    "                      \n",
    "\n",
    "# Configure main plot\n",
    "ax = plot_pareto(data=perc, xlabel=\"Climate Hazard Category\", ylabel=\"% Responses\",\n",
    "                        title=\"Cities Climate Hazards by Category\", orient=\"v\")\n",
    "\n",
    "rotate_labels(fig=ax, axis=\"x\", rotation=75)\n",
    "add_patches(ax);\n",
    "val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With only ten categories remaining, the results are getting much clearer. More than 20% of the cities are afraid of flood and sea level rise, extreme precipitation and hot temperatures are also mentioned abore average. \n",
    "Of particular importance are the threats posed by extremely high temperatures, water scarcity and mass movement. It can be assumed that socially disadvantaged groups and poorer countries in particular are affected by these effects much more strongly and frequently than the world's strong industrialised nations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows and get responses from dataframe\n",
    "data = df.query('column_number == 2')\n",
    "answers = data.response_answer     # get responses from data frame\n",
    "\n",
    "gob = data.groupby([\"year\",\"response_answer\"]).count()\n",
    "gob = gob.iloc[:,0]\n",
    "gob_perc = gob.groupby(level=0).apply(lambda x:100 * x / float(x.sum()))\n",
    "gob_perc = round(gob_perc, 1)\n",
    "gob_perc = gob_perc.reset_index()\n",
    "\n",
    "# provide corrosponding question context\n",
    "print_question(data, \"2.1\",[2]) \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "val, perc = get_pct_freq(answers)\n",
    "                      \n",
    "\n",
    "# Configure main plot\n",
    "ax = sns.barplot(data=gob_perc, x=\"response_answer\", y=\"account_number\",hue = \"year\", orient=\"v\", palette=\"hls\") #xlabel=\"Frequency\", ylabel=\"Climate Hazard\",\n",
    "                      #  title=\"Cities threatining Climate Hazards\", orient=\"h\", ax=ax_b1)\n",
    "ax.set_xlabel(\"impact observed\",fontdict={\"fontsize\":rcParams[\"axes.labelsize\"]})\n",
    "ax.set_ylabel(\"% responses\", fontdict={\"fontsize\":rcParams[\"axes.labelsize\"]})\n",
    "ax.set_title(\"Presence of hazard impact on cities\", fontdict={\"fontsize\":rcParams[\"axes.titlesize\"], \"fontweight\":rcParams[\"axes.titleweight\"]})\n",
    "add_patches(ax)\n",
    "print(\"Number responses:\" + str(len(data)));\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This observation shows very clearly that a concrete threat to cities has long been a reality. Of the more than 5,000 hazards mentioned, 74% can no longer be considered as a theoretical risk, but have already had a concrete negative effect on the city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows and get responses from dataframe\n",
    "data = df\n",
    "\n",
    "# transform response-strings to categories\n",
    "df = data.copy()\n",
    "df.response_answer = df.response_answer.apply(lambda x: x.split(\">\")[0]) \n",
    "\n",
    "# create dataframe with responser to columns 1 and 5 next to each others\n",
    "comparison = compare_columns(data=df, questionnumber=\"2.1\", select_col=1, compare_col=2)\n",
    "comparison.rename(columns={\"column_1\":\"hazard_cat\", \"column_2\":\"impact_observed\"}, inplace=True)\n",
    "\n",
    "# group results by impact\n",
    "gob = comparison.groupby([\"hazard_cat\",\"impact_observed\"]).count()\n",
    "gob = gob.iloc[:,0]\n",
    "gob_perc = gob.groupby(level=0).apply(lambda x:100 * x / float(x.sum()))\n",
    "gob_perc = round(gob_perc, 1)\n",
    "gob_perc = gob_perc.reset_index()\n",
    " \n",
    "# provide corrosponding question context\n",
    "print_question(df, \"2.1\",[1, 2]) \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "val, perc = get_pct_freq(answers)\n",
    "                      \n",
    "\n",
    "# Configure main plot\n",
    "plt.figure(figsize=(12,6))\n",
    "ax = sns.barplot(data=gob_perc, x=\"hazard_cat\", y=\"select_key\",hue = \"impact_observed\", orient=\"v\", palette=\"hls\") #xlabel=\"Frequency\", ylabel=\"Climate Hazard\",\n",
    "                      #  title=\"Cities threatining Climate Hazards\", orient=\"h\", ax=ax_b1)\n",
    "ax.set_xlabel(\"Hazard category\",fontdict={\"fontsize\":rcParams[\"axes.labelsize\"]})\n",
    "ax.set_ylabel(\"% responses\", fontdict={\"fontsize\":rcParams[\"axes.labelsize\"]})\n",
    "ax.set_title(\"Impact observed per category\", fontdict={\"fontsize\":rcParams[\"axes.titlesize\"], \"fontweight\":rcParams[\"axes.titleweight\"]})\n",
    "\n",
    "add_patches(ax)\n",
    "rotate_labels(ax, \"x\", 45);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extreme weather conditions (precipitation, cold, heat) already had a negative impact on the participating city in over 80% of their entries. In comparison, biological hazards, chemical changes and wildlife have occurred significantly less frequently. In comparison to the threats mentioned above, these may be treated with lower priority."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corporates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_response_pivot(data=cor, questionnumber=\"C2.3\", pivot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows and get responses from dataframe\n",
    "data = df\n",
    "answers = data.response_answer     # get responses from data frame\n",
    "\n",
    "# provide corrosponding question context\n",
    "print_question(data, \"C2.3\", [0]) \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "val, perc = get_pct_freq(answers)\n",
    "                      \n",
    "# Create plotting grid\n",
    "fig, ax_b1, ax_s1, ax_s2, ax_s3 = create_3x3grid(size=(15,10), orient=\"vertical\")\n",
    "\n",
    "# Configure main plot\n",
    "ax_b1 = plot_freq_of_cv(data=perc, xlabel=\"Answer\", ylabel=\"% responses\",\n",
    "                        title=\"Corporates identified climate risks\", orient=\"v\", ax=ax_b1)\n",
    "\n",
    "\n",
    "add_patches(ax_b1)\n",
    "# Calculate basic plots\n",
    "ax_s1 = plot_small_no_responses(data, ax=ax_s1)\n",
    "ax_s2 = plot_small_responses_yoy(data, ax=ax_s2, plt_type=\"perc\");\n",
    "ax_s3 = plot_small_responses_per_ptcp(data, ax=ax_s3)\n",
    "\n",
    "plt.tight_layout();\n",
    "plt.show();\n",
    "\n",
    "print(\"Number responses:\" + str(len(data)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In more than 2,500 surveys (between 2018 and 2020), 67% of companies stated that they had identified climate-related risks with substantial financial or strategic influence. From this we can conclude that companies also feel threatened and are likely to show willingness to change and cooperate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_response_pivot(data=cor, questionnumber=\"C2.3a\", pivot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows and get responses from dataframe\n",
    "data = df.query(\"column_number == 3 & column_name == 'C2.3a_c3-Risk type'\")\n",
    "answers = data.response_answer     # get responses from data frame\n",
    "\n",
    "# provide corrosponding question context\n",
    "print_question(data, \"C2.3a\", [3]) \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "val, perc = get_pct_freq(answers)\n",
    "top = perc.nlargest(20)\n",
    "\n",
    "                      \n",
    "# Create plotting grid\n",
    "fig, ax_b1, ax_s1, ax_s2, ax_s3 = create_3x3grid(size=(20,10), orient=\"horizontal\")\n",
    "\n",
    "# Configure main plot\n",
    "ax_b1 = plot_freq_of_cv(data=top, xlabel=\"Answer\", ylabel=\"% responses\",\n",
    "                        title=\"Risk type\", orient=\"h\", ax=ax_b1)\n",
    "\n",
    "add_patches(ax_b1, \"h\")\n",
    "\n",
    "# Calculate basic plots\n",
    "ax_s1 = plot_small_no_responses(data, ax=ax_s1)\n",
    "ax_s2 = plot_small_responses_yoy(data, ax=ax_s2, plt_type=\"perc\");\n",
    "ax_s3 = plot_small_responses_per_ptcp(data, ax=ax_s3)\n",
    "\n",
    "plt.tight_layout();\n",
    "plt.show();\n",
    "print(\"Number responses:\" + str(len(data)))\n",
    "print(\"Answers reflected by plot: \"+str(top.sum())+\"%\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "59 % of the corporates risks are related to the effects of big econimical shifts, while 41 % refer to actual physical damage. We'll explore the meaning of these categories further below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows and get responses from dataframe\n",
    "data = df.query(\"column_number == 3 & column_name == 'C2.3a_c3-Risk type & Primary climate-related risk driver_G'\")\n",
    "answers = data.response_answer     # get responses from data frame\n",
    "\n",
    "# provide corrosponding question context\n",
    "print_question(data, \"C2.3a\", [3]) \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "val, perc = get_pct_freq(answers)\n",
    "top = perc.nlargest(20)\n",
    "\n",
    "                      \n",
    "\n",
    "\n",
    "# Configure main plot\n",
    "ax_b1 = plot_freq_of_cv(data=top, xlabel=\"Answer\", ylabel=\"% responses\",\n",
    "                        title=\"Risk driver group\", orient=\"h\")\n",
    "add_patches(ax_b1, \"h\")\n",
    "\n",
    "plt.tight_layout();\n",
    "plt.show();\n",
    "print(\"Number responses:\" + str(len(data)))\n",
    "print(\"Answers reflected by plot: \"+str(top.sum())+\"%\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four pillars characterise the risk profile of companies: Physical damage, emerging regulation, market risks and technology. While cities and companies paint a similar picture in terms of concerns about physical damage and unfavourable technological development, companies' concerns about regulation and market changes partly conflict with the objectives of socially responsible climate protection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows and get responses from dataframe\n",
    "data = df.query(\"column_number == 3 & column_name == 'C2.3a_c3-Risk type & Primary climate-related risk driver'\")\n",
    "answers = data.response_answer     # get responses from data frame\n",
    "\n",
    "# provide corrosponding question context\n",
    "print_question(data, \"C2.3a\", [3]) \n",
    "\n",
    "# preprocess / calculate data for visualization\n",
    "val, perc = get_pct_freq(answers)\n",
    "top = perc.nlargest(20)\n",
    "\n",
    "\n",
    "# Configure main plot\n",
    "plt.figure(figsize=(8,6))\n",
    "ax_b1 = plot_freq_of_cv(data=top, xlabel=\"% responses\", ylabel=\"answers\",\n",
    "                        title=\"Corporates risk drivers\", orient=\"h\")\n",
    "\n",
    "\n",
    "\n",
    "plt.show();\n",
    "print(\"Number responses:\" + str(len(data)))\n",
    "print(\"Answers reflected by plot: \"+str(top.sum())+\"%\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focusing on the top 20 responses (reflecting 93% of al answers to this question) it shows up clearly that companies are most afraid of the effect of extreme weather events, just like the cities. They are also afraid of new climate-related regulatory mechanisms, including those relating to carbon emissions. While this view of the companies opposes collaborative behaviour, other aspects are likely to encourage it:\n",
    "As many companies fear climate-related changes in consumer behaviour, close cooperation with external stakeholders will become increasingly important for the success of companies in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.2 Scoring "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to classify the risk perspective of cities and companies in a relatively comparable way, we transfer the answers to selected survey questions into a risk scoring. The general idea of the score methodology can be interpreted as follows:\n",
    "\n",
    "- 1: entity is not threatened by climate related hazards\n",
    "- 2: entity is only slightly affected by climate related hazards\n",
    "- 3: entity is affected on average by climate related hazards\n",
    "- 4: entity is disproportionately affected by climate related hazards\n",
    "- 5: entity is strongly threatend by climate related hazards\n",
    "\n",
    "- 0/NaN: entity provides not enough utilizable data for scoring\n",
    "\n",
    "Due to the great heterogeneity of the questions and answers, the specific scoring components deviate slightly from this basic logic with regard to the concrete individual questions.\n",
    "\n",
    "In the following section we will look on these scoring criteria more specifically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating initial dataframe for city and corporate scores:\n",
    "cis = pd.DataFrame(columns=[\"account_number\", \"year\"]) #city scores\n",
    "cos = pd.DataFrame(columns=[\"account_number\", \"year\"]) #corporate scores\n",
    "\n",
    "# create dataframe with score explanation\n",
    "sex = pd.DataFrame(columns=[\"type\", \"score_name\", \"score_question\", \"score_explanation\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cities**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**r_score_1**<br/>\n",
    "Number of climate hazards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cir.copy()\n",
    "e_type = \"cis\"\n",
    "score = \"r_score_1\"\n",
    "base_question = \"2.1\"\n",
    "base_column = 1\n",
    "\n",
    "# select rows and get responses from dataframe\n",
    "data = df.query('question_number == @base_question & column_number == @base_column')\n",
    "\n",
    "# provide corrosponding question context\n",
    "q_string = print_question(data, base_question, [base_column]) \n",
    "\n",
    "# calculate scoring\n",
    "gob = data.groupby([\"account_number\", \"year\"], as_index=False)[\"response_answer\"].count()\n",
    "gob[score] = (pd.cut(gob.response_answer, bins=[0, 2, 5, 8, 15, 99], labels=[1, 2, 3, 4, 5])).astype(int)\n",
    "gob = gob.loc[:,[\"account_number\", \"year\", score]]\n",
    "\n",
    "# # add score to dataframe\n",
    "cis = pd.merge(left=cis, right=gob, on=[\"account_number\", \"year\"], how=\"outer\")\n",
    "\n",
    "# add explanation to dataframe\n",
    "question = pd.Series(data=[\n",
    "                        e_type, \n",
    "                        score, \n",
    "                        q_string,\n",
    "                        \"1: less than 2 two hazards, 2: less than 5, 3: less than 8, 4: less than 15, 5: more than 15 hazards\"],\n",
    "                    index=sex.columns)\n",
    "sex = sex.append(question, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of identified climate hazards of can be taken as a first indicator of the current risk label. Therefor we divide the counts of the cities hazards into 5 scoring bins with the following properties:\n",
    "- 1: less than 2 hazards\n",
    "- 2: less than 5 hazards\n",
    "- 3: less than 8 hazards\n",
    "- 4: less than 15 hazards\n",
    "- 5: more than 15 hazards\n",
    "The bin number matches the score value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**r_score_2** <br/>\n",
    "climate hazards with significant impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cir.copy()\n",
    "e_type = \"cis\"\n",
    "score = \"r_score_2\"\n",
    "base_question = \"2.1\"\n",
    "base_column = 2\n",
    "\n",
    "# select rows and get responses from dataframe\n",
    "data = df.query('question_number == @base_question & column_number == @base_column & response_answer == \"Yes\"')\n",
    "\n",
    "# provide corrosponding question context\n",
    "q_string = print_question(data, base_question, [base_column]) \n",
    "\n",
    "# calculate scoring\n",
    "gob = data.groupby([\"account_number\", \"year\"], as_index=False)[\"response_answer\"].count()\n",
    "gob[score] = (pd.cut(gob.response_answer, bins=[0, 1, 2, 4, 7, 99], labels=[1, 2, 3, 4, 5])).astype(int)\n",
    "gob = gob.loc[:,[\"account_number\", \"year\", score]]\n",
    "\n",
    "# # add score to dataframe\n",
    "cis = pd.merge(left=cis, right=gob, on=[\"account_number\", \"year\"], how=\"outer\")\n",
    "\n",
    "# add explanation to dataframe\n",
    "question = pd.Series(data=[\n",
    "                        e_type, \n",
    "                        score, \n",
    "                        q_string,\n",
    "                        \"1: less than 1 two hazards, 2: less than 2, 3: less than 4, 4: less than 7, 5: more than 7 hazards\"],\n",
    "                    index=sex.columns)\n",
    "sex = sex.append(question, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methodoly for r_score_2 follows exactly the r_score_1 scheme. As we are talking about hazards that already have an impact on the city, we set the bin threshold much lower:\n",
    "- 1: less than 1 hazards\n",
    "- 2: less than 2 hazards\n",
    "- 3: less than 4 hazards\n",
    "- 4: less than 7 hazards\n",
    "- 5: more than 7 hazards\n",
    "The bin number matches the score value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**r_score_3** <br/>\n",
    "climate hazards current probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cir.copy()\n",
    "e_type = \"cis\"\n",
    "score = \"r_score_3\"\n",
    "base_question = \"2.1\"\n",
    "base_column = 3\n",
    "\n",
    "# select rows and get responses from dataframe\n",
    "data = df.copy().query('question_number == @base_question & column_number == @base_column & response_answer !=\"Do not know\"')\n",
    "\n",
    "# provide corrosponding question context\n",
    "q_string = print_question(data, base_question, [base_column]) \n",
    "\n",
    "# map text responses to values\n",
    "response_map = {\n",
    "    \"Does not currently impact the city\": 1,\n",
    "    \"Low\": 1,\n",
    "    \"Medium Low\": 2,\n",
    "    \"Medium\": 3,\n",
    "    \"Medium High\": 4,\n",
    "    \"High\": 5\n",
    "               }\n",
    "\n",
    "data[\"calc_column\"] = data.response_answer.map(response_map)\n",
    "\n",
    "# calculate scoring\n",
    "gob = data.groupby([\"account_number\", \"year\"], as_index=False)[\"calc_column\"].mean()\n",
    "gob[score] = (pd.cut(gob.calc_column, bins=5, labels=[1, 2, 3, 4, 5])).astype(int)\n",
    "gob = gob.loc[:,[\"account_number\", \"year\", score]]\n",
    "\n",
    "# # add score to dataframe\n",
    "cis = pd.merge(left=cis, right=gob, on=[\"account_number\", \"year\"], how=\"outer\")\n",
    "\n",
    "# add explanation to dataframe\n",
    "question = pd.Series(data=[\n",
    "                        e_type, \n",
    "                        score, \n",
    "                        q_string,\n",
    "                        \"\"\"mapped values for every single risk from 1 to 5 and calculated avg. \n",
    "                        risk propability per entity. 1: propability for the entity belongs to \n",
    "                        the lowest 20% of all entities...\n",
    "                        5: belongs to highest 20%\"\"\"\n",
    "                            ],\n",
    "                    index=sex.columns)\n",
    "sex = sex.append(question, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To transform the current probability into a numeric score we first of all translate the responses into corrosponding calculation scores for every single risk:\n",
    "    \"Does not currently impact the city\": 1,\n",
    "    \"Low\": 1,\n",
    "    \"Medium Low\": 2,\n",
    "    \"Medium\": 3,\n",
    "    \"Medium High\": 4,\n",
    "    \"High\": 5\n",
    "    \n",
    "The overall score calulcation per entity follows these values and calculates the mean risk probability. To receive the final score per entitiy, the means are grouped into 5 quintiles, representing the lowest 20% up to the highest 20% average per entity:\n",
    "- 1: average risk propability for the entity belongs to the lowest 20% of all entities\n",
    "<br/>..\n",
    "- 5: average risk propability for the entity belongs to the highest 20% of all entities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**r_score_4** <br/>\n",
    "climate hazards current magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cir.copy()\n",
    "e_type = \"cis\"\n",
    "score = \"r_score_4\"\n",
    "base_question = \"2.1\"\n",
    "base_column = 4\n",
    "\n",
    "# select rows and get responses from dataframe\n",
    "data = df.copy().query('question_number == @base_question & column_number == @base_column & response_answer !=\"Do not know\"')\n",
    "\n",
    "# provide corrosponding question context\n",
    "q_string = print_question(data, base_question, [base_column]) \n",
    "\n",
    "# map text responses to values\n",
    "response_map = {\n",
    "    \"Does not currently impact the city\": 1,\n",
    "    \"Low\": 1,\n",
    "    \"Medium Low\": 2,\n",
    "    \"Medium\": 3,\n",
    "    \"Medium High\": 4,\n",
    "    \"High\": 5\n",
    "               }\n",
    "\n",
    "data[\"calc_column\"] = data.response_answer.map(response_map)\n",
    "\n",
    "# calculate scoring\n",
    "gob = data.groupby([\"account_number\", \"year\"], as_index=False)[\"calc_column\"].mean()\n",
    "gob[score] = (pd.cut(gob.calc_column, bins=5, labels=[1, 2, 3, 4, 5])).astype(int)\n",
    "gob = gob.loc[:,[\"account_number\", \"year\", score]]\n",
    "\n",
    "# # add score to dataframe\n",
    "cis = pd.merge(left=cis, right=gob, on=[\"account_number\", \"year\"], how=\"outer\")\n",
    "\n",
    "# add explanation to dataframe\n",
    "question = pd.Series(data=[\n",
    "                        e_type, \n",
    "                        score, \n",
    "                        q_string,\n",
    "                        \"\"\"mapped values for every single risk from 1 to 5 and calculated avg. \n",
    "                        risk magnitude per entity. 1: magnitude for the entity belongs to \n",
    "                        the lowest 20% of all entities...\n",
    "                        5: belongs to highest 20%\"\"\"\n",
    "                            ],\n",
    "                    index=sex.columns)\n",
    "sex = sex.append(question, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation of the magnitude scores follows exactly the methodoly for r_score_3 (see above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate total score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cis.loc[:,[\"r_score_1\", \"r_score_2\", \"r_score_3\", \"r_score_4\"]]\n",
    "cis[\"r_score_total\"] = scores.mean(axis=1, skipna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corporates**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**r_score_1**<br/>\n",
    "Inherent climate related risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cor.copy()\n",
    "e_type = \"cos\"\n",
    "score = \"r_score_1\"\n",
    "base_question = \"C2.3\"\n",
    "base_column = 0\n",
    "\n",
    "# select rows and get responses from dataframe\n",
    "data = df.copy().query('question_number == @base_question & column_number == @base_column')\n",
    "\n",
    "# provide corrosponding question context\n",
    "q_string = print_question(data, base_question, [base_column]) \n",
    "\n",
    "# map text responses to values\n",
    "response_map = {\"No\": 1, \"Yes\" : 5}\n",
    "\n",
    "data[score] = data.response_answer.map(response_map)\n",
    "\n",
    "# calculate scoring\n",
    "gob = data.groupby([\"account_number\", \"year\"], as_index=False)[score].sum()\n",
    "gob = gob.loc[:,[\"account_number\", \"year\", score]]\n",
    "\n",
    "# add score to dataframe\n",
    "cos = pd.merge(left=cos, right=gob, on=[\"account_number\", \"year\"], how=\"outer\")\n",
    "\n",
    "# add explanation to dataframe\n",
    "question = pd.Series(data=[\n",
    "                        e_type, \n",
    "                        score, \n",
    "                        q_string,\n",
    "                        \"1: no inherent risk, 5: inherent risk identified\"],\n",
    "                    index=sex.columns)\n",
    "sex = sex.append(question, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the scoring is based on a boolean-structured questions, we simply mapped the answers Yes and No to score values:\n",
    "- 1: No, no inherent risk identified\n",
    "- 5: Yes, inherent risk identified\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**r_score_2**<br/>\n",
    "Risk Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cor.copy()\n",
    "e_type = \"cos\"\n",
    "score = \"r_score_2\"\n",
    "base_question = \"C2.3a\"\n",
    "base_column = 3\n",
    "\n",
    "# select rows and get responses from dataframe\n",
    "data = df.copy().query('question_number == @base_question & column_number == @base_column & column_name == \"C2.3a_c3-Risk type & Primary climate-related risk driver_G\"')\n",
    "\n",
    "# provide corrosponding question context\n",
    "q_string = print_question(data, base_question, [base_column]) \n",
    "\n",
    "# map text responses to values\n",
    "response_map = {\n",
    "    'Emerging regulation' : 1, \n",
    "    'Reputation' :1, \n",
    "    'Acute physical' : 5,\n",
    "    'Technology': 3, \n",
    "    'Market' : 1, \n",
    "    'Chronic physical' : 4, \n",
    "    'Current regulation' : 2,\n",
    "    'Legal':1\n",
    "    }\n",
    "\n",
    "data[\"calc_column\"] = data.response_answer.map(response_map)\n",
    "\n",
    "# calculate scoring\n",
    "gob = data.groupby([\"account_number\", \"year\"], as_index=False)[\"calc_column\"].mean()\n",
    "gob[score] = (pd.cut(gob.calc_column, bins=5, labels=[1, 2, 3, 4, 5])).astype(int)\n",
    "gob = gob.loc[:,[\"account_number\", \"year\", score]]\n",
    "\n",
    "# add score to dataframe\n",
    "cos = pd.merge(left=cos, right=gob, on=[\"account_number\", \"year\"], how=\"outer\")\n",
    "\n",
    "# add explanation to dataframe\n",
    "question = pd.Series(data=[\n",
    "                        e_type, \n",
    "                        score, \n",
    "                        q_string,\n",
    "                        \"\"\"mapped values for every single risk from 1 to 5 and calculated avg. \n",
    "                        risk propability per entity. 1: propability for the entity belongs to \n",
    "                        the lowest 20% of all entities...\n",
    "                        5: belongs to highest 20%\"\"\"\n",
    "                            ],\n",
    "                    index=sex.columns)\n",
    "sex = sex.append(question, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on every single identified risk position of a company, we assigned scoring values to the responses. The main factor for the single score is physical threat a risk provides. Therefor physical threats score high, while e.g. regulational threads score low:    \n",
    "'Emerging regulation' : 1, \n",
    "    'Reputation' :1, \n",
    "    'Acute physical' : 5,\n",
    "    'Technology': 3, \n",
    "    'Market' : 1, \n",
    "    'Chronic physical' : 4, \n",
    "    'Current regulation' : 2,\n",
    "    'Legal':1\n",
    "    \n",
    "The overall score calulcation per entity follows these values and calculates the mean risk scoring. To receive the final score per entitiy, the means are grouped into 5 quintiles, representing the lowest 20% up to the highest 20% average per entity:\n",
    "\n",
    "1: average risk score for the entity belongs to the lowest 20% of all entities\n",
    "..\n",
    "5: average risk score for the entity belongs to the highest 20% of all entities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**r_score_3**<br/>\n",
    "Transitional / physical risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cor.copy()\n",
    "e_type = \"cos\"\n",
    "score = \"r_score_3\"\n",
    "base_question = \"C2.3a\"\n",
    "base_column = 3\n",
    "\n",
    "# select rows and get responses from dataframe\n",
    "data = df.copy().query('question_number == @base_question & column_number == @base_column & column_name == \"C2.3a_c3-Risk type\"')\n",
    "\n",
    "# provide corrosponding question context\n",
    "q_string = print_question(data, base_question, [base_column]) \n",
    "\n",
    "# map text responses to values\n",
    "response_map = {\"Transition risk\": 0, \"Physical risk\" : 1}\n",
    "\n",
    "data[\"calc_column\"] = data.response_answer.map(response_map)\n",
    "\n",
    "# calculate scoring\n",
    "gob = data.groupby([\"account_number\", \"year\"], as_index=False)[\"calc_column\"].mean()\n",
    "gob[score] = (pd.cut(gob.calc_column, bins=5, labels=[1, 2, 3, 4, 5])).astype(int)\n",
    "gob = gob.loc[:,[\"account_number\", \"year\", score]]\n",
    "\n",
    "# add score to dataframe\n",
    "cos = pd.merge(left=cos, right=gob, on=[\"account_number\", \"year\"], how=\"outer\")\n",
    "\n",
    "# add explanation to dataframe\n",
    "question = pd.Series(data=[\n",
    "                        e_type, \n",
    "                        score, \n",
    "                        q_string,\n",
    "                         \"\"\"mapped values {\"Transition risk\": 0, \"Physical risk\" : 1} \n",
    "                         for every single risk and calculated avg. The closer to 1 the higher the risk.\n",
    "                         Split risk-avg into 5 bins, representing 20% slices of all values.\n",
    "                        1: physical risk for the entity belongs to \n",
    "                        the lowest 20% of all entities...\n",
    "                        5: belongs to highest 20%\"\"\"],\n",
    "                    index=sex.columns)\n",
    "sex = sex.append(question, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated before physical risks are of higher importance the transitional risks. Therefor we assigned the following score-values:\n",
    "- 0: transitional risk\n",
    "- 1: physical risk\n",
    "\n",
    "After weighting all the entries we build the average for entity / year and group the means into 5 quintiles, representing the lowest 20% up to the highest 20% average per entity:\n",
    "\n",
    "1: physical risk component for the entity belongs to the lowest 20% of all entities <br/>\n",
    ".. \n",
    "5: physical risk component for the entity belongs to the highest 20% of all entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate total score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cos.loc[:,[\"r_score_1\", \"r_score_2\", \"r_score_3\"]]\n",
    "cos[\"r_score_total\"] = scores.mean(axis=1, skipna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.3 Conclusion\n",
    "<font color=orange size=4> **Kurze Zusammenfassung des Capitels.** </font>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Engagement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploration Content**:<br/>\n",
    "At this point, we look at various questions that provide information on the extent to which cities and companies are addressing the issue of sustainability in terms of both quality and quantity. In other words, we determine the extent of their commitment to environmental protection.\n",
    "\n",
    "\n",
    "**Motivation Purpose**:<br/>\n",
    "We want to create a scoring base on the basis of which we can use the dashboard evaluations to find out whether there are significant regional or industry-specific differences (deficits/development potential) and show their dependence on the other parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.1 Exploration (Cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0 Does your city incorporate sustainability goals and targets into the master planning? (Cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0 Col-0 (A)\n",
    "# Erkunden der Datenlage\n",
    "df_grp = get_response_pivot(cir, '1.0', columnnumber='all', pivot=False, add_info=True, year=['2019','2020'])\n",
    "df_grp[['account_number','entity','year','response_answer']]\n",
    "# In 2018 ist es die Frage 1.4!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0 Col-0 (A)\n",
    "sql_statement = \"\"\"\n",
    "(\n",
    "SELECT\n",
    "`account_number`\n",
    ",`entity`\n",
    ",`year`\n",
    ",`response_answer`\n",
    ",count(*) as count\n",
    "FROM `cir`\n",
    "WHERE 1\n",
    "AND `theme` = 'combined'\n",
    "AND `year` in ('2019','2020')\n",
    "AND `question_number` = '1.0'\n",
    "AND `column_number` = 0\n",
    "GROUP BY\n",
    "`account_number`\n",
    ",`entity`\n",
    ",`year`\n",
    ",`response_answer`\n",
    "ORDER BY\n",
    "count DESC\n",
    ",`account_number` ASC\n",
    ",`year` ASC\n",
    ")\n",
    "UNION\n",
    "(\n",
    "SELECT\n",
    "`account_number`\n",
    ",`entity`\n",
    ",`year`\n",
    ",`response_answer`\n",
    ",count(*) as count\n",
    "FROM `cir`\n",
    "WHERE 1\n",
    "AND `theme` = 'combined'\n",
    "AND `year` in ('2018')\n",
    "AND `question_number` = '1.4'\n",
    "AND `column_number` = 0\n",
    "GROUP BY\n",
    "`account_number`\n",
    ",`entity`\n",
    ",`year`\n",
    ",`response_answer`\n",
    "ORDER BY\n",
    "count DESC\n",
    ",`account_number` ASC\n",
    ",`year` ASC\n",
    ")\n",
    "\"\"\"\n",
    "#sql_to_db(sql_statement)\n",
    "cir_0100_sql = sql_pickle('cir_0100_sql', sql_statement)\n",
    "#cir_0100_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aus wie vielen verschiedenen Städten stammen die Daten?\n",
    "print(cir_0100_sql['account_number'].unique().shape)\n",
    "\n",
    "# Reduktion und Umbenennung auf benötigte Daten:\n",
    "cir_0100_sql = cir_0100_sql[['account_number','year','response_answer']]\n",
    "cir_0100_sql.rename(columns={'response_answer': '10_goals_targets'}, inplace=True)\n",
    "cir_0100_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0 Col-0 (B)\n",
    "# Wir sichern unsere Erkenntnisse für spätere KPI-Entwicklung:\n",
    "cid_enh = pd.merge(left = cid_enh, right = cir_0100_sql, on = (\"account_number\",\"year\"), how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0 Col-0 (C)\n",
    "plotdata = cid_enh['10_goals_targets'].value_counts()\n",
    "ax = plotdata.plot.bar(x='index', y='10_goals_targets')\n",
    "plt.xticks(rotation=85)\n",
    "plt.title(\"Sustainability goals and targets in the master planning?\",{'fontsize': 20});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusätzliche Plot-Versuche:\n",
    "\n",
    "# 1.0 Col-0 (C)\n",
    "plotdata = cid_enh[['account_number','year','10_goals_targets']] #,'e_score_1']].sort_values(by=['e_score_1','10_goals_targets'], ascending=[False,False])\n",
    "\n",
    "fig = px.histogram(\n",
    "    plotdata\n",
    "    ,x='10_goals_targets'\n",
    "    #,text='10_goals_targets'\n",
    "    ,color='year'\n",
    "    ,labels={'count':'Nennungen','10_goals_targets':''}\n",
    "    ,barmode='group'\n",
    "    ,title=\"Sustainability goals and targets in the master planning?\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    showlegend=True\n",
    "    ,plot_bgcolor='white'\n",
    "    ,xaxis_tickangle=-60\n",
    "    ,autosize=True\n",
    "    ,margin=dict(\n",
    "        autoexpand=False,\n",
    "        l=100,\n",
    "        r=100,\n",
    "        t=110,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that 70% of the participants already have corresponding goals in their current annual plans. A further 19% are in the process or plan to implement them within the next 2 years. Only about 11% of the participants do not want to take this step at all or only later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0a Top 10 Targets (Cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grp = get_response_pivot(cir, '1.0a', columnnumber='all', pivot=False, add_info=False, year=['2019','2020'])\n",
    "df_grp[['year', 'account_number','column_number','column_name','response_answer']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevate Frage: cir 1.0a: Please detail which goals and targets are incorporated in your city’s master plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antworten auf Basis der Daten (Pro Account und Jahr dürfte es (in der Regel) nur eine Nennung geben):\n",
    "sql_statement = \"\"\"\n",
    "SELECT\n",
    "`account_number`\n",
    ",`city`\n",
    ",`year`\n",
    ",`column_name`\n",
    ",`response_answer`\n",
    ",count(*) as count\n",
    "FROM `cir`\n",
    "WHERE 1\n",
    "AND `theme` = 'combined'\n",
    "AND `year` IN ('2019','2020')\n",
    "AND `question_number` = '1.0a'\n",
    "AND `column_name` = 'Goal type'\n",
    "GROUP BY\n",
    "`account_number`\n",
    ",`city`\n",
    ",`year`\n",
    ",`response_answer`\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "sql_pickle('17-01', sql_statement)\n",
    "\n",
    "# Die 376 (nach Prüfung immer gleichen) Antworten aus Account 73750 Tarakan sind Duplikate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antworten auf Basis der (so vorgefundenen, falschen) Daten:\n",
    "sql_statement = \"\"\"\n",
    "SELECT\n",
    "`response_answer` as answer\n",
    ",count(*) as count\n",
    "FROM `cir`\n",
    "WHERE 1\n",
    "AND `theme` = 'combined'\n",
    "AND `year` IN ('2019','2020')\n",
    "AND `question_number` = '1.0a'\n",
    "AND `column_name` = 'Goal type'\n",
    "GROUP BY\n",
    "`response_answer`\n",
    "order by count desc\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "sql_pickle('17-02', sql_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korrekte Antworten; ohne Duplikate (durch SQL-Logik bereinigt):\n",
    "sql_statement = \"\"\"\n",
    "SELECT\n",
    "`answer`\n",
    ",count(*) as `count`\n",
    "FROM (SELECT DISTINCT\n",
    "      `account_number`as `account`\n",
    "      ,`entity` as `city`\n",
    "      ,`response_answer` as `answer`\n",
    "      FROM `cir`\n",
    "      WHERE 1\n",
    "      AND `theme` = 'combined'\n",
    "      AND `year` IN ('2019','2020')\n",
    "      AND `question_number` = '1.0a'\n",
    "      AND `column_name` = 'Goal type'\n",
    "      ORDER BY `account`, `answer` ASC) AS `ans`\n",
    "GROUP BY `answer`\n",
    "ORDER BY `count` DESC\n",
    "LIMIT 7\n",
    "\"\"\"\n",
    "cir_0100a_sql = sql_pickle('cir_0100a_sql', sql_statement)\n",
    "cir_0100a_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0a (C)\n",
    "ax = cir_0100a_sql.plot.bar(x='answer', y='count')\n",
    "plt.xticks(rotation=85)\n",
    "plt.title('Top 10 Targets (Cites) 2020',{'fontsize': 20});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recognize that emission reduction targets are the most important topic (433 mentions), but all other 5 main target levels of the cities are also mentioned as targets and are therefore relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0a (A) Anzahl der Ziele pro Account und Jahr:\n",
    "sql_statement = \"\"\"\n",
    "SELECT\n",
    "`account_number`\n",
    ",`year`\n",
    "#,`response_answer`\n",
    ",count(*) as `count`\n",
    "FROM (SELECT DISTINCT\n",
    "      `account_number`\n",
    "      ,`entity`\n",
    "      ,`year`\n",
    "      ,`response_answer`\n",
    "      FROM `cir`\n",
    "      WHERE 1\n",
    "      AND `theme` = 'combined'\n",
    "      AND `year` IN ('2019','2020')\n",
    "      AND `question_number` = '1.0a'\n",
    "      AND `column_name` = 'Goal type'\n",
    "      ORDER BY `account_number`, `response_answer` ASC) AS `ans`\n",
    "GROUP BY \n",
    "`account_number`\n",
    ",`year`\n",
    "#,`response_answer`\n",
    "ORDER BY \n",
    "`count` DESC\n",
    ",`account_number`\n",
    ",`year`\n",
    "#,`response_answer`\n",
    "\"\"\"\n",
    "#sql_to_db(sql_statement)\n",
    "\n",
    "cir_0100a_score_sql = sql_pickle('cir_0100a_score_sql', sql_statement)\n",
    "cir_0100a_score_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0a (D)\n",
    "# Ermitteln und sichern des Scorings:\n",
    "cir_0100a_score_sql.rename(columns={'count': '10a_targets_count'}, inplace=True)\n",
    "cir_0100a_score_sql['10a_targets_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0a (D)\n",
    "# Wir sichern unsere Erkenntnisse für spätere KPI-Entwicklung:\n",
    "cid_enh = pd.merge(left = cid_enh, right = cir_0100a_score_sql, on = (\"account_number\",\"year\"), how = \"left\")\n",
    "cid_enh.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The scoring methodology here is as follows:**\n",
    "* 0: no response (nan)\n",
    "* 1: 0 Targets\n",
    "* 2: 1 or 2 targets\n",
    "* 3: 3 or 4 targets\n",
    "* 4: 5 or 6 targets\n",
    "* 5: 7 or more targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(score_value):\n",
    "    if score_value  > 6.0:      return 5\n",
    "    if score_value  > 4.0:      return 4\n",
    "    if score_value  > 2.0:      return 3\n",
    "    if score_value  > 0.0:      return 2\n",
    "    if score_value == 0.0:      return 1\n",
    "    else:                       return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_enh['e_score_2'] = cid_enh.apply(lambda x : scoring(x['10a_targets_count']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_enh['e_score_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_enh.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0 Has a climate change risk and vulnerability assessment been undertaken for your city? (Cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0 Col-0 (A)\n",
    "# Erkunden der Datenlage\n",
    "df_grp = get_response_pivot(cir, '2.0', columnnumber='all', pivot=False, add_info=True, year=['2018','2019','2020'])\n",
    "df_grp[['account_number','entity','year','response_answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0 Col-0 (A)\n",
    "sql_statement = \"\"\"\n",
    "SELECT\n",
    "`account_number`\n",
    ",`entity`\n",
    ",`year`\n",
    ",`response_answer`\n",
    ",count(*) as count\n",
    "FROM `cir`\n",
    "WHERE 1\n",
    "AND `theme` = 'combined'\n",
    "AND `year` in ('2018','2019','2020')\n",
    "AND `question_number` = '2.0'\n",
    "AND `column_number` = 0\n",
    "GROUP BY\n",
    "`account_number`\n",
    ",`entity`\n",
    ",`year`\n",
    ",`response_answer`\n",
    "ORDER BY\n",
    "count DESC\n",
    ",`account_number` ASC\n",
    ",`year` ASC\n",
    "\"\"\"\n",
    "#sql_to_db(sql_statement)\n",
    "cir_0200_sql = sql_pickle('cir_0200_sql', sql_statement)\n",
    "cir_0200_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aus wie vielen verschiedenen Städten stammen die Daten?\n",
    "print(cir_0200_sql['account_number'].unique().shape)\n",
    "\n",
    "# Reduktion und Umbenennung auf benötigte Daten:\n",
    "cir_0200_sql = cir_0200_sql[['account_number','year','response_answer']]\n",
    "cir_0200_sql.rename(columns={'response_answer': '20_climate_assessment'}, inplace=True)\n",
    "cir_0200_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0 Col-0 (B)\n",
    "# Wir sichern unsere Erkenntnisse für spätere KPI-Entwicklung:\n",
    "cid_enh = pd.merge(left = cid_enh, right = cir_0200_sql, on = (\"account_number\",\"year\"), how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0 Col-0 (C)\n",
    "plotdata = cid_enh['20_climate_assessment'].value_counts().head(4)\n",
    "ax = plotdata.plot.bar(x='index', y='20_climate_assessment')\n",
    "plt.xticks(rotation=85)\n",
    "plt.title(\"Climate change risk and vulnerability assessment?\",{'fontsize': 20});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding: The topic is taken very seriously. More than 76% of the participants have made such an assessment or are currently doing so. Only 11% make no effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0 Col-0 (D)\n",
    "# Ermitteln und sichern des Scorings:\n",
    "score_values = cid_enh['20_climate_assessment'].value_counts()\n",
    "score_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The scoring methodology here is as follows:**\n",
    "* 0: no response (nan)\n",
    "* 1: No / Not intending to undertake / Do not know\n",
    "* 2: Intending to undertake in future\n",
    "* 3: Intending to undertake in the next 2 years\n",
    "* 4: In progress\n",
    "* 5: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(score_value):\n",
    "    if score_value == 'No':                                         return 1\n",
    "    if score_value == 'Not intending to undertake':                 return 1\n",
    "    if score_value == 'Do not know':                                return 1\n",
    "    if score_value == 'Intending to undertake in future':           return 2\n",
    "    if score_value == 'Intending to undertake in the next 2 years': return 3\n",
    "    if score_value == 'In progress':                                return 4\n",
    "    if score_value == 'Yes':                                        return 5\n",
    "    else:                                                           return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_enh['e_score_3'] = cid_enh.apply(lambda x : scoring(x['20_climate_assessment']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_enh['e_score_3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_enh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Does your city council, or similar authority, have a published plan that addresses climate change adaptation? (Cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Col-0 (A)\n",
    "# Erkunden der Datenlage\n",
    "df_grp = get_response_pivot(cir, '3.2', columnnumber='all', pivot=False, add_info=True, year=['2020'])\n",
    "df_grp[['account_number','entity','year','response_answer']]\n",
    "\n",
    "# In 2020 findet sich die Antwort in Frage 3.2!\n",
    "# In 2018 und 2019 ist sie in Frage 3.1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Col-0 (A)\n",
    "sql_statement = \"\"\"\n",
    "(\n",
    "SELECT\n",
    "`account_number`\n",
    ",`entity`\n",
    ",`year`\n",
    ",`response_answer`\n",
    ",count(*) as count\n",
    "FROM `cir`\n",
    "WHERE 1\n",
    "AND `theme` = 'combined'\n",
    "AND `year` in ('2020')\n",
    "AND `question_number` = '3.2'\n",
    "AND `column_number` = 0\n",
    "GROUP BY\n",
    "`account_number`\n",
    ",`entity`\n",
    ",`year`\n",
    ",`response_answer`\n",
    "ORDER BY\n",
    "count DESC\n",
    ",`account_number` ASC\n",
    ",`year` ASC\n",
    ")\n",
    "UNION\n",
    "(\n",
    "SELECT\n",
    "`account_number`\n",
    ",`entity`\n",
    ",`year`\n",
    ",`response_answer`\n",
    ",count(*) as count\n",
    "FROM `cir`\n",
    "WHERE 1\n",
    "AND `theme` = 'combined'\n",
    "AND `year` in ('2018','2018')\n",
    "AND `question_number` = '3.1'\n",
    "AND `column_number` = 0\n",
    "GROUP BY\n",
    "`account_number`\n",
    ",`entity`\n",
    ",`year`\n",
    ",`response_answer`\n",
    "ORDER BY\n",
    "count DESC\n",
    ",`account_number` ASC\n",
    ",`year` ASC\n",
    ")\n",
    "\"\"\"\n",
    "cir_0302_sql = sql_pickle('cir_0302_sql', sql_statement)\n",
    "cir_0302_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aus wie vielen verschiedenen Städten stammen die Daten?\n",
    "print(cir_0302_sql['account_number'].unique().shape)\n",
    "\n",
    "# Reduktion und Umbenennung auf benötigte Daten:\n",
    "cir_0302_sql = cir_0302_sql[['account_number','year','response_answer']]\n",
    "cir_0302_sql.rename(columns={'response_answer': '32_published_plan'}, inplace=True)\n",
    "cir_0302_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Col-0 (B)\n",
    "# Wir sichern unsere Erkenntnisse für spätere KPI-Entwicklung:\n",
    "cid_enh = pd.merge(left = cid_enh, right = cir_0302_sql, on = (\"account_number\",\"year\"), how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Col-0 (C)\n",
    "plotdata = cid_enh['32_published_plan'].value_counts().head(4)\n",
    "ax = plotdata.plot.bar(x='index', y='32_published_plan')\n",
    "plt.xticks(rotation=85)\n",
    "plt.title(\"Published plan that addresses climate change adaptation?\",{'fontsize': 20});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This point is also treated very positively: More than 75% of the respondents already publish or are at least in the process of doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Col-0 (D)\n",
    "# Ermitteln und sichern des Scorings:\n",
    "score_values = cid_enh['32_published_plan'].value_counts()\n",
    "score_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The scoring methodology here is as follows:**\n",
    "* 0: no response (nan)\n",
    "* 1: No / Not intending to undertake / Do not know\n",
    "* 2: Intending to undertake in future\n",
    "* 3: Intending to undertake in the next 2 years\n",
    "* 4: In progress\n",
    "* 5: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(score_value):\n",
    "    if score_value == 'No':                                         return 1\n",
    "    if score_value == 'Not intending to undertake':                 return 1\n",
    "    if score_value == 'Do not know':                                return 1\n",
    "    if score_value == 'Intending to undertake in future':           return 2\n",
    "    if score_value == 'Intending to undertake in the next 2 years': return 3\n",
    "    if score_value == 'In progress':                                return 4\n",
    "    if score_value == 'Yes':                                        return 5\n",
    "    else:                                                           return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_enh['e_score_4'] = cid_enh.apply(lambda x : scoring(x['32_published_plan']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_enh['e_score_4'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_enh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0 Reduction Target-Types (Cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0 Do you have a GHG emissions reduction target(s) in place at the city-wide level?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grp = get_response_pivot(cir, '5.0', columnnumber='all', pivot=False, add_info=False, year=['2019','2020'])\n",
    "df_grp[['year', 'account_number','column_number','column_name','response_answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl der Nennungen (Basis für Chart)\n",
    "sql_statement = \"\"\"\n",
    "SELECT\n",
    "`response_answer`\n",
    ",count(*) as count\n",
    "FROM `cir`\n",
    "WHERE 1\n",
    "AND `theme` = 'combined'\n",
    "AND `year` IN ('2019','2020')\n",
    "AND `question_number` = '5.0'\n",
    "AND `column_number` = 0\n",
    "AND `row_number` = 0\n",
    "GROUP BY\n",
    "`response_answer`\n",
    "ORDER BY\n",
    "count DESC\n",
    "\"\"\"\n",
    "cir_0500_sql = sql_pickle('cir_0500_sql', sql_statement)\n",
    "cir_0500_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antworten pro Account/Jahr. Mehrfach-Antworten möglich:\n",
    "sql_statement = \"\"\"\n",
    "SELECT DISTINCT\n",
    "`account_number`\n",
    ",`year`\n",
    ",`response_answer`\n",
    "FROM `cir`\n",
    "WHERE 1\n",
    "AND `theme` = 'combined'\n",
    "AND `year` IN ('2019','2020')\n",
    "AND `question_number` = '5.0'\n",
    "AND `column_number` = 0\n",
    "AND `row_number` = 0\n",
    "ORDER BY\n",
    "`account_number`\n",
    ",`year`\n",
    ",`response_answer`\n",
    "\"\"\"\n",
    "cir_0500_score_sql = sql_pickle('cir_0500_score_sql', sql_statement)\n",
    "cir_0500_score_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aus wie vielen verschiedenen Städten stammen die Daten?\n",
    "print(cir_0500_score_sql['account_number'].unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umbenennung der 'response_answer'-Spalte:\n",
    "cir_0500_score_sql.rename(columns={'response_answer': '50_target_level'}, inplace=True)\n",
    "\n",
    "# Das sind die verschiedenen Antworten:\n",
    "cir_0500_score_sql['50_target_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Da der jeweils beste (Scoring-) Wert in die Wertung soll, machen wir das Scoring bereits hier:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The scoring methodology here is as follows:**\n",
    "* 0: no response (nan)\n",
    "* 1: No target\n",
    "* 2: Baseline scenario (business as usual) target\n",
    "* 3: Base year emissions (absolute) target\n",
    "* 4: Fixed level target / Base year intensity target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(score_value):\n",
    "    if score_value            == 'No target':                                       return 1\n",
    "    if score_value            == 'Baseline scenario (business as usual) target':    return 2\n",
    "    if score_value            == 'Base year emissions (absolute) target':           return 3\n",
    "    if score_value            == 'Fixed level target':                              return 4\n",
    "    if score_value            == 'Base year intensity target':                      return 4\n",
    "    else:                                                                           return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0 Col-0 (D)\n",
    "# Sichern des Scoring-werte für die dann folgende Verdichtung nach bester Wertung:\n",
    "cir_0500_score_sql['e_score_6'] = cir_0500_score_sql.apply(lambda x : scoring(x['50_target_level']), axis=1)\n",
    "\n",
    "cir_0500_score_sql = cir_0500_score_sql.groupby(['account_number','year']).max().reset_index()\n",
    "cir_0500_score_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0 Col-0 (D)\n",
    "# Wir sichern unsere Erkenntnisse für spätere KPI-Entwicklung:\n",
    "cid_enh = pd.merge(left = cid_enh, right = cir_0500_score_sql, on = (\"account_number\",\"year\"), how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_enh['e_score_6'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0 Col-0 (C)\n",
    "ax = cir_0500_sql.plot.bar(x='response_answer', y='count')\n",
    "plt.xticks(rotation=85)\n",
    "plt.title(\"Reduction Target-Types in 2020\",{'fontsize': 20});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding: Most cities set absolute targets based on the base year. And: 30% of responding cities have not yet defined a destination type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0a Align Paris agreement? (Cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grp = get_response_pivot(cir, '5.0a', columnnumber='all', pivot=False, add_info=False, year=['2019','2020'])\n",
    "df_grp[['year', 'account_number','column_number','column_name','response_answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Col-11 (A)\n",
    "column_params = (11, '50a_paris_alignment')\n",
    "\n",
    "df_gvir = get_var_indexed_responses(df_grp, '5.0a', 1, 'All emissions sources included in city inventory', column_params[0])\n",
    "df_gvir = df_gvir[['account_number','year','response_answer']]\n",
    "df_gvir.rename(columns={\"response_answer\": column_params[1]}, inplace=True)\n",
    "df_gvir\n",
    "\n",
    "if db_write: write_to_db(df_gvir,'df_gvir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es gibt offenbar mehrere, verschiedene Antworten pro Account/Jahr:\n",
    "sql_statement = \"\"\"\n",
    "SELECT\n",
    "`is`.`account_number`\n",
    ",`is`.`year`\n",
    ",count(*)\n",
    "FROM (SELECT DISTINCT\n",
    "      `account_number`\n",
    "      ,`year`\n",
    "      ,`50a_paris_alignment`\n",
    "      FROM `df_gvir`\n",
    "      WHERE 1) AS `is`\n",
    "GROUP BY\n",
    "`is`.`account_number`\n",
    ",`is`.`year`\n",
    "ORDER BY\n",
    "count(*) DESC\n",
    "\"\"\"\n",
    "sql_pickle('18-01',sql_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das sind die verschiedenen Antworten:\n",
    "df_gvir['50a_paris_alignment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Da der jeweils beste (Scoring-) Wert in die Wertung soll, machen wir das Scoring bereits hier:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The scoring methodology here is as follows:**\n",
    "* 0: no response (nan)\n",
    "* 1: Do not know\n",
    "* 1: No\n",
    "* 2: Other: Aligned with Kyoto Protocol targets and Provincial targets\n",
    "* 2: Other: In order to be aligned with the Paris agreement an acceleration is needed. As a matter of fact Milan already signed the Covenant of Mayors for Climate and Energy and the Deadline 2020\n",
    "* 2: Other: It has 40% by 2030, but by 2005 year not 1990 as the baseline.\n",
    "* 2: Other: Target is old, will be revised in 2019\n",
    "* 3: Other\n",
    "* 3: Other: Current CAP does not; new targets for 2030 and 2050 will align with Paris Agreement\n",
    "* 3: Other: It is not of competence of the city to assess this. It actually depends on the contributions by all local and national authorities in total.\n",
    "* 3: Other: Target year is too early for Paris Agreement, but may be considered to be aligned.\n",
    "* 4: Other: Boston's 2050 target (carbon neutrality) aligns with the global 1.5 - 2 °C pathway set out in the Paris Agreement.\n",
    "* 4: Other: Yes\n",
    "* 4: Yes - 2 °C\n",
    "* 5: Other: Carbon Neutrality by 2045 goes beyond the emissions reduction pathway to 1.5 degrees.\n",
    "* 5: Other: Yes - 1 degree C\n",
    "* 5: Yes - 1.5 °C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(score_value):\n",
    "    if score_value            == 'Do not know':                      return 1\n",
    "    if score_value            == 'No':                               return 1\n",
    "    if str(score_value)[0:25] == 'Other: Aligned with Kyoto':        return 2\n",
    "    if str(score_value)[0:29] == 'Other: In order to be aligned':    return 2\n",
    "    if str(score_value)[0:20] == 'Other: It has 40% by':             return 2\n",
    "    if str(score_value)[0:26] == 'Other: Target is old, will':       return 2\n",
    "    if score_value            == 'Other':                            return 3\n",
    "    if str(score_value)[0:27] == 'Other: Current CAP does not':      return 3\n",
    "    if str(score_value)[0:30] == 'Other: It is not of competence':   return 3\n",
    "    if str(score_value)[0:31] == 'Other: Target year is too early':  return 3\n",
    "    if str(score_value)[0:13] == 'Other: Boston':                    return 4\n",
    "    if score_value            == 'Other: Yes':                       return 4\n",
    "    if score_value            == 'Yes - 2 °C':                       return 4\n",
    "    if str(score_value)[0:32] == 'Other: Carbon Neutrality by 2045': return 5\n",
    "    if score_value            == 'Other: Yes - 1 degree C':          return 5\n",
    "    if score_value            == 'Yes - 1.5 °C':                     return 5\n",
    "    else:                                                            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Col-1 (D)\n",
    "# Ermitteln und sichern des Scorings:\n",
    "df_gvir['e_score_7'] = df_gvir.apply(lambda x : scoring(x['50a_paris_alignment']), axis=1)\n",
    "df_gvir = df_gvir.groupby(['account_number','year']).max().reset_index()\n",
    "df_gvir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Col-11 (B)\n",
    "# Wir sichern unsere Erkenntnisse ('50a_paris_alignment' und 'e_score_7') für spätere KPI-Entwicklung:\n",
    "cid_enh = pd.merge(left = cid_enh, right = df_gvir, on = (\"account_number\",\"year\"), how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Col-11 (C)\n",
    "plotdata = cid_enh['50a_paris_alignment'].value_counts().head(4)\n",
    "ax = plotdata.plot.bar(x='index', y='50a_paris_alignment')\n",
    "plt.xticks(rotation=85)\n",
    "plt.title(\"Align with Paris Agreement\",{'fontsize': 20});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_enh['50a_paris_alignment'].value_counts().head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pleasing finding: Over 62% are committed to the Paris Agreement and act accordingly. Only a small proportion (approx. 7%) explicitly denies this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.1 Exploration / Corporates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C4.1 Did you have an emissions target that was active in the reporting year? (Corporates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.1 Col-0 (A)\n",
    "# Erkunden der Datenlage\n",
    "df_grp = get_response_pivot(cor, 'C4.1', columnnumber='all', pivot=False, add_info=False, year=['2018''2019','2020'])\n",
    "df_grp #[['account_number','entity','year','response_answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.1 Col-0 (A)\n",
    "sql_statement = \"\"\"\n",
    "SELECT\n",
    "`account_number`\n",
    ",`entity`\n",
    ",`year`\n",
    ",`question_number`\n",
    ",`question_name`\n",
    ",`response_answer`\n",
    ",count(*) as count\n",
    "FROM `cor`\n",
    "WHERE 1\n",
    "AND `theme` = 'climate'\n",
    "AND `year` in ('2018','2019','2020')\n",
    "AND `question_number` = 'C4.1'\n",
    "AND `column_number` = 0\n",
    "GROUP BY\n",
    "`account_number`\n",
    ",`entity`\n",
    ",`year`\n",
    ",`response_answer`\n",
    "ORDER BY\n",
    "count DESC\n",
    ",`account_number` ASC\n",
    ",`year` ASC\n",
    "\"\"\"\n",
    "cor_0401_sql = sql_pickle('cor_0401_sql', sql_statement)\n",
    "cor_0401_sql[['account_number','year','response_answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.1 Col-0 (A)\n",
    "# Aus wie vielen verschiedenen Städten stammen die Daten?\n",
    "print(cor_0401_sql['account_number'].unique().shape)\n",
    "\n",
    "# C4.1 Col-0 (B)\n",
    "# Reduktion und Umbenennung auf benötigte Daten:\n",
    "cor_0401_sql = cor_0401_sql[['account_number','year','response_answer']]\n",
    "cor_0401_sql.rename(columns={'response_answer': 'C41_emission_target'}, inplace=True)\n",
    "cor_0401_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.1 Col-0 (B)\n",
    "# Wir sichern unsere Erkenntnisse für spätere KPI-Entwicklung:\n",
    "cod_enh = pd.merge(left = cod_enh, right = cor_0401_sql, on = (\"account_number\",\"year\"), how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.1 Col-0 (C)\n",
    "plotdata = cod_enh['C41_emission_target'].value_counts().head(8)\n",
    "ax = plotdata.plot.bar(x='index', y='C41_emission_target')\n",
    "plt.xticks(rotation=85)\n",
    "plt.title(\"Emission target? (Corporates)\",{'fontsize': 20});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.1 Col-0 (D)\n",
    "# Ermitteln und sichern des Scorings:\n",
    "score_values = cod_enh['C41_emission_target'].value_counts()\n",
    "score_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The scoring methodology here is as follows:**\n",
    "* 0: no response (nan)\n",
    "* 1: No target\n",
    "* 4: Intensity target / Absolute target\n",
    "* 5: Both absolute and intensity targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(score_value):\n",
    "    if score_value == 'No target':                                  return 1\n",
    "    if score_value == 'Intensity target':                           return 4\n",
    "    if score_value == 'Absolute target':                            return 4\n",
    "    if score_value == 'Both absolute and intensity targets':        return 5\n",
    "    else:                                                           return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_enh['e_score_8'] = cod_enh.apply(lambda x : scoring(x['C41_emission_target']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_enh['e_score_8'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C4.3 Did you have emissions reduction initiatives that were active within the reporting year? (Corporates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.3 Col-0 (A)\n",
    "# Erkunden der Datenlage\n",
    "df_grp = get_response_pivot(cor, 'C4.3', columnnumber='all', pivot=False, add_info=False, year=['2018','2019','2020'])\n",
    "df_grp[['account_number','entity','year','response_answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.3 Col-0 (A)\n",
    "sql_statement = \"\"\"\n",
    "SELECT\n",
    "`account_number`\n",
    ",`entity`\n",
    ",`year`\n",
    ",`question_number`\n",
    ",`question_name`\n",
    ",`response_answer`\n",
    ",count(*) as count\n",
    "FROM `cor`\n",
    "WHERE 1\n",
    "AND `theme` = 'climate'\n",
    "AND `year` in ('2018','2019','2020')\n",
    "AND `question_number` = 'C4.3'\n",
    "AND `column_number` = 0\n",
    "GROUP BY\n",
    "`account_number`\n",
    ",`entity`\n",
    ",`year`\n",
    ",`response_answer`\n",
    "ORDER BY\n",
    "count DESC\n",
    ",`account_number` ASC\n",
    ",`year` ASC\n",
    "\"\"\"\n",
    "cor_0403_sql = sql_pickle('cor_0403_sql', sql_statement)\n",
    "cor_0403_sql[['account_number','year','response_answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.3 Col-0 (A)\n",
    "# Aus wie vielen verschiedenen Städten stammen die Daten?\n",
    "print(cor_0403_sql['account_number'].unique().shape)\n",
    "\n",
    "# C4.3 Col-0 (B)\n",
    "# Reduktion und Umbenennung auf benötigte Daten:\n",
    "cor_0403_sql = cor_0403_sql[['account_number','year','response_answer']]\n",
    "cor_0403_sql.rename(columns={'response_answer': 'C43_initiatives_in_place'}, inplace=True)\n",
    "cor_0403_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.3 Col-0 (B)\n",
    "# Wir sichern unsere Erkenntnisse für spätere KPI-Entwicklung:\n",
    "cod_enh = pd.merge(left = cod_enh, right = cor_0403_sql, on = (\"account_number\",\"year\"), how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.3 Col-0 (C)\n",
    "plotdata = cod_enh['C43_initiatives_in_place'].value_counts().head(8)\n",
    "ax = plotdata.plot.bar(x='index', y='C43_initiatives_in_place')\n",
    "plt.xticks(rotation=85)\n",
    "plt.title(\"Initiatives in place? (Corporates)\",{'fontsize': 20});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.3 Col-0 (D)\n",
    "# Ermitteln und sichern des Scorings:\n",
    "score_values = cod_enh['C43_initiatives_in_place'].value_counts()\n",
    "score_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The scoring methodology here is as follows:**\n",
    "* 0: no response (nan)\n",
    "* 1: No\n",
    "* 4: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(score_value):\n",
    "    if score_value == 'No':                     return 1\n",
    "    if score_value == 'Yes':                    return 4\n",
    "    else:                                       return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_enh['e_score_9'] = cod_enh.apply(lambda x : scoring(x['C43_initiatives_in_place']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_enh['e_score_9'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_enh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C4.3a Implemented emissions savings (reduction initiatives)? (Corporates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.3a Col-0 (A)\n",
    "# Erkunden der Datenlage\n",
    "df_grp = get_response_pivot(cor, 'C4.3a', columnnumber=[2], pivot=False, add_info=False, year=['2018','2019','2020'])\n",
    "df_grp #[['account_number','entity','year','response_answer']]\n",
    "# In 2018 gibt es diese Frage nicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grp.row_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.3a Col-2 Row-4 (A)\n",
    "sql_statement = \"\"\"\n",
    "SELECT\n",
    "`account_number`\n",
    ",`entity`\n",
    ",`year`\n",
    ",`question_number`\n",
    ",`question_name`\n",
    ",`column_name`\n",
    ",`row_name`\n",
    ",`response_answer`\n",
    ",count(*) as count\n",
    "FROM `cor`\n",
    "WHERE 1\n",
    "AND `theme` = 'climate'\n",
    "AND `year` in ('2019','2019','2020')\n",
    "AND `question_number` = 'C4.3a'\n",
    "AND `column_number` = 2\n",
    "AND `row_number` = 4\n",
    "AND `row_name` = 'Implemented*'\n",
    "GROUP BY\n",
    "`account_number`\n",
    ",`entity`\n",
    ",`year`\n",
    ",`response_answer`\n",
    "ORDER BY\n",
    "count DESC\n",
    ",`account_number` ASC\n",
    ",`year` ASC\n",
    "\"\"\"\n",
    "cor_0403a_sql = sql_pickle('cor_0403a_sql', sql_statement)\n",
    "cor_0403a_sql[['account_number','year','response_answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.3a Col-2 Row-4 (A)\n",
    "# Aus wie vielen verschiedenen Städten stammen die Daten?\n",
    "print(cor_0403a_sql['account_number'].unique().shape)\n",
    "\n",
    "# C4.3a Col-1 Row-2 (B)\n",
    "# Reduktion und Umbenennung auf benötigte Daten:\n",
    "cor_0403a_sql = cor_0403a_sql[['account_number','year','response_answer']]\n",
    "cor_0403a_sql.rename(columns={'response_answer': 'C43a_implemented_savings'}, inplace=True)\n",
    "cor_0403a_sql['C43a_implemented_savings'] = cor_0403a_sql['C43a_implemented_savings'].astype('float64')\n",
    "cor_0403a_sql.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.3a Col-1 Row-2 (B)\n",
    "# Wir sichern unsere Erkenntnisse für spätere KPI-Entwicklung:\n",
    "cod_enh = pd.merge(left = cod_enh, right = cor_0403a_sql, on = (\"account_number\",\"year\"), how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.3a Col-1 Row-2 (D)\n",
    "# Ermitteln und sichern des Scorings:\n",
    "score_values = cod_enh['C43a_implemented_savings']\n",
    "score_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The scoring methodology here is as follows:**\n",
    "* 0: no response (nan)\n",
    "* 1: Total estimated annual CO2e savings in metric tonnes CO2e for implemented initiatives: =      0\n",
    "* 2: Total estimated annual CO2e savings in metric tonnes CO2e for implemented initiatives: >      0\n",
    "* 3: Total estimated annual CO2e savings in metric tonnes CO2e for implemented initiatives: >=   800\n",
    "* 4: Total estimated annual CO2e savings in metric tonnes CO2e for implemented initiatives: >=  6000\n",
    "* 5: Total estimated annual CO2e savings in metric tonnes CO2e for implemented initiatives: >= 42000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(score_value):\n",
    "    if score_value >= 42000.0:                  return 5    # >= 80000.0\n",
    "    if score_value >=  6000.0:                  return 4    # >= 11000.0\n",
    "    if score_value >=   800.0:                  return 3    # >=  3000.0\n",
    "    if score_value  >     0.0:                  return 2    # >=   500.0\n",
    "    if score_value ==     0.0:                  return 1    # >=     0.0\n",
    "    else:                                       return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_enh['e_score_10'] = cod_enh.apply(lambda x : scoring(x['C43a_implemented_savings']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_enh['e_score_10'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C7.1 Does your organization break down its Scope 1 emissions by greenhouse gas type? (Corporates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C7.1 Col-0 (A)\n",
    "# Erkunden der Datenlage\n",
    "df_grp = get_response_pivot(cor, 'C7.1', columnnumber='all', pivot=False, add_info=False, year=['2019','2020'])\n",
    "df_grp[['account_number','entity','year','response_answer']]\n",
    "# In 2018 gibt es diese Frage nicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C7.1 Col-0 (A)\n",
    "sql_statement = \"\"\"\n",
    "SELECT\n",
    "`account_number`\n",
    ",`entity`\n",
    ",`year`\n",
    ",`question_number`\n",
    ",`question_name`\n",
    ",`response_answer`\n",
    ",count(*) as count\n",
    "FROM `cor`\n",
    "WHERE 1\n",
    "AND `theme` = 'climate'\n",
    "AND `year` in ('2019','2020')\n",
    "AND `question_number` = 'C7.1'\n",
    "AND `column_number` = 0\n",
    "GROUP BY\n",
    "`account_number`\n",
    ",`entity`\n",
    ",`year`\n",
    ",`response_answer`\n",
    "ORDER BY\n",
    "count DESC\n",
    ",`account_number` ASC\n",
    ",`year` ASC\n",
    "\"\"\"\n",
    "cor_0701_sql = sql_pickle('cor_0701_sql', sql_statement)\n",
    "cor_0701_sql[['account_number','year','response_answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C7.1 Col-0 (A)\n",
    "# Aus wie vielen verschiedenen Städten stammen die Daten?\n",
    "print(cor_0701_sql['account_number'].unique().shape)\n",
    "\n",
    "# C7.1 Col-0 (B)\n",
    "# Reduktion und Umbenennung auf benötigte Daten:\n",
    "cor_0701_sql = cor_0701_sql[['account_number','year','response_answer']]\n",
    "cor_0701_sql.rename(columns={'response_answer': 'C71_break_down_scope1'}, inplace=True)\n",
    "cor_0701_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C7.1 Col-0 (B)\n",
    "# Wir sichern unsere Erkenntnisse für spätere KPI-Entwicklung:\n",
    "cod_enh = pd.merge(left = cod_enh, right = cor_0701_sql, on = (\"account_number\",\"year\"), how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C7.1 Col-0 (C)\n",
    "plotdata = cod_enh['C71_break_down_scope1'].value_counts().head(8)\n",
    "ax = plotdata.plot.bar(x='index', y='C71_break_down_scope1')\n",
    "plt.xticks(rotation=85)\n",
    "plt.title(\"Break down Scope 1 by Grenhouse gas type? (Corporates)\",{'fontsize': 20});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding: 68% of companies analyze their Scope 1 emissions more precisely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C7.1 Col-0 (D)\n",
    "# Ermitteln und sichern des Scorings:\n",
    "score_values = cod_enh['C71_break_down_scope1'].value_counts()\n",
    "score_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The scoring methodology here is as follows:**\n",
    "* 0: no response (nan)\n",
    "* 1: No / Don't know\n",
    "* 4: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(score_value):\n",
    "    if score_value == 'No':                     return 1\n",
    "    if score_value == \"Don't know\":             return 1\n",
    "    if score_value == 'Yes':                    return 4\n",
    "    else:                                       return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_enh['e_score_11'] = cod_enh.apply(lambda x : scoring(x['C71_break_down_scope1']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_enh['e_score_11'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.2 Scoring (Cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have six five scores for cities that will provide...\n",
    "\n",
    "**e_score_1** will provide ...<br>\n",
    "**e_score_2** will provide ...<br>\n",
    "**e_score_3** will provide ...<br>\n",
    "**e_score_4** will provide ...<br>\n",
    "**e_score_5** will provide ...<br>\n",
    "**e_score_6** will provide ...<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0 Col-0 (D)\n",
    "# Ermitteln und sichern des Scorings:\n",
    "score_values = cid_enh['10_goals_targets'].value_counts()\n",
    "score_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The scoring methodology here is as follows:**\n",
    "* 0: no response (nan)\n",
    "* 1: No / Not intending to incorporate / Do not know\n",
    "* 2: Intending to undertake in future\n",
    "* 3: Intending to incorporate in the next 2 years\n",
    "* 4: In progress\n",
    "* 5: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(score_value):\n",
    "    if score_value == 'No':                                             return 1\n",
    "    if score_value == 'Not intending to incorporate':                   return 1\n",
    "    if score_value == 'Do not know':                                    return 1\n",
    "    if score_value == 'Intending to undertake in future':               return 2\n",
    "    if score_value == 'Intending to incorporate in the next 2 years':   return 3\n",
    "    if score_value == 'In progress':                                    return 4\n",
    "    if score_value == 'Yes':                                            return 5\n",
    "    else:                                                               return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_enh['e_score_1'] = cid_enh.apply(lambda x : scoring(x['10_goals_targets']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_enh[['account_number','year','10_goals_targets','e_score_1']].sort_values(by=['account_number','year']).query('e_score_1 != 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.2 Scoring (Corporates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6.3 Conclusion\n",
    "<font color=orange size=4> **Kurze Zusammenfassung des Capitels.** </font>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through our exploration we have found out that...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 Emissions \n",
    "\n",
    "In this section we'll have a closer look to the emission data provided by the cities and corporations answers. And we'll have a look at the distribution of the emission between the others in the same region for cities and between the others in the same industry for corporations.\n",
    "\n",
    "We'll use this data then to build scores, to rank the cities and corporations based on their emission data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.1 Exploration (Cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frage: Wo finden sich die meisten Antworten zu \"Emission\" und \"CO2\"\n",
    "sql_statement = \"\"\"\n",
    "SELECT distinct\n",
    "`year`\n",
    ",`question_number`\n",
    ",`question_name`\n",
    ",`column_number`\n",
    ",`column_name`\n",
    ",count(*) as count\n",
    "FROM `cir`\n",
    "WHERE 1\n",
    "and `question_name` LIKE '%emission%'\n",
    "and (`column_name` LIKE '%CO2%' or `column_name` LIKE '%Categor%')\n",
    "and `year` in ('2018','2019','2020')\n",
    "group by\n",
    "`year`\n",
    ",`question_number`\n",
    ",`question_name`\n",
    ",`column_number`\n",
    ",`column_name`\n",
    "order by\n",
    "count desc\n",
    "\"\"\"\n",
    "sql_pickle('12-03', sql_statement).head(10)\n",
    "# Antwort: In Frage 4.6a (für die Jahre 2019 und 2020) & Frage 7.3a für das Jahr 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.6a Total Scope 1 Emission 2019 & 2020 (Cities)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frage: Wie sehen die (festen) Row-Fragen aus? Welche wollen wir betrachten?\n",
    "sql_statement = \"\"\"\n",
    "select\n",
    "`year`\n",
    ",`question_number`\n",
    "#,`question_name`\n",
    ",`column_number`\n",
    ",`column_name`\n",
    ",`row_number`\n",
    ",`row_name`\n",
    ",count(*)\n",
    ",round(sum(`response_answer`)/1000,0) as `sum_in_megatonnes`\n",
    ",round(((sum(`response_answer`)/count(*))/1000),0) as `average_in_megatonnes`\n",
    "from cir\n",
    "WHERE 1\n",
    "and `year`='2020'\n",
    "and `question_number` = '4.6a'\n",
    "and `column_number` = 1\n",
    "group by\n",
    "`year`\n",
    ",`question_number`\n",
    "#,`question_name`\n",
    ",`column_number`\n",
    ",`column_name`\n",
    ",`row_number`\n",
    ",`row_name`\n",
    "order by\n",
    "`row_number`\n",
    "\"\"\"\n",
    "sql_pickle('12-04', sql_statement)\n",
    "# Antwort: Row 31 'Total Emissions (excluding generation of grid-supplied energy)' ist gut verwendbar!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total emission data for 2019 and 2020 is listed in question 4.6a column 1 row 31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.6a Col1 Row31 (A)\n",
    "df_gr = get_responses(cir, '4.6a', column_number=[1], row_number=[31], theme='combined', year=['2019','2020'])\n",
    "df_gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll build a dataframe and collect our results for the total emission data for the years 2019 and 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aus wie vielen verschiedenen Städten stammen die Daten?\n",
    "print(df_gr['account_number'].unique().shape)\n",
    "df_gr.rename(columns={'response_answer': '46a_total_emissions'}, inplace=True)\n",
    "\n",
    "# Erstellen einer passenden 'year'-Spalte:\n",
    "df_gr['year'] =   df_gr.apply(lambda x : str(x['response_pnt'].split('-')[0]), axis=1)\n",
    "df_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reduktion auf benötigte Daten:\n",
    "df_gr = df_gr[['account_number','year','46a_total_emissions']]\n",
    "df_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.6a Col1 Row31 (B)\n",
    "# Wir sichern unsere Erkenntnisse für spätere KPI-Entwicklung:\n",
    "cid_enh = pd.merge(left = cid_enh, right = df_gr, on = (\"account_number\",\"year\"), how = \"left\")\n",
    "cid_enh['46a_total_emissions'] = cid_enh['46a_total_emissions'].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.3a Total Scope 1 Emission 2018 (Cities)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frage: Wie sehen die (festen) Row-Fragen aus? Welche wollen wir betrachten?\n",
    "sql_statement = \"\"\"\n",
    "select\n",
    "`year`\n",
    ",`question_number`\n",
    "#,`question_name`\n",
    ",`column_number`\n",
    ",`column_name`\n",
    ",`row_number`\n",
    ",`row_name`\n",
    ",count(*)\n",
    ",round(sum(`response_answer`)/1000,0) as `sum_in_megatonnes`\n",
    ",round(((sum(`response_answer`)/count(*))/1000),0) as `average_in_megatonnes`\n",
    "from cir\n",
    "WHERE 1\n",
    "and `year`='2018'\n",
    "and `question_number` = '7.3a'\n",
    "and `column_number` = 1\n",
    "group by\n",
    "`year`\n",
    ",`question_number`\n",
    "#,`question_name`\n",
    ",`column_number`\n",
    ",`column_name`\n",
    ",`row_number`\n",
    ",`row_name`\n",
    "order by\n",
    "`row_number`\n",
    "\"\"\"\n",
    "sql_pickle('12-05', sql_statement)\n",
    "# Antwort: Row 13 'TOTAL Scope 1 (Territorial) emissions' ist gut verwendbar!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total emission data for the year 2018 is located in question 7.3a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3a Col1 Row13 (A)\n",
    "df_gr = get_responses(cir, '7.3a', column_number=[1], row_number=[13], theme='combined', year=['2018'])\n",
    "df_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aus wie vielen verschiedenen Städten stammen die Daten?\n",
    "print(df_gr['account_number'].unique().shape)\n",
    "df_gr.rename(columns={'response_answer': '73a_total_emissions'}, inplace=True)\n",
    "\n",
    "# Erstellen einer passenden 'year'-Spalte:\n",
    "df_gr['year'] =   df_gr.apply(lambda x : str(x['response_pnt'].split('-')[0]), axis=1)\n",
    "\n",
    "# Reduktion auf benötigte Daten:\n",
    "df_gr = df_gr[['account_number','year','73a_total_emissions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3a Col1 Row13 (B)\n",
    "# Erweiterung des Working-Dataframes um die neu gewonnenen Informationen:\n",
    "cid_enh = pd.merge(left = cid_enh, right = df_gr, on = (\"account_number\",\"year\"), how = \"left\")\n",
    "cid_enh['73a_total_emissions'] = cid_enh['73a_total_emissions'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugen einer Summen-Spalte und Löschen der nicht mehr benötigten Einzelspalten:\n",
    "cid_enh.loc[:,'total_emissions'] = cid_enh.loc[:,['46a_total_emissions','73a_total_emissions']].sum(axis=1, min_count=1)\n",
    "del cid_enh['46a_total_emissions']\n",
    "del cid_enh['73a_total_emissions']\n",
    "cid_enh.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.0a Headline: Emissions reduction (absolute) targets and related informations (Cities)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Please provide details of your total city-wide base year emissions reduction (absolute) target(s)...:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grp = get_response_pivot(cir, '5.0a', columnnumber='all', pivot=False, add_info=False, year=['2019','2020'])\n",
    "df_grp[['year', 'account_number','column_number','column_name','response_answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Gibt es genug Antworten für den Sector 'All emissions sources included in city inventory'?\n",
    "sql_statement = \"\"\"\n",
    "SELECT\n",
    "`account_number`as account\n",
    ",`entity` as city\n",
    ",`response_answer` as answer\n",
    ",count(*) as count\n",
    "FROM `cir`\n",
    "WHERE 1\n",
    "AND `theme` = 'combined'\n",
    "AND `year` in (2019,2020)\n",
    "AND `question_number` = '5.0a'\n",
    "AND `column_name` = 'Sector'\n",
    "AND `response_answer` = 'All emissions sources included in city inventory'\n",
    "GROUP BY\n",
    "`account_number`\n",
    ",`entity`\n",
    ",`response_answer`\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "cir_2020_0500a_sql = sql_pickle('cir_2020_0500a_sql', sql_statement)\n",
    "cir_2020_0500a_sql.shape\n",
    "\n",
    "# Es gib 292 Städte die in 2019 und/oder 2020 Angaben zum 'Sector':'All emissions sources included in city inventory' gemacht haben.\n",
    "# Die Summenbildung der 292 Antworten ist einfacher mit der Python-Funktion get_var_indexed_responses():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 292 cities in 2019 and 2020 that provided data to the total emissions question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.0a Base Year (Cities)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a dataframe with the results of the base year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Col4 (A)\n",
    "# Wir extrahieren die Column 4 (Base year)\n",
    "column_params = (4, '50a_base_year')\n",
    "\n",
    "df_gvir = get_var_indexed_responses(df_grp, '5.0a', 1, 'All emissions sources included in city inventory', column_params[0])\n",
    "df_gvir = df_gvir[['account_number','response_answer']]\n",
    "df_gvir = df_gvir.groupby('account_number').max().reset_index()\n",
    "df_gvir.rename(columns={\"response_answer\": column_params[1]}, inplace=True)\n",
    "df_gvir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5.0a Col4 (B)\n",
    "# Wir sichern unsere Erkenntnisse für spätere KPI-Entwicklung:\n",
    "cid_enh = pd.merge(left = cid_enh, right = df_gvir, on = \"account_number\", how = \"left\")\n",
    "cid_enh['50a_base_year'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.0a Base Year Emissions (Cities)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Col6 (A)\n",
    "column_params = (6, '50a_base_year_emissions')\n",
    "\n",
    "df_gvir = get_var_indexed_responses(df_grp, '5.0a', 1, 'All emissions sources included in city inventory', column_params[0])\n",
    "df_gvir = df_gvir[['account_number','response_answer']]\n",
    "df_gvir = df_gvir.groupby('account_number').max().reset_index()\n",
    "df_gvir.rename(columns={\"response_answer\": column_params[1]}, inplace=True)\n",
    "df_gvir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Col6 (B)\n",
    "# Wir sichern unsere Erkenntnisse für spätere KPI-Entwicklung:\n",
    "cid_enh = pd.merge(left = cid_enh, right = df_gvir, on = \"account_number\", how = \"left\")\n",
    "cid_enh['50a_base_year_emissions'] = cid_enh['50a_base_year_emissions'].astype('float64')\n",
    "cid_enh[['account_number','50a_base_year_emissions']].dropna(axis=0, subset=['50a_base_year_emissions'], inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.0a Percentage Reduction Target (Cities)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Col7 (A)\n",
    "column_params = (7, '50a_percentage_reduction_target')\n",
    "\n",
    "df_gvir = get_var_indexed_responses(df_grp, '5.0a', 1, 'All emissions sources included in city inventory', column_params[0])\n",
    "df_gvir = df_gvir[['account_number','response_answer']]\n",
    "df_gvir = df_gvir.groupby('account_number').max().reset_index()\n",
    "df_gvir.rename(columns={\"response_answer\": column_params[1]}, inplace=True)\n",
    "df_gvir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Col7 (B)\n",
    "# Wir sichern unsere Erkenntnisse für spätere KPI-Entwicklung:\n",
    "cid_enh = pd.merge(left = cid_enh, right = df_gvir, on = \"account_number\", how = \"left\")\n",
    "cid_enh['50a_percentage_reduction_target'] = cid_enh['50a_percentage_reduction_target'].astype('float64')\n",
    "cid_enh[cid_enh['50a_percentage_reduction_target'].notna()]['50a_percentage_reduction_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Col7 (C)\n",
    "plotdata = cid_enh[cid_enh['50a_percentage_reduction_target'].notna()]['50a_percentage_reduction_target']\n",
    "ax = plotdata.plot.hist(bins=20)\n",
    "plt.xticks(rotation=85)\n",
    "plt.title(\"Percentage Reduction Target\",{'fontsize': 20});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common reduction target is set at 80%, but the targest are widely spreaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.0a Target Year (Cities)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Col8 (A)\n",
    "column_params = (8, '50a_target_year')\n",
    "\n",
    "df_gvir = get_var_indexed_responses(df_grp, '5.0a', 1, 'All emissions sources included in city inventory', column_params[0])\n",
    "df_gvir = df_gvir[['account_number','response_answer']]\n",
    "df_gvir = df_gvir.groupby('account_number').max().reset_index()\n",
    "df_gvir.rename(columns={\"response_answer\": column_params[1]}, inplace=True)\n",
    "df_gvir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Col8 (B)\n",
    "# Wir sichern unsere Erkenntnisse für spätere KPI-Entwicklung:\n",
    "cid_enh = pd.merge(left = cid_enh, right = df_gvir, on = \"account_number\", how = \"left\")\n",
    "cid_enh['50a_target_year']\n",
    "cid_enh['50a_target_year'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Col8 (C)\n",
    "plotdata = cid_enh[cid_enh['50a_target_year'].notna()]['50a_target_year']\n",
    "plotdata = plotdata.value_counts().sort_index()\n",
    "ax = plotdata.plot.bar(x='index', y='50a_target_year')\n",
    "plt.xticks(rotation=85)\n",
    "plt.title(\"Target year\",{'fontsize': 20});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common target years are 2020, 2030 and 2050."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.0a Target Year Emissions (Cities)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Col9 (A)\n",
    "column_params = (9, '50a_target_year_emissions')\n",
    "\n",
    "df_gvir = get_var_indexed_responses(df_grp, '5.0a', 1, 'All emissions sources included in city inventory', column_params[0])\n",
    "df_gvir = df_gvir[['account_number','response_answer']]\n",
    "df_gvir = df_gvir.groupby('account_number').max().reset_index()\n",
    "df_gvir.rename(columns={\"response_answer\": column_params[1]}, inplace=True)\n",
    "df_gvir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Col9 (B)\n",
    "# Wir sichern unsere Erkenntnisse für spätere KPI-Entwicklung:\n",
    "cid_enh = pd.merge(left = cid_enh, right = df_gvir, on = \"account_number\", how = \"left\")\n",
    "cid_enh['50a_target_year_emissions'] = cid_enh['50a_target_year_emissions'].astype('float64')\n",
    "cid_enh['50a_target_year_emissions'].value_counts().head(10)\n",
    "# Erkenntnis: Die häufigste Nennung ist 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Col9 (C)\n",
    "# Hier folgt eine Grafik über die Zielmengen (müssen vergleichbar sein)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.0a Percentage Target Archieved (Cities)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Col10 (A)\n",
    "column_params = (10, '50a_percentage_target_achieved')\n",
    "\n",
    "df_gvir = get_var_indexed_responses(df_grp, '5.0a', 1, 'All emissions sources included in city inventory', column_params[0])\n",
    "df_gvir = df_gvir[['account_number','response_answer']]\n",
    "df_gvir = df_gvir.groupby('account_number').max().reset_index()\n",
    "df_gvir.rename(columns={\"response_answer\": column_params[1]}, inplace=True)\n",
    "df_gvir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Col10 (B)\n",
    "# Wir sichern unsere Erkenntnisse für spätere KPI-Entwicklung:\n",
    "cid_enh = pd.merge(left = cid_enh, right = df_gvir, on = \"account_number\", how = \"left\")\n",
    "cid_enh['50a_percentage_target_achieved'] = cid_enh['50a_percentage_target_achieved'].astype('float64')\n",
    "cid_enh[cid_enh['50a_percentage_target_achieved'].notna()]['50a_percentage_target_achieved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0a Col10 (C)\n",
    "plotdata = cid_enh[cid_enh['50a_percentage_target_achieved'].notna()]['50a_percentage_target_achieved']\n",
    "ax = plotdata.plot.hist(bins=20)\n",
    "plt.xticks(rotation=85)\n",
    "plt.title(\"Percentage target achieved\",{'fontsize': 20});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most cities reached less than 50% of their targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emission data compared to other areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import emission data and remove unnecessary columns\n",
    "\n",
    "answer_4_6a = pd.read_csv('data/Cities/cid_total_emissions_v2.csv')\n",
    "answer_4_6a = answer_4_6a.iloc[:,3:6]\n",
    "\n",
    "# Merge population data from cid dataframe\n",
    "\n",
    "cid_red = cid.drop_duplicates(subset='account_number', keep='first')\n",
    "\n",
    "answer_4_6a   = pd.merge(left = answer_4_6a,\n",
    "                     right = cid_red[['region', 'population']],\n",
    "                     left_on = answer_4_6a['account_number'],\n",
    "                     right_on = cid_red['account_number'], \n",
    "                     how = 'left')\n",
    "\n",
    "# Calculate emission per population in new column\n",
    "\n",
    "answer_4_6a['emission_per_pop'] = answer_4_6a['total_emissions']/answer_4_6a['population']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many cities participated\n",
    "In the regions South and West Asia, as in Middle East only a few cities provided their emission data. Therefore it is not sufficient data in some cases, to make conclusions out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_4_6a[answer_4_6a['year'] == 2018].region.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_4_6a[answer_4_6a['year'] == 2019].region.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_4_6a[answer_4_6a['year'] == 2020].region.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median emission per region\n",
    "In the following section, we compare the median emission per cities between the regions. These plots are part of the EDA, but the plots are not meaningful due to unsuffisient data. In the end the values are not compareable. So there is no interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = answer_4_6a[answer_4_6a['year'] == 2018].groupby('region').median()\n",
    "df.reset_index(inplace=True)\n",
    "plt.figure(figsize=(18, 6))\n",
    "#fig.set_axis_labels('Region', 'Emission')\n",
    "ax = sns.barplot(x='region', y='total_emissions', data=df, palette='mako');\n",
    "ax.set(xlabel='Region', ylabel='Emission in metric tonnes CO2e', title='Median emission per region 2018');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = answer_4_6a[answer_4_6a['year'] == 2019].groupby('region').median()\n",
    "df.reset_index(inplace=True)\n",
    "plt.figure(figsize=(18, 6))\n",
    "#fig.set_axis_labels('Region', 'Emission')\n",
    "ax = sns.barplot(x='region', y='total_emissions', data=df, palette='mako');\n",
    "ax.set(xlabel='Region', ylabel='Emission in metric tonnes CO2e', title='Median emission per region 2019');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = answer_4_6a[answer_4_6a['year'] == 2020].groupby('region').median()\n",
    "df.reset_index(inplace=True)\n",
    "plt.figure(figsize=(18, 6))\n",
    "#fig.set_axis_labels('Region', 'Emission')\n",
    "ax = sns.barplot(x='region', y='total_emissions', data=df, palette='mako');\n",
    "ax.set(xlabel='Region', ylabel='Emission in metric tonnes CO2e', title='Median emission per region 2020');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median emission per population\n",
    "\n",
    "In the following section, we compare the median emission per population per cities between the regions. These plots are part of the EDA, but the plots are not meaningful due to unsuffisient data. In the end the values are not compareable. So there is no interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = answer_4_6a[answer_4_6a['year'] == 2018].groupby('region').median()\n",
    "df.reset_index(inplace=True)\n",
    "plt.figure(figsize=(18, 6))\n",
    "#fig.set_axis_labels('Region', 'Emission')\n",
    "ax = sns.barplot(x='region', y='emission_per_pop', data=df, palette='mako');\n",
    "ax.set(xlabel='Region', ylabel='Emission in metric tonnes CO2e', title='Median emission per population per region 2018');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = answer_4_6a[answer_4_6a['year'] == 2019].groupby('region').median()\n",
    "df.reset_index(inplace=True)\n",
    "plt.figure(figsize=(18, 6))\n",
    "#fig.set_axis_labels('Region', 'Emission')\n",
    "ax = sns.barplot(x='region', y='emission_per_pop', data=df, palette='mako');\n",
    "ax.set(xlabel='Region', ylabel='Emission in metric tonnes CO2e', title='Median emission per population per region 2019');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = answer_4_6a[answer_4_6a['year'] == 2020].groupby('region').median()\n",
    "df.reset_index(inplace=True)\n",
    "plt.figure(figsize=(18, 6))\n",
    "#fig.set_axis_labels('Region', 'Emission')\n",
    "ax = sns.barplot(x='region', y='emission_per_pop', data=df, palette='mako');\n",
    "ax.set(xlabel='Region', ylabel='Emission in metric tonnes CO2e', title='Median emission per population per region 2020');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.2 Scoring (Cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will be two scores for the emission data. \n",
    "\n",
    "**em_score_1** will give a score for the actual emission per people and year that are situated in the respective city. 5 points means, that there is less than 3 tonnes of emission per year and person. This is the mean value of emission per people and year in the world before 1960. Actual studies use this value as a safe value for preventing the climate change keeping in mind, that the population in the world already raised up in the meantime.\n",
    "\n",
    "**em_score_2** will give a score for aimed emission per people and year one year in advance. It is calculated based on the provided data. If data is missing for calculating this score, it won't be calculated.\n",
    "\n",
    "- 5 Points for less than  3    tonnes of emission per person and year\n",
    "- 4 Points for less than  3.75 tonnes of emission per person and year\n",
    "- 3 Points for less than  5    tonnes of emission per person and year\n",
    "- 2 Points for less than  7.5  tonnes of emission per person and year\n",
    "- 1 Point  for less than  15   tonnes of emission per person and year\n",
    "\n",
    "- 0 Points for missing answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating em_scores\n",
    "\n",
    "#Creating scoring function for em_score_1 and em_score_2\n",
    "def create_score(x):  \n",
    "    \n",
    "    if 0 < x < 3:\n",
    "        return 5\n",
    "    elif 0 < x < 3.75:\n",
    "        return 4\n",
    "    elif 0 < x < 5:\n",
    "        return 3\n",
    "    elif 0 < x < 7.5:\n",
    "        return 2\n",
    "    elif 0 < x :\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Collecting relevant answers for em_score_1 and em_score_2\n",
    "#Reading information from csv_file with relevant answers and merge it with relevant information from cid dataframe\n",
    "reduced = pd.read_csv('data/Cities/cid_em_answers.csv')\n",
    "cid_red = cid.drop_duplicates(subset='account_number', keep='first')\n",
    "\n",
    "reduced   =     pd.merge(left = reduced,\n",
    "                     right = cid_red[['region', 'population']],\n",
    "                     left_on = reduced['account_number'],\n",
    "                     right_on = cid_red['account_number'], \n",
    "                     how = 'left')\n",
    "\n",
    "#Creating key based on year and account number\n",
    "reduced[\"select_key\"] =reduced[\"year\"].astype(str)+\"_\"+reduced[\"account_number\"].astype(str)\n",
    "\n",
    "#Calculating target emission per people and year one year in advance\n",
    "reduced['next_emission_pop'] = (((reduced['50a_target_year_emissions'] - reduced['total_emissions']) / (reduced['50a_target_year'] - reduced['year'])) + reduced['total_emissions']) / reduced['population']\n",
    "\n",
    "#Calculating actual emission per people and year\n",
    "reduced['emission_pop'] = reduced['total_emissions'] / reduced['population']\n",
    "\n",
    "#Colleting results in dataframe\n",
    "reduced = reduced[['emission_pop', 'next_emission_pop', 'select_key']]\n",
    "em_score = pd.DataFrame()\n",
    "em_score['select_key'] = reduced['select_key']\n",
    "em_score['em_score_1'] = reduced.emission_pop.apply(create_score)\n",
    "em_score['em_score_2'] = reduced.next_emission_pop.apply(create_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collecting results for cities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging city scores to one dataframe\n",
    "\n",
    "score_ci  =     pd.merge(left = s_score,\n",
    "                     right = o_score_ci[['o_score_1','o_score_2']],\n",
    "                     left_on = s_score['select_key'],\n",
    "                     right_on = o_score_ci['select_key'], \n",
    "                     how = 'left')\n",
    "\n",
    "score_ci = score_ci[['select_key', 's_score_1','s_score_2','o_score_1','o_score_2']]\n",
    "\n",
    "score_ci  =     pd.merge(left = score_ci,\n",
    "                     right = em_score[['em_score_1','em_score_2']],\n",
    "                     left_on = s_score['select_key'],\n",
    "                     right_on = o_score_ci['select_key'], \n",
    "                     how = 'left') \n",
    "\n",
    "score_ci['s_score_1'] = score_ci.s_score_1.astype(int)\n",
    "score_ci['s_score_2'] = score_ci.s_score_2.astype(int)\n",
    "score_ci['o_score_1'] = score_ci.s_score_1.astype(int)\n",
    "score_ci['o_score_2'] = score_ci.s_score_2.astype(int)\n",
    "score_ci = score_ci[['select_key', 's_score_1','s_score_2','o_score_1','o_score_2','em_score_1','em_score_2']]\n",
    "\n",
    "score_ci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collecting results for companies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging corporation scores to one dataframe\n",
    "\n",
    "score_co  =     o_score_co\n",
    "\n",
    "score_co['o_score_1'] = score_co.o_score_1.astype(int)\n",
    "score_co['o_score_2'] = score_co.o_score_2.astype(int)\n",
    "score_co['o_score_3'] = score_co.o_score_3.astype(int)\n",
    "score_co['o_score_4'] = score_co.o_score_4.astype(int)\n",
    "score_co['o_score_5'] = score_co.o_score_5.astype(int)\n",
    "\n",
    "score_co = score_co[['select_key','o_score_1','o_score_2','o_score_3','o_score_4','o_score_5']]\n",
    "\n",
    "score_co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.2 Scoring (Corporates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will be two scores for the corporation emission data.  \n",
    "\n",
    "**em_score_1** will give a score for the actual scope 1 emission in comprehension to the other scope 1 emissions in the other corporations being in the same industry.  \n",
    "\n",
    "- 5 Points for being in the first quantile of scope 1 emissions\n",
    "- 4 Points for being in the second quantile of scope 1 emissions\n",
    "- 3 Points for being in the third quantile of scope 1 emissions\n",
    "- 2 Points for being in the fourth quantile of scope 1 emissions\n",
    "- 1 Point for being in the fifth quantile of scope 1 emissions\n",
    "- 0 Points for missing answers\n",
    "\n",
    "\n",
    "**em_score_2** will give a score for providing emission data for scope 1, 2 and 3.  \n",
    "- 5 Points for providing scope 3 emission data and scope 1 or 2\n",
    "- 4 Points for providing only scope 3 emission data\n",
    "- 3 Points for providing only scope 1 and 2 data\n",
    "- 2 Points for providing only scope 2 data\n",
    "- 1 Point for providing only scope 1 data\n",
    "- 0 Points for missing answers\n",
    "\n",
    "\n",
    "**Idea for a more distributed em_score_2 (needs testing)** \n",
    "- 5 Points for providing all 3 scopes\n",
    "- 4 Points for providing scope 1 and scope 2\n",
    "- 3 Points for providing scope 2 and scope 3\n",
    "- 2 Points for providing only scope 1\n",
    "- 2 Points for providing only scope 2\n",
    "- 2 Points for providing only scope 3\n",
    "- 1 Point for providing nothing\n",
    "- 0 Points for missing answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframe subset for question C6.1 column 1 \n",
    "reduced = cor[(cor['question_number'] == 'C6.1') & (cor['theme'] == 'climate') & (cor['column_number']==1)]\n",
    "reduced[\"select_key\"] =reduced[\"year\"].astype(str)+\"_\"+reduced[\"account_number\"].astype(str)\n",
    "reduced = reduced[['select_key', 'response_answer']]\n",
    "\n",
    "# Anmerkung: Column-1 enthält diverse Einträge für 'Reporting year', 'Past year 1', 'Past year 2', 'Past year 3'\n",
    "# Deshalb gibt es auch mehr Antworten als Account/Year\n",
    "\n",
    "#Count for companies with several answers the highest value\n",
    "reduced = reduced.groupby('select_key')['response_answer'].max().to_frame()\n",
    "reduced['select_key'] =reduced.index\n",
    "reduced = reduced[['select_key','response_answer']]\n",
    "reduced_em1 = pd.DataFrame()\n",
    "reduced_em1['select_key'] = reduced['select_key']\n",
    "reduced_em1['total_emissions'] = reduced['response_answer']\n",
    "reduced_em1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Merge data together with data from cod dataframe\n",
    "cod_red = cod[cod['theme'] == 'climate']\n",
    "cod_red[\"select_key\"] =cod_red[\"year\"].astype(str)+\"_\"+cod_red[\"account_number\"].astype(str)\n",
    "cod_red.reset_index(inplace=True)\n",
    "cod_em1 =pd.merge(left = cod_red,\n",
    "                     right = reduced_em1[['total_emissions']],\n",
    "                     left_on = cod_red['select_key'],\n",
    "                     right_on = reduced_em1['select_key'], \n",
    "                     how = 'left',\n",
    "                     copy = False)\n",
    "cod_em1['total_emissions'] = cod_em1['total_emissions'].astype(\"float\")\n",
    "\n",
    "#Create dataframe with quantiles of total emission grouped by industries\n",
    "q=pd.DataFrame()\n",
    "q['a'] = cod_em1.groupby('industries')['total_emissions'].quantile(0.2).to_frame()['total_emissions']\n",
    "q['b'] = cod_em1.groupby('industries')['total_emissions'].quantile(0.4).to_frame()['total_emissions']\n",
    "q['c'] = cod_em1.groupby('industries')['total_emissions'].quantile(0.6).to_frame()['total_emissions']\n",
    "q['d'] = cod_em1.groupby('industries')['total_emissions'].quantile(0.8).to_frame()['total_emissions']\n",
    "q['industries'] = q.index\n",
    "q.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Merge generated information back to dataframe\n",
    "cod_em1 = cod_em1.iloc[:, 1:]\n",
    "cod_em1 =pd.merge(left = cod_em1,\n",
    "                     right = q[['a','b','c','d']],\n",
    "                     left_on = cod_red['industries'],\n",
    "                     right_on = q['industries'], \n",
    "                     how = 'left')\n",
    "\n",
    "#Create scoring function for em_score_1\n",
    "def score(c):\n",
    "    \n",
    "    if c['total_emissions'] < c['a']:\n",
    "        return 5\n",
    "    elif (c['total_emissions'] > c['a']) & (c['total_emissions'] < c['b']):\n",
    "        return 4\n",
    "    elif (c['total_emissions'] > c['b']) & (c['total_emissions'] < c['c']):\n",
    "        return 3\n",
    "    elif (c['total_emissions'] > c['c']) & (c['total_emissions'] < c['d']):\n",
    "        return 2\n",
    "    elif (c['total_emissions'] > c['d']):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Create em_score_1\n",
    "cod_em1['em_score_1'] = cod_em1.apply(score, axis=1)\n",
    "cod_em1 = cod_em1[['select_key','em_score_1']]\n",
    "\n",
    "# Hier beginnt Scope-1:\n",
    "#Creating dataframe subset for question C6.1 column 1 \n",
    "reduced = cor[(cor['question_number'] == 'C6.1') & (cor['theme'] == 'climate') & (cor['column_number']==1)]\n",
    "reduced[\"select_key\"] =reduced[\"year\"].astype(str)+\"_\"+reduced[\"account_number\"].astype(str)\n",
    "reduced = reduced[['select_key', 'response_answer']]\n",
    "\n",
    "#Create dataframe with scope 1 emissions\n",
    "reduced = reduced.groupby('select_key')['response_answer'].max().to_frame()\n",
    "reduced['select_key'] =reduced.index\n",
    "reduced = reduced[['select_key','response_answer']]\n",
    "reduced_sc1 = pd.DataFrame()\n",
    "reduced_sc1['select_key'] = reduced['select_key']\n",
    "reduced_sc1['scope_1'] = reduced['response_answer']\n",
    "reduced_sc1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Hier beginnt Scope-2:\n",
    "#Creating dataframe subset for question C6.3 column 1 \n",
    "reduced = cor[(cor['question_number'] == 'C6.3') & (cor['theme'] == 'climate') & (cor['column_number']==1)]\n",
    "reduced[\"select_key\"] =reduced[\"year\"].astype(str)+\"_\"+reduced[\"account_number\"].astype(str)\n",
    "reduced = reduced[['select_key', 'response_answer']]\n",
    "\n",
    "# Anmerkung: In 6.3 gibt es Werte in Col-1 (location-based) und Col-2 (market-based)\n",
    "# Und auch hier gibt es diverse Einträge für 'Reporting year', 'Past year 1', 'Past year 2', 'Past year 3'\n",
    "# Deshalb gibt es wohl auch hier mehr Antworten als Account/Year\n",
    "\n",
    "#Create dataframe with scope 2 emissions\n",
    "reduced = reduced.groupby('select_key')['response_answer'].max().to_frame()\n",
    "reduced['select_key'] =reduced.index\n",
    "reduced = reduced[['select_key','response_answer']]\n",
    "reduced_sc2 = pd.DataFrame()\n",
    "reduced_sc2['select_key'] = reduced['select_key']\n",
    "reduced_sc2['scope_2'] = reduced['response_answer']\n",
    "reduced_sc2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Hier beginnt Scope-3:\n",
    "#Creating dataframe subset for question C6.5 column 2 \n",
    "reduced = cor[(cor['question_number'] == 'C6.5') & (cor['theme'] == 'climate') & (cor['column_number']==2)]\n",
    "reduced[\"select_key\"] =reduced[\"year\"].astype(str)+\"_\"+reduced[\"account_number\"].astype(str)\n",
    "reduced = reduced[['select_key', 'response_answer']]\n",
    "\n",
    "# Col-2 gibt Werte für diverse Rows (Relevant, Not-Relevant usw. aus).\n",
    "# Es braucht eigentlich eine Beschränkung auf die Rows mit 'Evaluation status' (Col-1) = 'Relevant, calculated'\n",
    "\n",
    "#Create dataframe with scope 3 emissions\n",
    "reduced = reduced.groupby('select_key')['response_answer'].max().to_frame()\n",
    "reduced['select_key'] =reduced.index\n",
    "reduced = reduced[['select_key','response_answer']]\n",
    "reduced_sc3 = pd.DataFrame()\n",
    "reduced_sc3['select_key'] = reduced['select_key']\n",
    "reduced_sc3['scope_3'] = reduced['response_answer']\n",
    "reduced_sc3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Merge results together\n",
    "cod_red = cod[cod['theme'] == 'climate']\n",
    "cod_red[\"select_key\"] =cod_red[\"year\"].astype(str)+\"_\"+cod_red[\"account_number\"].astype(str)\n",
    "cod_red.reset_index(inplace=True)\n",
    "cod_em2 =pd.merge(left = cod_red,\n",
    "                     right = reduced_sc1[['scope_1']],\n",
    "                     left_on = cod_red['select_key'],\n",
    "                     right_on = reduced_sc1['select_key'], \n",
    "                     how = 'left',\n",
    "                     copy = False)\n",
    "cod_em2 = cod_em2.iloc[:, 1:]\n",
    "cod_em2 =pd.merge(left = cod_em2,\n",
    "                     right = reduced_sc2[['scope_2']],\n",
    "                     left_on = cod_red['select_key'],\n",
    "                     right_on = reduced_sc2['select_key'], \n",
    "                     how = 'left',\n",
    "                     copy = False)\n",
    "cod_em2 = cod_em2.iloc[:, 1:]\n",
    "cod_em2 =pd.merge(left = cod_em2,\n",
    "                     right = reduced_sc3[['scope_3']],\n",
    "                     left_on = cod_red['select_key'],\n",
    "                     right_on = reduced_sc3['select_key'], \n",
    "                     how = 'left',\n",
    "                     copy = False)\n",
    "cod_em2.fillna(0, inplace=True)\n",
    "cod_em2['scope_1'] = cod_em2['scope_1'].astype(\"float\")\n",
    "cod_em2['scope_2'] = cod_em2['scope_2'].astype(\"float\")\n",
    "cod_em2['scope_3'] = cod_em2['scope_3'].astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create scoring function for em_score_2\n",
    "def score(c):\n",
    "    \n",
    "    if (c['scope_1'] == 0) & (c['scope_2'] == 0) & (c['scope_3'] == 0):\n",
    "        return 0\n",
    "    elif (c['scope_1'] > 0) & (c['scope_2'] == 0) & (c['scope_3'] == 0):\n",
    "        return 1\n",
    "    elif (c['scope_2'] == 0) & (c['scope_2'] > 0) & (c['scope_3'] == 0):\n",
    "        return 2\n",
    "    elif (c['scope_1'] > 0) & (c['scope_2'] > 0) & (c['scope_3'] == 0):\n",
    "        return 3\n",
    "    elif (c['scope_1'] == 0) & (c['scope_2'] == 0) & (c['scope_3'] > 0):\n",
    "        return 4\n",
    "    elif ((c['scope_1'] > 0) & (c['scope_2'] > 0)) & (c['scope_3'] > 0):\n",
    "        return 5\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "#Create em_score_2\n",
    "cod_em2['em_score_2'] = cod_em2.apply(score, axis=1)\n",
    "cod_em2 = cod_em2[['select_key','em_score_2']]\n",
    "\n",
    "#Merge em_score_1 and em_score_2 together to one dataframe\n",
    "cod_em =pd.merge(left = cod_em1,\n",
    "                     right = cod_em2[['em_score_2']],\n",
    "                     left_on = cod_em1['select_key'],\n",
    "                     right_on = cod_em2['select_key'], \n",
    "                     how = 'left',\n",
    "                     copy = False)\n",
    "cod_em = cod_em.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging corporate scores to one dataframe\n",
    "score_co  =     pd.merge(left = score_co,\n",
    "                         right = cod_em,\n",
    "                         on = 'select_key',\n",
    "                         how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_co['em_score_2'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.3 Conclusion\n",
    "<font color=orange size=4> **Kurze Zusammenfassung des Capitels.** </font>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through our exploration we have found out that...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Conclusion & Future Work "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=5> **Wer? / Kurze Zusammenfassung unseres Gesamtergebnisses und Ausblick** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consolidating SCORE-Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# von David:\n",
    "#if pkl_write: cis.to_pickle('data/cis.pkl')\n",
    "#if pkl_read: cis = pd.read_pickle('data/cis.pkl')\n",
    "\n",
    "#if pkl_write: cos.to_pickle('data/cos.pkl')\n",
    "#if pkl_read: cos = pd.read_pickle('data/cos.pkl')\n",
    "cos.rename(columns={\n",
    "    'r_score_1':'r_score_5',\n",
    "    'r_score_2':'r_score_6',\n",
    "    'r_score_3':'r_score_7'},inplace=True)\n",
    "\n",
    "#if pkl_write: sex.to_pickle('data/sex.pkl')\n",
    "#if pkl_read: sex = pd.read_pickle('data/sex.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# von Tobi:\n",
    "#if pkl_write: cid_scores.to_pickle('data/cid_scores.pkl')\n",
    "#if pkl_read: cid_scores = pd.read_pickle('data/cid_scores.pkl')\n",
    "cid_scores.rename(columns={\n",
    "    'year':'int_year'}, inplace=True)\n",
    "\n",
    "#if pkl_write: cod_scores.to_pickle('data/cod_scores.pkl')\n",
    "#if pkl_read: cod_scores = pd.read_pickle('data/cod_scores.pkl')\n",
    "cod_scores.rename(columns={\n",
    "    'year':'int_year'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# von Felix:\n",
    "#if pkl_write: score_ci.to_pickle('data/score_ci.pkl')\n",
    "#if pkl_read: score_ci = pd.read_pickle('data/score_ci.pkl')\n",
    "\n",
    "#if pkl_write: score_co.to_pickle('data/score_co.pkl')\n",
    "#if pkl_read: score_co = pd.read_pickle('data/score_co.pkl')\n",
    "score_co.rename(columns={\n",
    "    'o_score_1': 'o_score_03',\n",
    "    'o_score_2': 'o_score_04',\n",
    "    'o_score_3': 'o_score_05',\n",
    "    'o_score_4': 'o_score_6',\n",
    "    'o_score_5': 'o_score_7',\n",
    "    'em_score_1': 'em_score_3',\n",
    "    'em_score_2': 'em_score_4'},inplace=True)\n",
    "score_co.rename(columns={\n",
    "    'o_score_03': 'o_score_3',\n",
    "    'o_score_04': 'o_score_4',\n",
    "    'o_score_05': 'o_score_5'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# von Olaf:\n",
    "# cid_enh # used as it is\n",
    "# cod_enh # used as it is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cities: Creating the empty frame for the consolidated cities scores\n",
    "# Einmalig (Alle):\n",
    "ci_scores = cid[[\n",
    "    'type',\n",
    "    'theme',\n",
    "    'year',\n",
    "    'account_number',\n",
    "    'public',\n",
    "    'entity',\n",
    "    'country',\n",
    "    'region'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bereitstellen der\n",
    "# s_scores (Felix):\n",
    "score_ci['year']           = score_ci.apply(lambda x : str(x['select_key'].split('_')[0]), axis=1)\n",
    "score_ci['account_number'] = score_ci.apply(lambda x : int(x['select_key'].split('_')[1]), axis=1)\n",
    "\n",
    "score_ci_merge = score_ci[[\n",
    "    'year',\n",
    "    'account_number',\n",
    "    's_score_1',\n",
    "    's_score_2'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge des ci_scores mit\n",
    "# s_scores (Felix):\n",
    "ci_scores = pd.merge(\n",
    "    left = ci_scores, \n",
    "    right = score_ci_merge, \n",
    "    on = ('year','account_number'), \n",
    "    how = \"left\"\n",
    ")\n",
    "\n",
    "# Ersetzen der NaN-Werte durch 0 und Umwandlung in int64:\n",
    "#ci_scores['x_score_x'] = ci_scores['x_score_x'].fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bereitstellen der\n",
    "# c_scores (Tobi):\n",
    "cid_scores['year'] = cid_scores.apply(lambda x : str(x['int_year'])[0:4], axis=1)\n",
    "cid_scores_merge = cid_scores[[\n",
    "    'year',\n",
    "    'account_number',\n",
    "    'c_score_1',\n",
    "    'c_score_2'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge des ci_scores mit\n",
    "# c_scores (Tobi):\n",
    "ci_scores = pd.merge(\n",
    "    left = ci_scores, \n",
    "    right = cid_scores_merge, \n",
    "    on = ('year','account_number'), \n",
    "    how = \"left\"\n",
    ")\n",
    "\n",
    "# Ersetzen der NaN-Werte durch 0 und Umwandlung in int64:\n",
    "ci_scores['c_score_1'] = ci_scores['c_score_1'].fillna(0).astype('int64')\n",
    "ci_scores['c_score_2'] = ci_scores['c_score_2'].fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bereitstellen der\n",
    "# o_scores (Felix):\n",
    "score_ci['year']           = score_ci.apply(lambda x : str(x['select_key'].split('_')[0]), axis=1)\n",
    "score_ci['account_number'] = score_ci.apply(lambda x : int(x['select_key'].split('_')[1]), axis=1)\n",
    "\n",
    "score_ci_merge = score_ci[[\n",
    "    'year',\n",
    "    'account_number',\n",
    "    'o_score_1',\n",
    "    'o_score_2'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge des ci_scores mit\n",
    "# o_scores (Felix):\n",
    "ci_scores = pd.merge(\n",
    "    left = ci_scores, \n",
    "    right = score_ci_merge, \n",
    "    on = ('year','account_number'), \n",
    "    how = \"left\"\n",
    ")\n",
    "\n",
    "# Ersetzen der NaN-Werte durch 0 und Umwandlung in int64:\n",
    "#ci_scores['x_score_x'] = ci_scores['x_score_x'].fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bereitstellen der\n",
    "# r_scores (David):\n",
    "cis_merge = cis[[\n",
    "    'year',\n",
    "    'account_number',\n",
    "    'r_score_1',\n",
    "    'r_score_2',\n",
    "    'r_score_3',\n",
    "    'r_score_4'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge des ci_scores mit\n",
    "# r_scores (David):\n",
    "ci_scores = pd.merge(\n",
    "    left = ci_scores, \n",
    "    right = cis_merge, \n",
    "    on = ('year','account_number'), \n",
    "    how = \"left\"\n",
    ")\n",
    "\n",
    "# Ersetzen der NaN-Werte durch 0 und Umwandlung in int64:\n",
    "ci_scores['r_score_1'] = ci_scores['r_score_1'].fillna(0).astype('int64')\n",
    "ci_scores['r_score_2'] = ci_scores['r_score_2'].fillna(0).astype('int64')\n",
    "ci_scores['r_score_3'] = ci_scores['r_score_3'].fillna(0).astype('int64')\n",
    "ci_scores['r_score_4'] = ci_scores['r_score_4'].fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bereitstellen der\n",
    "# e_scores (Olaf):\n",
    "cid_enh_merge = cid_enh[[\n",
    "    'type',\n",
    "    'theme',\n",
    "    'year',\n",
    "    'account_number',\n",
    "    'e_score_1',\n",
    "    'e_score_2',\n",
    "    'e_score_3',\n",
    "    'e_score_4',\n",
    "    'e_score_6',\n",
    "    'e_score_7'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge des ci_scores mit\n",
    "# e_scores (Olaf):\n",
    "ci_scores = pd.merge(\n",
    "    left = ci_scores, \n",
    "    right = cid_enh_merge, \n",
    "    on = ('type','theme','year','account_number'), \n",
    "    how = \"left\"\n",
    ")\n",
    "\n",
    "# Ersetzen der NaN-Werte durch 0 und Umwandlung in int64:\n",
    "ci_scores['e_score_6'] = ci_scores['e_score_6'].fillna(0).astype('int64')\n",
    "ci_scores['e_score_7'] = ci_scores['e_score_7'].fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bereitstellen der\n",
    "# o_scores (Felix):\n",
    "score_ci['year']           = score_ci.apply(lambda x : str(x['select_key'].split('_')[0]), axis=1)\n",
    "score_ci['account_number'] = score_ci.apply(lambda x : int(x['select_key'].split('_')[1]), axis=1)\n",
    "\n",
    "score_ci_merge = score_ci[[\n",
    "    'year',\n",
    "    'account_number',\n",
    "    'em_score_1',\n",
    "    'em_score_2'\n",
    "]]\n",
    "\n",
    "# Merge des ci_scores mit\n",
    "# o_scores (Felix):\n",
    "ci_scores = pd.merge(\n",
    "    left = ci_scores, \n",
    "    right = score_ci_merge, \n",
    "    on = ('year','account_number'), \n",
    "    how = \"left\"\n",
    ")\n",
    "\n",
    "# Ersetzen der NaN-Werte durch 0 und Umwandlung in int64:\n",
    "#ci_scores['x_score_x'] = ci_scores['x_score_x'].fillna(0).astype('int64')\n",
    "\n",
    "ci_scores.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pkl_write: ci_scores.to_pickle('data/ci_scores.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corporates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corporates: Creating the empty frame for the consolidated corporates scores (only 'theme' = 'climate')\n",
    "# Einmalig (Alle):\n",
    "co_scores = cod.query('theme == \"climate\"')[[\n",
    "    'type',\n",
    "    'theme',\n",
    "    'year',\n",
    "    'account_number',\n",
    "    'public',\n",
    "    'entity',\n",
    "    'country'\n",
    "]]\n",
    "co_scores['region'] = 'North America'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bereitstellen der\n",
    "# c_scores (Tobi):\n",
    "cod_scores['year'] = cod_scores.apply(lambda x : str(x['int_year'])[0:4], axis=1)\n",
    "\n",
    "cod_scores_merge = cod_scores[[\n",
    "    'year',\n",
    "    'account_number',\n",
    "    'c_score_3',\n",
    "    'c_score_4',\n",
    "    'c_score_5',\n",
    "    'c_score_6'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge des co_scores mit\n",
    "# c_scores (Tobi):\n",
    "co_scores = pd.merge(\n",
    "    left = co_scores, \n",
    "    right = cod_scores_merge, \n",
    "    on = ('year','account_number'), \n",
    "    how = \"left\"\n",
    ")\n",
    "\n",
    "# Ersetzen der NaN-Werte durch 0 und Umwandlung in int64:\n",
    "co_scores['c_score_3'] = co_scores['c_score_3'].fillna(0).astype('int64')\n",
    "co_scores['c_score_4'] = co_scores['c_score_4'].fillna(0).astype('int64')\n",
    "co_scores['c_score_5'] = co_scores['c_score_5'].fillna(0).astype('int64')\n",
    "co_scores['c_score_6'] = co_scores['c_score_6'].fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bereitstellen der\n",
    "# o_scores (Felix):\n",
    "score_co['year']           = score_co.apply(lambda x : str(x['select_key'].split('_')[0]), axis=1)\n",
    "score_co['account_number'] = score_co.apply(lambda x : int(x['select_key'].split('_')[1]), axis=1)\n",
    "\n",
    "score_co_merge = score_co[[\n",
    "    'year',\n",
    "    'account_number',\n",
    "    'o_score_3',\n",
    "    'o_score_4',\n",
    "    'o_score_5',\n",
    "    'o_score_6',\n",
    "    'o_score_7'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge des co_scores mit\n",
    "# o_scores (Felix):\n",
    "co_scores = pd.merge(\n",
    "    left = co_scores, \n",
    "    right = score_co_merge, \n",
    "    on = ('year','account_number'), \n",
    "    how = \"left\"\n",
    ")\n",
    "\n",
    "# Ersetzen der NaN-Werte durch 0 und Umwandlung in int64:\n",
    "#co_scores['x_score_x'] = co_scores['x_score_x'].fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bereitstellen der\n",
    "# r_scores (David):\n",
    "cos_merge = cos[[\n",
    "    'year',\n",
    "    'account_number',\n",
    "    'r_score_5',\n",
    "    'r_score_6',\n",
    "    'r_score_7'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge des co_scores mit\n",
    "# r_scores (David):\n",
    "co_scores = pd.merge(\n",
    "    left = co_scores, \n",
    "    right = cos_merge, \n",
    "    on = ('year','account_number'), \n",
    "    how = \"left\"\n",
    ")\n",
    "\n",
    "# Ersetzen der NaN-Werte durch 0 und Umwandlung in int64:\n",
    "co_scores['r_score_5'] = co_scores['r_score_5'].fillna(0).astype('int64')\n",
    "co_scores['r_score_6'] = co_scores['r_score_6'].fillna(0).astype('int64')\n",
    "co_scores['r_score_7'] = co_scores['r_score_7'].fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bereitstellen der\n",
    "# e_scores (Olaf):\n",
    "cod_enh_merge = cod_enh.query('theme == \"climate\"')[[\n",
    "    'type',\n",
    "    'theme',\n",
    "    'year',\n",
    "    'account_number',\n",
    "    'e_score_8',\n",
    "    'e_score_9',\n",
    "    'e_score_10',\n",
    "    'e_score_11'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge des co_scores mit\n",
    "# e_scores (Olaf):\n",
    "co_scores = pd.merge(\n",
    "    left = co_scores, \n",
    "    right = cod_enh_merge, \n",
    "    on = ('type','theme','year','account_number'), \n",
    "    how = \"left\"\n",
    ")\n",
    "\n",
    "# Ersetzen der NaN-Werte durch 0 und Umwandlung in int64:\n",
    "#co_scores['x_score_xx'] = co_scores['x_score_xx'].fillna(0).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bereitstellen der\n",
    "# o_scores (Felix):\n",
    "score_co['year']           = score_co.apply(lambda x : str(x['select_key'].split('_')[0]), axis=1)\n",
    "score_co['account_number'] = score_co.apply(lambda x : int(x['select_key'].split('_')[1]), axis=1)\n",
    "\n",
    "score_co_merge = score_co[[\n",
    "    'year',\n",
    "    'account_number',\n",
    "    'em_score_3',\n",
    "    'em_score_4'\n",
    "]]\n",
    "\n",
    "# Merge des co_scores mit\n",
    "# o_scores (Felix):\n",
    "co_scores = pd.merge(\n",
    "    left = co_scores, \n",
    "    right = score_co_merge, \n",
    "    on = ('year','account_number'), \n",
    "    how = \"left\"\n",
    ")\n",
    "\n",
    "# Ersetzen der NaN-Werte durch 0 und Umwandlung in int64:\n",
    "#ci_scores['x_score_x'] = ci_scores['x_score_x'].fillna(0).astype('int64')\n",
    "\n",
    "co_scores.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pkl_write: co_scores.to_pickle('data/co_scores.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Cities & Corporates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = pd.merge(\n",
    "    left = ci_scores, \n",
    "    right = co_scores, \n",
    "    on = [\n",
    "        'type',\n",
    "        'theme',\n",
    "        'year',\n",
    "        'account_number',\n",
    "        'public',\n",
    "        'entity',\n",
    "        'country',\n",
    "        'region'\n",
    "    ], \n",
    "    how = \"outer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing some values for direct Dashboard-usability:\n",
    "all_scores.loc[all_scores['type'] == 'cid','type'] = 'cities'\n",
    "all_scores.loc[all_scores['type'] == 'cod','type'] = 'corporates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pkl_write: all_scores.to_pickle('data/all_scores.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "270.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-showcode": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
